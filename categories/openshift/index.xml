<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>OpenShift on TechBlog about OpenShift/Ansible/Satellite and much more</title><link>https://blog.stderr.at/categories/openshift/</link><description>Recent content in OpenShift on TechBlog about OpenShift/Ansible/Satellite and much more</description><generator>Hugo</generator><language>en-us</language><copyright>Toni Schmidbauer &amp; Thomas Jungbauer</copyright><lastBuildDate>Mon, 10 Nov 2025 15:25:08 +0100</lastBuildDate><atom:link href="https://blog.stderr.at/categories/openshift/index.xml" rel="self" type="application/rss+xml"/><item><title>What's new in OpenShift, 4.20 Edition</title><link>https://blog.stderr.at/whatss-new/2025-11-10-whatsnew-420/</link><pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/whatss-new/2025-11-10-whatsnew-420/</guid><description>&lt;div class="paragraph">
&lt;p>This article covers news and updates in the OpenShift 4.20 release. We focus on points that got our attention, this
is &lt;strong>not&lt;/strong> a complete summary of the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/release_notes/index">release notes&lt;/a>.&lt;/p>
&lt;/div></description></item><item><title>Red Hat Quay Registry - Integrate Keycloak</title><link>https://blog.stderr.at/quay/2025-09-19-quay-integrate-keycloak/</link><pubDate>Fri, 19 Sep 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/quay/2025-09-19-quay-integrate-keycloak/</guid><description>&lt;div class="paragraph">
&lt;p>This guide shows you how to configure Keycloak as an OpenID Connect (OIDC) provider for Red Hat Quay Registry. It covers what to configure in Keycloak, what to put into Quay’s config.yaml (or Operator config), how to verify the login flow, and how to switch your Quay initial/admin account (stored locally in Quay’s DB) to an admin user that authenticates via Keycloak.&lt;/p>
&lt;/div></description></item><item><title>A second look into the Kubernetes Gateway API on OpenShift</title><link>https://blog.stderr.at/openshift/2025/08/a-second-look-into-the-kubernetes-gateway-api-on-openshift/</link><pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/08/a-second-look-into-the-kubernetes-gateway-api-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>This is our second look into the Kubernetes Gateway API an it’s
integration into OpenShift. This post covers TLS configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Kubernetes Gateway API is new implementation of the ingress, load
balancing and service mesh API’s. See
&lt;a href="https://gateway-api.sigs.k8s.io/" target="_blank" rel="noopener">upstream&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-overview_ingress-gateway-api" target="_blank" rel="noopener">OpenShift documentation&lt;/a> provides an overview of the Gateway API and it’s integration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We demonstrate how to add TLS to our Nginx deployment, how to
implement a shared Gateway and finally how to implement HTTP to HTTPS
redirection with the Gateway API. Furthermore we cover how &lt;em>HTTPRoute&lt;/em>
objects attach to Gateways and dive into ordering of &lt;em>HTTPRoute&lt;/em>
objects.&lt;/p>
&lt;/div></description></item><item><title>A first look into the Kubernetes Gateway API on OpenShift</title><link>https://blog.stderr.at/openshift/2025/08/a-first-look-into-the-kubernetes-gateway-api-on-openshift/</link><pubDate>Fri, 29 Aug 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/08/a-first-look-into-the-kubernetes-gateway-api-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>This blog post summarizes our first look into the Kubernetes Gateway
API and how it is integrated in OpenShift.&lt;/p>
&lt;/div></description></item><item><title>Reusable Argo CD Application Helm Template</title><link>https://blog.stderr.at/gitopscollection/2025-07-17-common-template-application/</link><pubDate>Thu, 17 Jul 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2025-07-17-common-template-application/</guid><description>&lt;div class="paragraph">
&lt;p>When working with Argo CD at scale, you often find yourself creating similar Application manifests repeatedly. Each application needs the same basic structure but with different configurations for source repositories, destinations, and sync policies. Additionally, managing namespace metadata becomes tricky when you need to conditionally control whether Argo CD should manage namespace metadata based on sync options.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article, I’ll walk you through a reusable Helm template that solves these challenges by providing a flexible, DRY (Don’t Repeat Yourself) approach to creating Argo CD Applications. This template is available in my public Helm Chart library and can easily be used by anyone.&lt;/p>
&lt;/div></description></item><item><title>Cert-Manager Policy Approver in OpenShift</title><link>https://blog.stderr.at/openshift/2025/06/cert-manager-policy-approver-in-openshift/</link><pubDate>Tue, 03 Jun 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/06/cert-manager-policy-approver-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>One of the most commonly deployed operators in OpenShift environments is the &lt;strong>Cert-Manager Operator&lt;/strong>. It automates the management of TLS certificates for applications running within the cluster, including their issuance and renewal.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The tool supports a variety of certificate issuers by default, including ACME, Vault, and self-signed certificates. Whenever a certificate is needed, Cert-Manager will automatically create a CertificateRequest resource that contains the details of the certificate. This resource is then processed by the appropriate issuer to generate the actual TLS certificate. The approval process in this case is usually fully automated, meaning that the certificate is issued without any manual intervention.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>But what if you want to have more control? What if certificate issuance must follow strict organizational policies, such as requiring a specifc country code or organization name?
This is where the &lt;strong>CertificateRequestPolicy&lt;/strong> resource, a resource provided by the Approver Policy, comes into play.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article walks through configuring the &lt;strong>Cert-Manager Approver Policy&lt;/strong> in OpenShift to enforce granular policies on certificate requests.&lt;/p>
&lt;/div></description></item><item><title>Single log out from Keycloak and OpenShift</title><link>https://blog.stderr.at/openshift/2025/05/single-log-out-from-keycloak-and-openshift/</link><pubDate>Thu, 22 May 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/05/single-log-out-from-keycloak-and-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>The following 1-minute article is a follow-up to my &lt;a href="https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/">previous article&lt;/a> about how to use Keycloak as an authentication provider for OpenShift. In this article, I will show you how to configure Keycloak and OpenShift for Single Log Out (SLO). This means that when you log out from Keycloak, you will also be logged out from OpenShift automatically. This requires some additional configuration in Keycloak and OpenShift, but it is not too complicated.&lt;/p>
&lt;/div></description></item><item><title>Step by Step - Using Keycloak Authentication in OpenShift</title><link>https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/</link><pubDate>Sat, 17 May 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>I was recently asked about how to use Keycloak as an authentication provider for OpenShift. How to install Keycloak using the Operator and how to configure Keycloak and OpenShift so that users can log in to OpenShift using OpenID.
I have to admit that the exact steps are not easy to find, so I decided to write a blog post about it, describing each step in detail.
This time I will not use GitOps, but the OpenShift and Keycloak Web Console to show the steps, because before we put it into GitOps, we need to understand what is actually happening.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article tries to explain every step required so that a user can authenticate to OpenShift using Keycloak as an Identity Provider (IDP) and that Groups from Keycloak are imported into OpenShift. This article does not cover a production grade installation of Keycloak, but only a test installation, so you can see how it works. For production, you might want to consider a proper database (maybe external, but at least with a backup), high availability, etc.).&lt;/p>
&lt;/div></description></item><item><title>Using ApplicationSet with Matrix Generator and define individual Namespaces</title><link>https://blog.stderr.at/gitopscollection/2025-04-17-applicationset-defining-namespaces/</link><pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2025-04-17-applicationset-defining-namespaces/</guid><description>&lt;div class="paragraph">
&lt;p>During my day-to-day business, I am discussing the following setup with many customers: &lt;a href="https://blog.stderr.at/gitopscollection/2024-04-02-configure_app_of_apps/">Configure App-of-Apps&lt;/a>. Here I try to explain how I use an ApplicationSet that watches over a folder in Git and automatically adds a new Argo CD Application whenever a new folder is found. This works great, but there is a catch: The ApplicationSet uses the same Namespace &lt;strong>default&lt;/strong> for all Applications. This is not always desired, especially when you have different teams working on different Applications.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Recently I was asked by the customer if this can be fixed and if it is possible to define different Namespaces for each Application. The answer is yes, and I would like to show you how to do this.&lt;/p>
&lt;/div></description></item><item><title>Introducing AdminNetworkPolicies</title><link>https://blog.stderr.at/openshift/2024/11/introducing-adminnetworkpolicies/</link><pubDate>Wed, 06 Nov 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2024/11/introducing-adminnetworkpolicies/</guid><description>&lt;div class="paragraph">
&lt;p>Classic Kubernetes/OpenShift offer a feature called NetworkPolicy that allows users to control the traffic to and from their assigned Namespace.
NetworkPolicies are designed to give project owners or tenants the ability to protect their own namespace. Sometimes, however, I worked with customers where the
cluster administrators or a dedicated (network) team need to enforce these policies.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Since the NetworkPolicy API is namespace-scoped, it is not possible to enforce policies across namespaces. The only solution was to create custom (project) admin and edit
roles, and remove the ability of creating, modifying or deleting NetworkPolicy objects. Technically, this is possible and easily done. But shifts the whole network security to cluster administrators.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Luckily, this is where &lt;strong>AdminNetworkPolicy&lt;/strong> (ANP) and &lt;strong>BaselineAdminNetworkPolicy&lt;/strong> (BANP) comes into play.&lt;/p>
&lt;/div></description></item><item><title>Using Kustomize to post render a Helm Chart</title><link>https://blog.stderr.at/gitopscollection/2024-10-13-using-post-renderer/</link><pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-10-13-using-post-renderer/</guid><description>&lt;div class="paragraph">
&lt;p>Lately I came across several issues where a given Helm Chart must be modified after it has been rendered by Argo CD.
Argo CD does a &lt;strong>helm template&lt;/strong> to render a Chart. Sometimes, especially when you work with Subcharts or when a specific setting is not yet supported by the Chart, you need to modify it later …​ you need to post-render the Chart.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this very short article, I would like to demonstrate this on a real-live example I had to do. I would like to inject annotations to a Route objects, so that the certificate can be injected. This is done by the cert-utils operator.
For the post-rendering the Argo CD repo pod will be extended with a sidecar container, that is watching for the repos and patches them if required.&lt;/p>
&lt;/div></description></item><item><title>Managing Certificates using GitOps approach</title><link>https://blog.stderr.at/gitopscollection/2024-07-04-managing-certificates-with-gitops/</link><pubDate>Thu, 04 Jul 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-07-04-managing-certificates-with-gitops/</guid><description>&lt;div class="paragraph">
&lt;p>The article &lt;a href="https://blog.stderr.at/openshift/2023/02/ssl-certificate-management-for-openshift-on-aws/">SSL Certificate Management for OpenShift on AWS&lt;/a> explains how to use the &lt;strong>Cert-Manager Operator&lt;/strong> to request and install a new SSL Certificate.
This time, I would like to leverage the GitOps approach using the Helm Chart &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/cert-manager" target="_blank" rel="noopener">cert-manager&lt;/a> I have prepared to deploy the Operator and order new Certificates.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I will use an ACME Letsencrypt issuer with a DNS challenge. My domain is hosted at AWS Route 53.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>However, any other integration can be easily used.&lt;/p>
&lt;/div></description></item><item><title>Update Cluster Version using GitOps approach</title><link>https://blog.stderr.at/gitopscollection/2024-06-07-update-cluster-version-with-gitops/</link><pubDate>Fri, 07 Jun 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-06-07-update-cluster-version-with-gitops/</guid><description>&lt;div class="paragraph">
&lt;p>During a GitOps journey at one point, the question arises, how to update a cluster? Nowadays it is very easy to update a cluster using CLI or WebUI, so why bother with GitOps in that case? The reason is simple: Using GitOps you can be sure that all clusters are updated to the correct, required version and the version of each cluster is also managed in Git.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>All you need is the &lt;strong>channel&lt;/strong> you want to use and the desired cluster &lt;strong>version&lt;/strong>. Optionally, you can define the exact image SHA. This might be required when you are operating in a restricted environment.&lt;/p>
&lt;/div></description></item><item><title>Multiple Sources for Applications in Argo CD</title><link>https://blog.stderr.at/gitopscollection/2024-06-02-multisources-for-application-in-argocd/</link><pubDate>Sun, 02 Jun 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-06-02-multisources-for-application-in-argocd/</guid><description>&lt;div class="paragraph">
&lt;p>Argo CD or OpenShift GitOps uses Applications or ApplicationSets to define the relationship between a source (Git) and a cluster. Typically, this is a 1:1 link, which means one Application is using one source to compare the cluster status. This can be a limitation. For example, if you are working with Helm Charts and a Helm repository, you do not want to re-build (or re-release) the whole chart just because you made a small change in the values file that is packaged into the repository. You want to separate the configuration of the chart with the Helm package.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The most common scenarios for multiple sources are (see: &lt;a href="https://argo-cd.readthedocs.io/en/stable/user-guide/multiple_sources/" target="_blank" rel="noopener">Argo CD documentation&lt;/a>):&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Your organization wants to use an external/public Helm chart&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You want to override the Helm values with your own local values&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You don’t want to clone the Helm chart locally as well because that would lead to duplication and you would need to monitor it manually for upstream changes.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This small article describes three different ways with a working example and tries to cover the advantages and disadvantages of each of them. They might be opinionated but some of them proved to be easier to use and manage.&lt;/p>
&lt;/div></description></item><item><title>Installing OpenShift Logging using GitOps</title><link>https://blog.stderr.at/gitopscollection/2024-05-24-install-openshift-logging/</link><pubDate>Fri, 24 May 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-05-24-install-openshift-logging/</guid><description>&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.openshift.com/container-platform/4.15/observability/logging/logging_release_notes/logging-5-9-release-notes.html" target="_blank" rel="noopener">OpenShift Logging&lt;/a> is one of the more complex things to install and configure on an OpenShift cluster. Not because the service or Operators are so complex to understand, but because of the dependencies logging has. Besides the logging operator itself, the Loki operator is required, the Loki operator requires access to an object storage, that might be configured or is already available.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article, I would like to demonstrate the configuration of the full stack using an object storage from OpenShift Data Foundation. This means:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Installing the logging operator into the namespace openshift-logging&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Installing the Loki operator into the namespace openshift-operators-redhat&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Creating a new BackingStore and BucketClass&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Generating the Secret for Loki to authenticate against the object storage&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configuring the LokiStack resource&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configuring the ClusterLogging resource&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>All steps will be done automatically. In case you have S3 storage available, or you are not using OpenShift Data Foundation, the setup will be a bit different. For example, you do not need to create a BackingStore or the Loki authentication Secret.&lt;/p>
&lt;/div></description></item><item><title>Configure Buckets in MinIO using GitOps</title><link>https://blog.stderr.at/gitopscollection/2024-05-17-configure-minio-buckets/</link><pubDate>Fri, 17 May 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-05-17-configure-minio-buckets/</guid><description>&lt;div class="paragraph">
&lt;p>&lt;a href="https://min.io/" target="_blank" rel="noopener">MinIO&lt;/a> is a simple, S3-compatible object storage, built for high-performance and large-scale environments. It can be installed as an Operator to Openshift. In addition, to a command line tool, it provides a WebUI where all settings can be done, especially creating and configuring new buckets. Currently, this is not possible in a declarative GitOps-friendly way.
Therefore, I created the Helm chart &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/minio-configurator" target="_blank" rel="noopener">minio configurator&lt;/a>, that will start a Kubernetes Job, which will take care of the configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Honestly, when I say I have created it, the truth is, that it is based on an existing &lt;a href="https://github.com/bitnami/charts/tree/main/bitnami/minio" target="_blank" rel="noopener">MinIO Chart by Bitnami&lt;/a>, that does much more than just set up a bucket. I took out the bucket configuration part, streamlined it a bit and added some new features, which I required.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article shall explain how to achieve this.&lt;/p>
&lt;/div></description></item><item><title>Setup &amp; Configure Advanced Cluster Security using GitOps</title><link>https://blog.stderr.at/gitopscollection/2024-04-28-installing-advanced-cluster-security/</link><pubDate>Sun, 28 Apr 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-04-28-installing-advanced-cluster-security/</guid><description>&lt;div class="paragraph">
&lt;p>Today I want to demonstrate the deployment and configuration of &lt;strong>Advanced Cluster Security&lt;/strong> (ACS) using a GitOps approach. The required operator shall be installed, verified if it is running and then ACS shall be initialized. This initialization contains the deployment of several components:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Central - as UI and as a main component of ACS&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SecuredClusters - installs a Scanner, Controller pods etc.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Console link into OpenShift UI - to directly access the ACS Central UI&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Job to create an initialization bundle to install the Secured Cluster&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Job to configure authentication using OpenShift&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s start …​&lt;/p>
&lt;/div></description></item><item><title>Setup &amp; Configure Compliance Operator using GitOps</title><link>https://blog.stderr.at/gitopscollection/2024-04-25-installing-compliance-operator/</link><pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-04-25-installing-compliance-operator/</guid><description>&lt;div class="paragraph">
&lt;p>In the previous articles, we have discussed the &lt;a href="https://blog.stderr.at/gitopscollection/2023-12-28-gitops-repostructure/">Git repository folder structure&lt;/a> and the configuration of the &lt;a href="gitopscollection/2024-04-02-configure_app_of_apps/">App-Of-Apps&lt;/a>. Now it is time to deploy our first configuration. One of the first things I usually deploy is the &lt;a href="https://docs.openshift.com/container-platform/4.15/security/compliance_operator/co-overview.html" target="_blank" rel="noopener">Compliance Operator&lt;/a>. This Operator is recommended for any cluster and can be deployed without any addition to the Subscription.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article, I will describe how it is installed and how the Helm Chart is configured.&lt;/p>
&lt;/div></description></item><item><title>Configure App-of-Apps</title><link>https://blog.stderr.at/gitopscollection/2024-04-02-configure_app_of_apps/</link><pubDate>Tue, 02 Apr 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-04-02-configure_app_of_apps/</guid><description>&lt;div class="paragraph">
&lt;p>In the article &lt;a href="https://blog.stderr.at/gitopscollection/2024-02-02-setup-argocd/">Install GitOps to the cluster&lt;/a> OpenShift GitOps is deployed using a shell script. This should be the very first installation and the only deployment that is done manually on a cluster. This procedure automatically installs the so-called &lt;strong>App-of-Apps&lt;/strong> named &lt;strong>Argo CD Resources Manager&lt;/strong> which is responsible for all further Argo CD Applications and ApplicationSets. No other configuration should be done manually if possible.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article will demonstrate how to configure the App-of-Apps in an easy and declarative way, using ApplicationSet mainly.&lt;/p>
&lt;/div></description></item><item><title>OpenShift Data Foundation - Noobaa Bucket Data Retention (Lifecycle)</title><link>https://blog.stderr.at/openshift/2024/02/openshift-data-foundation-noobaa-bucket-data-retention-lifecycle/</link><pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2024/02/openshift-data-foundation-noobaa-bucket-data-retention-lifecycle/</guid><description>&lt;div class="paragraph">
&lt;p>Data retention or lifecycle configuration for S3 buckets is done by the S3 provider directly. The provider keeps track and files are automatically rotated after the requested time.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article is a simple step-by-step guide to configure such lifecycle for OpenShift Data Foundation (ODF), where buckets are provided by Noobaa. Knowledge about ODF is assumed, however similar steps can be reproduced for any S3-compliant storage operator.&lt;/p>
&lt;/div></description></item></channel></rss>