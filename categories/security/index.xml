<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Security on TechBlog about OpenShift/Ansible/Satellite and much more</title><link>https://blog.stderr.at/categories/security/</link><description>TechBlog about OpenShift/Ansible/Satellite and much more</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Toni Schmidbauer &amp; Thomas Jungbauer</copyright><lastBuildDate>Tue, 03 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.stderr.at/categories/security/index.xml" rel="self" type="application/rss+xml"/><item><title>Cert-Manager Policy Approver in OpenShift</title><link>https://blog.stderr.at/openshift/2025/06/cert-manager-policy-approver-in-openshift/</link><pubDate>Tue, 03 Jun 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/06/cert-manager-policy-approver-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>One of the most commonly deployed operators in OpenShift environments is the &lt;strong>Cert-Manager Operator&lt;/strong>. It automates the management of TLS certificates for applications running within the cluster, including their issuance and renewal.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The tool supports a variety of certificate issuers by default, including ACME, Vault, and self-signed certificates. Whenever a certificate is needed, Cert-Manager will automatically create a CertificateRequest resource that contains the details of the certificate. This resource is then processed by the appropriate issuer to generate the actual TLS certificate. The approval process in this case is usually fully automated, meaning that the certificate is issued without any manual intervention.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>But what if you want to have more control? What if certificate issuance must follow strict organizational policies, such as requiring a specifc country code or organization name?
This is where the &lt;strong>CertificateRequestPolicy&lt;/strong> resource, a resource provided by the Approver Policy, comes into play.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article walks through configuring the &lt;strong>Cert-Manager Approver Policy&lt;/strong> in OpenShift to enforce granular policies on certificate requests.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before you begin, ensure you have the following:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.16 or higher with cluster-admin access&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cert-Manager Operator installed&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The installation of Cert-Manager itself is discussed in the article: &lt;a href="https://blog.stderr.at/gitopscollection/2024-07-04-managing-certificates-with-gitops/">Managing Certificates using GitOps approach&lt;/a>.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The Cert-Manager Operator does not currently support the Approver Policy by default. You need to install the Approver Policy manually using a Helm Chart. There is a feature request to include the Approver Policy in the Cert-Manager Operator in the future.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adding_approver_policy_chart_as_a_dependency">Adding Approver Policy Chart as a dependency&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Source: &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/cert-manager" target="_blank" rel="noopener">Cert-Manager Deployment&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The above Chart contains the necessary resources to deploy the Cert-Manager itself and Cert-Manager Approver Policy in OpenShift.
To deploy the Approver Policy alongside Cert-Manager, add it as a dependency in your &lt;strong>Chart.yaml&lt;/strong>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">[...]
- name: cert-manager-approver-policy
version: v0.19.0
repository: https://charts.jetstack.io
[...]&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is the official Helm Chart for the Cert-Manager Approver Policy tool provided by Jetstack. The version used in this example is v0.19.0, but you can use a newer version if available.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuration_of_the_helm_chart">Configuration of the Helm Chart&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The initial &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/cert-manager/values.yaml" target="_blank" rel="noopener">values.yaml&lt;/a> file was extended to:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>include the configuration for the Approver Policy Chart&lt;/p>
&lt;/li>
&lt;li>
&lt;p>the configuration for a &lt;strong>CertificateRequestPolicy&lt;/strong> object&lt;/p>
&lt;/li>
&lt;li>
&lt;p>with some specific modifications to the CertManager resource itself&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_disabling_cert_managers_auto_approver">Disabling Cert-Manager’s Auto-Approver&lt;/h3>
&lt;div class="paragraph">
&lt;p>The first step we need to do is to disable the auto-approver of the Cert-Manager. If this is not done, there will be a race condition between the auto-approver and the Approver Policy, which will lead to unexpected results.
These changes are done by:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">cert-manager:
certManager:
enable_patch: true &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
unsupportedConfigOverrides:
controller:
args:
- &amp;#39;--controllers=*,-certificaterequests-approver&amp;#39; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>This enables the patching of the CertManager resource, which tells the chart to overwrite (patch) the automatically generated CertManager resource with the custom configuration.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>This disables the auto-approver Controller of the Cert-Manager.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
As the name suggests, this is currently an unsupported configuration, but it is necessary to disable the auto-approver for the Cert-Manager. In the future versions of the Cert-Manager, this might change, and the auto-approver might be supported out of the box.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In my case, the full CertManager resource looks like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: operator.openshift.io/v1alpha1
kind: CertManager
metadata:
annotations:
name: cluster
spec:
controllerConfig:
overrideArgs: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- &amp;#39;--dns01-recursive-nameservers-only&amp;#39;
- &amp;#39;--dns01-recursive-nameservers=ns-362.awsdns-45.com:53,ns-930.awsdns-52.net:53&amp;#39;
logLevel: Normal
managementState: Managed
operatorLogLevel: Normal
unsupportedConfigOverrides: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
controller:
args:
- &amp;#39;--controllers=*,-certificaterequests-approver&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Settings to support AWS Nameservers for DNS01 challenges.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>This disables the auto-approver Controller of the Cert-Manager.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configuration_of_the_approver_policy">Configuration of the Approver Policy&lt;/h3>
&lt;div class="paragraph">
&lt;p>The second step is to configure the Approver Policy chart. This chart will deploy the necessary resources, most importantly a Deployment that will start the Pods which will process the CertificateRequestPolicy resources later on.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>My configuration for that chart looks like this (some default values are omitted for brevity):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">cert-manager-approver-policy:
crds: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
# This option decides if the CRDs should be installed
# as part of the Helm installation.
enabled: true
# This option makes it so that the &amp;#34;helm.sh/resource-policy&amp;#34;: keep
# annotation is added to the CRD. This will prevent Helm from uninstalling
# the CRD when the Helm release is uninstalled.
# WARNING: when the CRDs are removed, all cert-manager-approver-policy custom resources
# (CertificateRequestPolicy) will be removed too by the garbage collector.
keep: true
# Number of replicas of approver-policy to run.
replicaCount: 1 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
image: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
# Target image repository.
repository: quay.io/jetstack/cert-manager-approver-policy
# Kubernetes imagePullPolicy on Deployment.
pullPolicy: IfNotPresent
tag: v0.19.0
app:
# List of signer names that approver-policy will be given permission to
# approve and deny. CertificateRequests referencing these signer names can be
# processed by approver-policy. Defaults to an empty array, allowing approval
# for all signers.
approveSignerNames: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- &amp;#39;issuers.cert-manager.io/*&amp;#39;
- &amp;#39;clusterissuers.cert-manager.io/*&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>This enables the installation of the CRDs that are required for the Approver Policy.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The number of replicas of the Approver Policy Deployment. In most cases, one replica is enough.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The image configuration for the Approver Policy. The image is pulled from the Jetstack Quay.io repository.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The list of signer names that the Approver Policy will be allowed to approve. In this case, it is configured to allow all issuers and clusterissuers.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The approveSignerNames are, if configured, an important setting, especially if you want to add custom (cluster)issuers. In such a case, you need to add the name of the custom issuer to this list. Otherwise the Approver Policy will not be able to approve the CertificateRequests for that issuer.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_a_certificaterequestpolicy_and_rolebinding">Creating a CertificateRequestPolicy and Role(Binding)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The final step in our configuration is to define a &lt;strong>CertificateRequestPolicy&lt;/strong> resource that will define the policy for the certificate requests. This resource will be processed by the Approver Policy and will determine if a certificate request is approved or denied based on the defined criteria.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following example shows a CertificateRequestPolicy that will:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Allow certificate requests with any common name, DNS names, IP addresses, URIs, and email addresses.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Require DNS names to be set.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Require the subject to contain a specific organization (MyOrganization) and country code (AT).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Allow usages for server auth and client auth.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set constraints for the certificate duration (1h-24h) and private key algorithm (RSA) and size (2048-4096).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Allow all issuers by using an empty selector.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">role: cert-manager-policy:global-approver &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
serviceAccount: cert-manager &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
cert_manager_Namespace: cert-manager &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
policies:
- name: my-approver-policy
enabled: true
allowed:
commonName:
required: false
value: &amp;#34;*&amp;#34;
validations: []
dnsNames: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
required: true
values:
- &amp;#34;*&amp;#34;
validations: []
ipAddresses:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
uris:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
emailAddresses:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
# isCA: false
subject:
organizations: &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
required: true
values:
- &amp;#34;MyOrganization&amp;#34;
validations:
- rule: self.matches(&amp;#34;MyOrganization&amp;#34;)
message: Organization must be MyOrganization
countries:
required: true
values:
- AT
validations:
- rule: self.matches(&amp;#34;AT&amp;#34;)
message: Country code must be AT
usages:
- &amp;#34;server auth&amp;#34;
- &amp;#34;client auth&amp;#34;
constraints: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
minDuration: 1h
maxDuration: 24h
privateKey:
algorithm: RSA
minSize: 2048
maxSize: 4096
selector:
issuerRef: {} &lt;i class="conum" data-value="7">&lt;/i>&lt;b>(7)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The role that is used to approve the certificate requests. This role must be created in the OpenShift cluster and must have the necessary permissions to approve certificate requests.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The service account that is used by the Approver Policy to process the certificate requests. This service account must have the necessary permissions to access the CertificateRequest resources.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The namespace where the Cert-Manager is deployed. This is usually the &lt;code>cert-manager&lt;/code> namespace, but you can change it if you have a different namespace.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The DNS names are required to be set for the certificate request.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The subject must contain the organization MyOrganization and the country code AT.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>The constraints for the certificate request, such as the minimum and maximum duration, private key algorithm, and size.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="7">&lt;/i>&lt;b>7&lt;/b>&lt;/td>
&lt;td>The selector is empty, which means that the policy applies to all issuers. If you want to limit the policy to specific issuers, you can specify the issuerRef here.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_rendered_certificaterequestpolicy_and_rolebinding">Rendered CertificateRequestPolicy and Role(Binding)&lt;/h3>
&lt;div class="paragraph">
&lt;p>The above configuration will create a CertificateRequestPolicy resource that looks like this:
&lt;div class="expand">
&lt;div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
&lt;i style="font-size:x-small;" class="fas fa-chevron-right">&lt;/i>
&lt;span>
&lt;a>Expand me...&lt;/a>
&lt;/span>
&lt;/div>
&lt;div class="expand-content" style="display: none;">
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
# Source: cert-manager/templates/ClusterRole-Approver-Policy-approving.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: &amp;#34;cert-manager-policy:global-approver&amp;#34;
labels:
helm.sh/chart: cert-manager-2.0.0
app.kubernetes.io/name: cert-manager
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
rules:
- verbs:
- use
apiGroups:
- policy.cert-manager.io
resources:
- certificaterequestpolicies
resourceNames:
- my-approver-policy
---
# Source: cert-manager/charts/cert-manager-approver-policy/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
labels:
app.kubernetes.io/name: cert-manager-approver-policy
helm.sh/chart: cert-manager-approver-policy-v0.19.0
app.kubernetes.io/instance: release-name
app.kubernetes.io/version: &amp;#34;v0.19.0&amp;#34;
app.kubernetes.io/managed-by: Helm
name: cert-manager-approver-policy
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: cert-manager-approver-policy
subjects:
- kind: ServiceAccount
name: cert-manager-approver-policy
namespace: default
---
# Source: cert-manager/templates/CertificateRequestPolicy.yaml
apiVersion: policy.cert-manager.io/v1alpha1
kind: CertificateRequestPolicy
metadata:
name: my-approver-policy
annotations:
argocd.argoproj.io/sync-wave: &amp;#34;10&amp;#34;
labels:
helm.sh/chart: cert-manager-2.0.0
app.kubernetes.io/name: cert-manager
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
spec:
allowed:
commonName:
required: false
value: &amp;#34;*&amp;#34;
validations: []
dnsNames:
required: true
values:
- &amp;#34;*&amp;#34;
validations: []
emailAddresses:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
ipAddresses:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
uris:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
isCA: false
subject:
organizations:
required: true
values:
- &amp;#34;MyOrganization&amp;#34;
validations:
- rule: &amp;#34;self.matches(\&amp;#34;MyOrganization\&amp;#34;)&amp;#34;
message: &amp;#34;Organization must be MyOrganization&amp;#34;
countries:
required: true
values:
- &amp;#34;AT&amp;#34;
validations:
- rule: &amp;#34;self.matches(\&amp;#34;AT\&amp;#34;)&amp;#34;
message: &amp;#34;Country code must be AT&amp;#34;
organizationalUnits:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
localities:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
provinces:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
streetAddresses:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
postalCodes:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
serialNumber:
required: false
value: &amp;#34;*&amp;#34;
validations: []
usages:
- &amp;#34;server auth&amp;#34;
- &amp;#34;client auth&amp;#34;
constraints:
minDuration: 1h
maxDuration: 24h
privateKey:
algorithm: RSA
minSize: 2048
maxSize: 4096
selector:
issuerRef: {}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>One important note is about the ClusterRole and ClusterRoleBinding that are created by the Helm Chart. The role looks like the following and is required to allow the Approver Policy to approve certificate requests. This small bit, puzzled me for a while:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">rules:
- verbs:
- use
apiGroups:
- policy.cert-manager.io
resources:
- certificaterequestpolicies
resourceNames:
- my-approver-policy&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the above configuration we are good to go. The Helm Chart can be deployed to the OpenShift cluster (for example, using Argo CD), and the CertificateRequestPolicy will be created automatically.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A new Pod is running in the &lt;strong>cert-manager&lt;/strong> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">❯ oc get pods -n cert-manager | grep approver
NAME READY STATUS RESTARTS AGE
cert-manager-approver-policy-xxxxx 1/1 Running 0 XXm &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The Pod &lt;code>cert-manager-approver-policy-xxxxx&lt;/code> is the Pod that is responsible for processing the CertificateRequestPolicy resources.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_testing_the_policy">Testing the Policy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="sect2">
&lt;h3 id="_test_1_valid_certificate_request">Test 1 - Valid Certificate Request&lt;/h3>
&lt;div class="paragraph">
&lt;p>Now it is time to test the policy. We need to create a Certificate and monitor the output of our approval pod.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a reminder, the policy we created requires the following:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>The subject must contain the organization MyOrganization&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The subject must contain the country code AT.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The keysize must be at least 2048 bits. (max 4096 bits)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The duration must be between 1 hour and 24 hours.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The usage must be server auth or client auth.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s create this example Certificate in the &lt;code>myproject&lt;/code> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: test-certificate1
namespace: myproject
spec:
dnsNames:
- test1.apps.ocp.aws.ispworld.at
duration: 24h
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod
privateKey:
algorithm: RSA
encoding: PKCS1
rotationPolicy: Always
secretName: test1
subject:
organizations:
- MyOrganization
countries:
- AT
usages:
- server auth&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In the log of the Approver Policy Pod, we should see the following output:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">time=2025-06-03T16:07:58.656Z level=DEBUG+3 msg=&amp;#34;Approved by CertificateRequestPolicy: \&amp;#34;my-approver-policy\&amp;#34;&amp;#34; logger=controller-manager/events type=Normal object=&amp;#34;{Kind:CertificateRequest Namespace:myproject Name:test-certificate1-1 [...]}&amp;#34; reason=Approved&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This indicates that the CertificateRequest was approved by the Approver Policy. The policy was able to validate the subject, keysize, duration, and usage of the certificate request and approved it accordingly.
The certificate has been created successfully in the &lt;strong>myproject&lt;/strong> namespace, and the secret &lt;strong>test1&lt;/strong> contains the TLS certificate and private key.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">❯ oc get secret test1 -n myproject -o yaml
apiVersion: v1
data:
tls.crt: ...
tls.key: ...
kind: Secret
metadata:
labels:
controller.cert-manager.io/fao: &amp;#34;true&amp;#34;
name: test1
namespace: myproject
type: kubernetes.io/tls&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_test_2_invalid_certificate_request">Test 2 - Invalid Certificate Request&lt;/h3>
&lt;div class="paragraph">
&lt;p>That was easy, but what happens if we create a CertificateRequest that does not meet the policy requirements? Let’s try to create a Certificate without the required organization or a wrong country code:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: test-certificate2
namespace: myproject
spec:
dnsNames:
- test2.apps.ocp.aws.ispworld.at
duration: 24h
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod
privateKey:
algorithm: RSA
encoding: PKCS1
rotationPolicy: Always
secretName: test2
subject: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
countries:
- XX
usages:
- server auth&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The subject does not contain the required organization MyOrganization and the country code is set to XX, which is not allowed by the policy.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will lead to the following error in the log of the Approver Policy Pod:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">time=2025-06-03T16:16:02.233Z level=DEBUG+3 msg=&amp;#34;No policy approved this request: [my-approver-policy: [spec.allowed.subject.organizations.required: Required value: true, spec.allowed.subject.countries.values: Invalid value: []string{\&amp;#34;XX\&amp;#34;}: AT, spec.allowed.subject.countries.validations[0]: Invalid value: \&amp;#34;XX\&amp;#34;: Country code must be AT]]&amp;#34; logger=controller-manager/events type=Warning object=&amp;#34;{Kind:CertificateRequest Namespace:myproject Name:test-certificate2-1 ...&amp;#34; reason=Denied&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>It complains that the subject does not meet the policy requirements and therefore the CertificateRequest was denied.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_ok_we_have_a_policy_but_whats_next">Ok we have a policy, but whats next?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The above example shows how the Cert-Manager Approver Policy can be configured and deployed, even if it is not yet supported by the Cert-Manager Operator. However, we only scratched the surface of what is possible with the Approver Policy.
You can create more complex policies that include additional validations, such as checking the validity of the DNS names, IP addresses, or URIs. You can also create policies that require specific email addresses or organizational units in the subject.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can even create fine-grained policies that apply to specific issuers or namespaces by using the &lt;code>selector&lt;/code> field in the CertificateRequestPolicy resource. This allows you to create policies that are tailored to your specific requirements and use cases.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The best references can be found here:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Official documentation: &lt;a href="https://cert-manager.io/docs/policy/approval/approver-policy/" target="_blank" rel="noopener">Cert-Manager Approver Policy&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Example Policies: &lt;a href="https://github.com/cert-manager/approver-policy/tree/main/docs/examples" target="_blank" rel="noopener">Cert-Manager Approver Policy Examples&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The Cert-Manager Approver Policy is a powerful tool that allows you to implement custom policies for certificate requests in OpenShift. It provides a way to control the issuance of TLS certificates based on specific criteria, such as the subject, key size, duration, and usage of the certificate.
While not yet officially supported by the Cert-Manager Operator, it can be easily integrated into your OpenShift environment using a Helm Chart. Future support is currently being discussed, and it is expected that the Approver Policy will be included in the Cert-Manager Operator in the future.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Single log out from Keycloak and OpenShift</title><link>https://blog.stderr.at/openshift/2025/05/single-log-out-from-keycloak-and-openshift/</link><pubDate>Thu, 22 May 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/05/single-log-out-from-keycloak-and-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>The following 1-minute article is a follow-up to my &lt;a href="https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/">previous article&lt;/a> about how to use Keycloak as an authentication provider for OpenShift. In this article, I will show you how to configure Keycloak and OpenShift for Single Log Out (SLO). This means that when you log out from Keycloak, you will also be logged out from OpenShift automatically. This requires some additional configuration in Keycloak and OpenShift, but it is not too complicated.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following prerequisites are required to follow this article:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.16 or higher with cluster-admin privileges&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Keycloak installed and configured, as described in the &lt;a href="https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/">Step by Step - Using Keycloak Authentication in OpenShift&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_keycloak_configuration">Keycloak Configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Configure the logout URL in Keycloak. This is done by adding a new &lt;strong>Valid post logout redirect URIs&lt;/strong> to the Keycloak client configuration. In this case, we want to call the OpenShift logout URL.
Which is: &lt;strong>&lt;a href="https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/logout" class="bare">https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/logout&lt;/a>&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is done in the client settings:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/set-logout-url.png" alt="Set Logout URL"/>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_openshift_configuration">OpenShift Configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now we need to configure OpenShift to use the logout URL. This is done by adding a new &lt;strong>Post Logout Redirect URI&lt;/strong> to the OpenShift Console configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Modify the existing Console resource named cluster and add the logoutRedirect parameter to the authentication section.
The important pieces of the logout URL are the &lt;strong>client_id&lt;/strong> and the &lt;strong>post_logout_redirect_uri&lt;/strong>. The client ID must be the same as the Keycloak client ID, and the post logout redirect URI must be the OpenShift logout URL.
(Also change the &amp;lt;keycloakURL&amp;gt; and &amp;lt;realm&amp;gt; to your Keycloak URL and realm name.)&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Actually, instead of &lt;strong>client_id&lt;/strong>, the &lt;strong>id_token_hint&lt;/strong> should be used. But OpenShift does not store the token, so we are using the client ID instead.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: config.openshift.io/v1
kind: Console
metadata:
name: cluster
spec:
authentication:
logoutRedirect: &amp;#39;https://&amp;lt;keycloakURL&amp;gt;/realms/&amp;lt;realm&amp;gt;/protocol/openid-connect/logout?client_id=&amp;lt;realm&amp;gt;&amp;amp;post_logout_redirect_uri=https://console-openshift-console.apps.ocp.aws.ispworld.at&amp;#39; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The logout URL for OpenShift. This is the URL that will be called when you log out from Keycloak. The URL must contain the client ID and the post logout redirect URI (console of OpenShift).&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Wait a few moments until the OpenShift Console Operator applies the new configuration.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_testing_the_configuration">Testing the configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now that the configuration is done, we can test the Single Log Out functionality.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>We are logged into OpenShift already as user &lt;strong>testuser&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/logged-in.png" alt="Logged in to OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Now we log out from OpenShift using the &lt;strong>Log out&lt;/strong> button in the upper right corner.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/logging-out.png" alt="Log out from OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>This will redirect us to the Keycloak logout page where we need to confirm the logout.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/keycloak-logout.png?width=420" alt="Keycloak Logout"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>This will log us out from Keycloak and redirect us back to the OpenShift logout page.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/logged-out.png?width=420" alt="Logged out from OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is it. You are now logged out from both Keycloak and OpenShift. You can also check the Sessions in Keycloak to see that the session for the user is terminated.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As promised, this was a short article about how to configure Keycloak and OpenShift for Single Log Out. This is a beneficial feature if you want to ensure that users are logged out from all applications when they log out from Keycloak. It is also a good security practice to ensure that users are logged out from all applications when they are done using them.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Step by Step - Using Keycloak Authentication in OpenShift</title><link>https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/</link><pubDate>Sat, 17 May 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>I was recently asked about how to use Keycloak as an authentication provider for OpenShift. How to install Keycloak using the Operator and how to configure Keycloak and OpenShift so that users can log in to OpenShift using OpenID.
I have to admit that the exact steps are not easy to find, so I decided to write a blog post about it, describing each step in detail.
This time I will not use GitOps, but the OpenShift and Keycloak Web Console to show the steps, because before we put it into GitOps, we need to understand what is actually happening.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article tries to explain every step required so that a user can authenticate to OpenShift using Keycloak as an Identity Provider (IDP) and that Groups from Keycloak are imported into OpenShift. This article does not cover a production grade installation of Keycloak, but only a test installation, so you can see how it works. For production, you might want to consider a proper database (maybe external, but at least with a backup), high availability, etc.).&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following prerequisites are required to follow this article:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.16 or higher with cluster-admin privileges&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_keycloak_operator">Installing Keycloak Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The very first step is to install the Keycloak Operator. This can be done using the OpenShift Web Console or the CLI or GitOps. I will show the steps using the OpenShift Web Console.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Installing the Keycloak Operator via GitOps can be seen in this &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/setup-rh-build-of-keycloak" target="_blank" rel="noopener">GitHub repository&lt;/a>. By the time you read this article, this repository will install and configure a Keycloak instance automatically using a local &lt;strong>EXAMPLE&lt;/strong> Postgres database. It does not yet import any Realm or additional configuration, but I will try to add this in the future when time allows. Oh, and it is just a demo and not production ready, so please do not use it in production.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Log in to the OpenShift Web Console as a user with cluster-admin privileges.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the OpenShift Web Console, navigate to the Operators → OperatorHub.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the OperatorHub, search for &lt;strong>Red Hat build of Keycloak&lt;/strong> and select the Operator from the list.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/search-operator.png?width=320" alt="Search Keycloak Operator"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Install the latest version of the Keycloak Operator.&lt;/p>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
You can keep the default settings for the installation, but I recommend using a specific namespace. In this example, I will use the namespace &lt;code>keycloak&lt;/code> for the installation.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/install-operator.png?width=840" alt="Install Keycloak Operator"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Press the &lt;strong>Install&lt;/strong> button to install the Keycloak Operator. After a few minutes, the Keycloak Operator should be installed and running in the OpenShift cluster. You can check the status of the Operator in the &lt;strong>Installed Operators&lt;/strong> view.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/installed-operator.png" alt="Installed Keycloak Operator"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_create_a_local_example_postgres_database">Create a local example Postgres Database&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Demo only! This is not production ready and should not be used in production.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a next step, we need to create a local Postgres database for Keycloak. Secrets are used to store the database credentials, and a simple StatefulSet is used to create the database. The database will be created in the same namespace as the Keycloak Operator.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>First, let’s create a Secret for the database credentials. In OpenShift select the &lt;strong>keycloak&lt;/strong> namespace and navigate to the &lt;strong>Secrets&lt;/strong> view. Create a new Secret with the following test configuration:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Secret
apiVersion: v1
metadata:
name: keycloak-db-secret
namespace: keycloak
stringData:
password: thisisonly4testingNOT4prod &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
username: testuser
type: Opaque&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The password for the database. This is just a test password and should not be used in production.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Next, we need to create a StatefulSet for the Postgres database, again in the &lt;strong>keycloak&lt;/strong> namespace.
Again, as I cannot mention that enough, this is just a test configuration and should not be used in production.&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
name: postgresql-db
namespace: keycloak
spec:
serviceName: postgresql-db-service
selector:
matchLabels:
app: postgresql-db
replicas: 1 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
template:
metadata:
labels:
app: postgresql-db
spec:
containers:
- name: postgresql-db
image: postgres:15 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
volumeMounts:
- mountPath: /data
name: psql
env: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
- name: POSTGRES_USER
value: testuser
- name: POSTGRES_PASSWORD
value: thisisonly4testingNOT4prod
- name: PGDATA
value: /data/pgdata
- name: POSTGRES_DB
value: keycloak
volumeClaimTemplates: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- metadata:
name: psql
spec:
accessModes: [ &amp;#34;ReadWriteOnce&amp;#34; ]
storageClassName: &amp;#34;gp3-csi&amp;#34;
resources:
requests:
storage: 10Gi&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The number of replicas for the database. In this example, we are using a single replica.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The image for the database, postgres version 15 in this example.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The environment variables for the database. The username and password are the same as in the Secret we created before, and &lt;strong>clear text&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The volume for the database. In this example, the StatefulSet uses a volume claim template to create a volume with the size of 10 GB for the database. The volume is created using the &lt;code>gp3-csi&lt;/code> storage class. You can use any other storage class that is available in your OpenShift cluster or even remove this line and use the default class instead.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Finally, we need to create a Service for the database so that the Keycloak Operator can access the database. Again, in the &lt;strong>keycloak&lt;/strong> namespace.&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
name: postgres-db
namespace: keycloak
spec:
selector:
app: postgresql-db &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
type: LoadBalancer
ports:
- port: 5432
targetPort: 5432&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The selector for the Service. This must match the label of the StatefulSet we created before.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_a_keycloak_instance">Creating a Keycloak Instance&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now that the Keycloak Operator is installed and our example database is running, we can create a Keycloak instance.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the OpenShift Web Console, navigate to the &lt;strong>Installed Operators&lt;/strong> view and select the Keycloak Operator. (Maybe you need to select the keycloak namespace first.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the Keycloak Operator view, create a new instance of &lt;strong>Keycloak&lt;/strong> and switch to the &lt;strong>YAML&lt;/strong> view.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-keycloak-instance.png?width=550" alt="Create Keycloak Instance"/>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The fun part here is that the YAML example the Operator provides is actually &lt;strong>wrong and does not work&lt;/strong>. Something that kept me busy for a while.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Replace the YAML with the following configuration:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: k8s.keycloak.org/v2alpha1
kind: Keycloak
metadata:
name: keycloak &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: keycloak
labels:
app: sso
spec:
db: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
host: postgres-db
passwordSecret:
key: password
name: keycloak-db-secret
usernameSecret:
key: username
name: keycloak-db-secret
vendor: postgres
hostname: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
hostname: sso.apps.ocp.aws.ispworld.at
http: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
tlsSecret: keycloak-certificate
instances: 1 &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The name and the namespace of the Keycloak instance.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The database configuration. In this example, we are using a local Postgres database. You can also use an external database, but you need to configure the connection string accordingly.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Hostname of our Keycloak instance.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The TLS secret for the Keycloak instance. You need to create a TLS secret with the certificate and key for the hostname. This is where the example YAML is wrong. It tries to put &lt;em>tlsSecret&lt;/em> under &lt;em>spec&lt;/em>, but it should be under &lt;em>http&lt;/em>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The number of instances of Keycloak. In this example, we are using a single instance.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_what_about_the_ssl_certificate">What about the SSL Certificate?&lt;/h3>
&lt;div class="paragraph">
&lt;p>The Keycloak Operator does not create a certificate for the Keycloak instance. You need to create a certificate manually and store it in a secret. The Operator will use this secret to create the TLS certificate for the Keycloak instance.
In the example above we are referencing a secret called &lt;code>keycloak-certificate&lt;/code> in the &lt;code>keycloak&lt;/code> namespace. This secret was created using the &lt;strong>Cert Manager Operator&lt;/strong>. For example, you can use the following configuration to create a certificate for the Keycloak instance.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: keycloak-certificate
namespace: keycloak
spec:
dnsNames:
- sso.apps.ocp.aws.ispworld.at &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
duration: 2160h0m0s
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
privateKey:
algorithm: RSA
encoding: PKCS1
rotationPolicy: Always
secretName: keycloak-certificate &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The DNS name the Certificate is valid for. This should be the same as the hostname in the Keycloak instance.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The issuer for the certificate. In this example, we are using the &lt;strong>LetsEncrypt&lt;/strong> ClusterIssuer.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The name of the secret where the certificate is stored. This should be the same as the TLS secret in the Keycloak instance.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I strongly recommend using the &lt;strong>Cert Manager Operator&lt;/strong> to automatically request and approve the certificate. However, if you do not have this automation in place, you can use a self-signed certificate. This certificate must be created manually and stored as a secret.
For example, you can use the following command to create a self-signed certificate and store it in a secret:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &amp;#34;/CN=test.keycloak.org/O=Test Keycloak./C=US&amp;#34;
oc create secret -n keycloak tls keycloak-certificate2 --cert=tls.crt --key=tls.key&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_login_in_to_keycloak">Login in to Keycloak&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Once the Keycloak instance is created and all Pods (1) are running, you can log in to the Keycloak Admin Console using the following URL: &lt;a href="https://sso.apps.ocp.aws.ispworld.at" class="bare">https://sso.apps.ocp.aws.ispworld.at&lt;/a>
This is the hostname we configured in the keycloak instance.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To authenticate, you need to fetch the initial password for the admin user. This password is stored in a secret called &lt;strong>keycloak-initial-admin&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can use the following command to fetch the password:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/keycloak-initial-admin -n keycloak --to=-&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>or you can use the OpenShift Web Console to view the secret.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Once authenticated, you should see the Keycloak Admin Console:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/keycloak-initial-login.png" alt="Keycloak Admin Console"/>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The first thing you should do is to change the password for the admin user. I trust you know how to do this :)
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_keycloak_to_be_used_by_openshift">Configure Keycloak to be used by OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The next steps are to configure Keycloak to be used as an Identity Provider (IDP) for OpenShift. This is done by creating a new Realm and a new Client in Keycloak. The following steps will show you the minimum configuration required to use Keycloak as an IDP for OpenShift. It does not cover all the options and features of Keycloak (and there are a lot), but it should be enough to get you started.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The full documentation for Keycloak can be found at &lt;a href="https://docs.redhat.com/en/documentation/red_hat_build_of_keycloak/" target="_blank" rel="noopener">Keycloak Documentation&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_create_a_new_realm_and_client">Create a new Realm and Client&lt;/h3>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the Realm Dropdown (upper left corner) select &lt;strong>Create new Realm&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-new-realm.png?width=420" alt="Create new Realm"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a new Realm called &lt;strong>openshift&lt;/strong> (Enabled, of course) and press &lt;strong>Create&lt;/strong>.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-new-realm-openshift.png?width=1024" alt="Create new Realm OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Now, inside the Realm &lt;strong>openshift&lt;/strong>, select &lt;strong>Clients&lt;/strong> and press the &lt;strong>Create client&lt;/strong> button.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-new-client.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a new Client with the following configuration. Name it, for example, &lt;strong>openshift&lt;/strong>.&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Be sure the &lt;strong>Client type&lt;/strong> is set to &lt;strong>OpenID Connect&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-client-screen-1.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Enable &lt;strong>Client authentication&lt;/strong>. The rest can be left as default.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-client-screen-2.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Add the following redirect URL and Web origin and press &lt;strong>Save&lt;/strong>.:&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Redirect URL: &lt;a href="https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/oauth2callback/*" class="bare">https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/oauth2callback/*&lt;/a> …​ redirecting everything under oauth2callback&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Web origin: &lt;a href="https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;" class="bare">https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;&lt;/a>;&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-client-screen-3.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_create_a_new_user_and_a_group">Create a new User and a Group&lt;/h3>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the &lt;strong>openshift&lt;/strong> Realm, select &lt;strong>Groups&lt;/strong>, press the &lt;strong>Create group&lt;/strong> button and create a group called, for example, &lt;strong>openshift-users&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the &lt;strong>openshift&lt;/strong> Realm, select &lt;strong>Users&lt;/strong> and press the &lt;strong>Add user&lt;/strong> button. Be sure to join the group &lt;strong>openshift-users&lt;/strong>.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-user.png?width=1024" alt="Create new User"/>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>No more configuration is needed for the (test) user at this point.&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Set the password for the user. Select the user we have just created, select the &lt;strong>Credentials&lt;/strong> tab and press &lt;strong>Set password&lt;/strong>. Set the password to &lt;strong>Temporary&lt;/strong> to force the user to change the password on the first login.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-user-password.png?width=1024" alt="Set password for new User"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configure_a_group_mapper">Configure a Group Mapper&lt;/h3>
&lt;div class="paragraph">
&lt;p>The above configuration is enough to log in to OpenShift using Keycloak as an IDP (except that we need to configure OpenShift itself). However, we also want to import the groups from Keycloak into OpenShift. This configuration was not easy to find, and is done by creating a Group Mapper in Keycloak.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the &lt;strong>openshift&lt;/strong> Realm, select &lt;strong>Clients scopes&lt;/strong> and select the &lt;strong>profile&lt;/strong> scope:&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes.png?width=1024" alt="Client Scopes"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Mappers&lt;/strong> tab and Add a mapper &lt;strong>By configuration&lt;/strong>:&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes-mappers.png?width=1024" alt="Client Scopes Mappers"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Group Membership&lt;/strong> mapper.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes-new-mapper.png?width=1024" alt="Client Scopes Create Group Membership Mapper"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Configure the mapper with the following settings:&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Mapper Type: &lt;strong>Group Membership&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Name: &lt;strong>openshift-groups&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Token Claim Name: &lt;strong>groups&lt;/strong> → This is the name of the claim that will be used to map the groups from Keycloak to OpenShift.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full group path: &lt;strong>OFF&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add to ID token: &lt;strong>ON&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add to access token: &lt;strong>ON&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add to userinfo: &lt;strong>ON&lt;/strong>&lt;/p>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Disable the &lt;strong>Full groupo path&lt;/strong> option, otherwise the group name will be prefixed with a &lt;strong>/&lt;/strong>. Moreover, be sure that you set the &lt;strong>Token Claim Name&lt;/strong> correctly to the claim we will configure in OpenShift (groups).
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes-new-mapper-2.png?width=1024" alt="Client Scopes Create Group Membership Mapper"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_openshift_to_use_keycloak_as_an_idp">Configure OpenShift to use Keycloak as an IDP&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now that Keycloak is configured, we need to configure OpenShift to use Keycloak as an IDP. This is done by creating a new Identity Provider in OpenShift.
Before we do this, we need to create a new OAuth client secret for OpenShift in the Namespace &lt;strong>openshift-config&lt;/strong> The secret will be used to authenticate OpenShift with Keycloak.
When we created the keycloak client, we enabled the &lt;strong>Client authentication&lt;/strong> option. This created a client secret we need to use in OpenShift.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In Keycloak, select the &lt;strong>openshift&lt;/strong> client and select the &lt;strong>Credentials&lt;/strong> tab and copy the &lt;strong>Client secret&lt;/strong>.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/keycloak-client-secret.png?width=1024" alt="Keycloak Client Secret"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Back in OpenShift, navigate to the &lt;strong>openshift-config&lt;/strong> namespace and select the &lt;strong>Secrets&lt;/strong> view. Create a new secret with the following configuration:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Secret
apiVersion: v1
metadata:
name: openid-client-secret
namespace: openshift-config
stringData:
clientSecret: &amp;lt;you client secret from Keycloak&amp;gt; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
type: Opaque&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The client secret we copied from Keycloak. This is the secret we will use to authenticate OpenShift with Keycloak.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Now we need to create a new Identity Provider in OpenShift. In the OpenShift Web Console, navigate to the &lt;strong>Administration&lt;/strong> → &lt;strong>Cluster Settings&lt;/strong> → &lt;strong>Configuration&lt;/strong> search for &lt;strong>OAuth&lt;/strong> and select the YAML view.
Here the following must be created or added to an existing OAuth configuration:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">[...]
spec:
identityProviders:
- mappingMethod: claim
name: rhsso &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
openID:
claims: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
email:
- email
groups:
- groups
name:
- name
preferredUsername:
- preferred_username
clientID: openshift &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
clientSecret:
name: openid-client-secret &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
extraScopes: []
issuer: &amp;#39;https://sso.apps.ocp.aws.ispworld.at/realms/openshift&amp;#39; &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
type: OpenID &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The name of the Identity Provider. This is the name that will be displayed in the OpenShift login screen.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The claims that will be used to map the user to OpenShift. In this example, we are using the email, groups, name and preferred_username claims from Keycloak.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The client ID we created in Keycloak. This is the client ID that will be used to authenticate OpenShift with Keycloak.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The name of the secret we created in the &lt;strong>openshift-config&lt;/strong> namespace.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The issuer URL for Keycloak. It is &amp;lt;hostname of keycloak&amp;gt;/realms/&amp;lt;realm name&amp;gt;.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>The type of the Identity Provider. In this example, we are using OpenID Connect.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The above configuration will trigger a restart of the authentication Pods in OpenShift. Wait until all Pods have been restarted and the Operator is running again.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/restart-oauth.png" alt="OpenShift OAuth Restart"/>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_test_the_configuration">Test the configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now it is time to test the configuration. Open a new browser window (or incognito window), navigate to the OpenShift login page and try to log in using Keycloak as an IDP &lt;strong>rhsso&lt;/strong>.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
If you have multiple IDPs configured, it is important to select the correct IDP. &lt;strong>rhsso&lt;/strong> in this example.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>By selecting the &lt;strong>rhsso&lt;/strong> Identity Provider, you should be redirected to the Keycloak login page.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-keycloak-login.png?width=1024" alt="OpenShift Login Page"/>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
If you selected &lt;strong>Temporary&lt;/strong> for the password, you will now be asked to change the password on the first login.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>After a successful login, you should see the OpenShift Web Console, and you should be logged in as the user you created in Keycloak.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-web-console.png?width=1024" alt="OpenShift Web Console"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>In OpenShift you will see the user created. In the Identities column you will see that it starts with &lt;strong>rhsso&lt;/strong>, indicating that the user was authenticated using the &lt;strong>rhsso&lt;/strong> Identity Provider.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-user.png" alt="OpenShift User"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>And finally, if you navigate to &lt;strong>User Management&lt;/strong> → &lt;strong>Groups&lt;/strong>, you should see the group &lt;strong>openshift-users&lt;/strong> that was created in Keycloak.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-groups.png" alt="OpenShift Group"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this article, I have shown how to install and configure Keycloak in OpenShift for authentication. I have also shown how to configure Keycloak to be used as an Identity Provider for OpenShift and how to import groups from Keycloak into OpenShift.
The biggest two challenges were to find the correct callback URL and to configure the Group Mapper in Keycloak. The rest was pretty straightforward.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>What’s next? With the groups now mapped into OpenShift, you can now create RoleBindings and ClusterRoleBindings to assign the appropriate roles to the users in Keycloak. This is quite nice, as I do not need to create Users manually in OpenShift anymore (previously used HTPasswd) but instead use Keycloak as the single source of truth for users and groups. All I need to configure is the RoleBindings and ClusterRoleBindings in OpenShift.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I hope this article was helpful and you learned something new. Remember, this is just a test configuration. In production you should use a proper database and keycloak setup (high Availability, backup, etc.).
If you have any questions or comments, please feel free to reach out to me on LinkedIn, Email or via GitHub issues.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_references">References&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/red_hat_build_of_keycloak/" target="_blank" rel="noopener">Keycloak Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.badgerops.net/keycloak-open-shift/" target="_blank" rel="noopener">Keycloak &amp;amp; Open Shift&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/setup-rh-build-of-keycloak" target="_blank" rel="noopener">Set up Keycloak using GitOps (No Realm/Client configuration yet)&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Introducing AdminNetworkPolicies</title><link>https://blog.stderr.at/openshift/2024/11/introducing-adminnetworkpolicies/</link><pubDate>Wed, 06 Nov 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2024/11/introducing-adminnetworkpolicies/</guid><description>&lt;div class="paragraph">
&lt;p>Classic Kubernetes/OpenShift offer a feature called NetworkPolicy that allows users to control the traffic to and from their assigned Namespace.
NetworkPolicies are designed to give project owners or tenants the ability to protect their own namespace. Sometimes, however, I worked with customers where the
cluster administrators or a dedicated (network) team need to enforce these policies.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Since the NetworkPolicy API is namespace-scoped, it is not possible to enforce policies across namespaces. The only solution was to create custom (project) admin and edit
roles, and remove the ability of creating, modifying or deleting NetworkPolicy objects. Technically, this is possible and easily done. But shifts the whole network security to cluster administrators.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Luckily, this is where &lt;strong>AdminNetworkPolicy&lt;/strong> (ANP) and &lt;strong>BaselineAdminNetworkPolicy&lt;/strong> (BANP) comes into play.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adminnetworkpolicy_anp_and_baselineadminnetworkpolicy_banp">AdminNetworkPolicy (ANP) and BaselineAdminNetworkPolicy (BANP)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
This article demonstrates the configuration of the new AdminNetworkPolicy and BaselineAdminNetworkPolicy objects using the Helm Chart &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/admin-networkpolicies" target="_blank" rel="noopener">admin-networkpolicies&lt;/a>. The NetworkPolicy object is not covered in this article.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>ANP and BANP are designed for cluster administrators to protect the entire cluster by creating &lt;strong>cluster-scoped policies&lt;/strong>. They are not replacing NetworkPolicies,
but instead create a tier model and can be used together. Administrators can use ANPs to enforce non-overridable policies that take precedence over NetworkPolicy objects.
Administrators can use BANP to set up and enforce optional cluster-scoped network policy rules that are overridable by users using NetworkPolicy objects when necessary.
When used together, ANP, BANP, and network policy can achieve full multi-tenant isolation that administrators can use to secure their cluster.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The three resources create a 3-Tier Access Control List (ACL) that is evaluated in descending order:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Tier 1 - AdminNetworkPolicy (ANP): If the traffic matches an &lt;strong>allow&lt;/strong> or &lt;strong>deny&lt;/strong> rule, then any existing
NetworkPolicy and BaselineAdminNetworkPolicy (BANP) objects in the cluster are skipped from evaluation. If a &lt;strong>pass&lt;/strong> rule is matched, then the evaluation is handed over to
the next tier (NetworkPolicy). This means, that Cluster Administrators can enforce policies that cannot be overwritten by users (allow/deny rules) or pass the evaluation to the Network Policy,
where the project owners can decide further.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tier 2 - NetworkPolicy (NP): If the traffic passed the ANP then the NetworkPolicy is evaluating the traffic. The NetworkPolicy resources are controlled by the project owners by default.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tier 3 - BaselineAdminNetworkPolicy (BANP): If the traffic passed the ANP and the NetworkPolicy, then the BANP is evaluating the traffic.
These objects are controlled by the cluster administrators again and are cluster scoped. There can only be one BANP (named &amp;#34;default&amp;#34;) configured on the cluster.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adminnetworkpolicy">AdminNetworkPolicy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>An AdminNetworkPolicy (ANP) is a cluster-scoped resource, that allow cluster administrators to secure the network traffic &lt;strong>before&lt;/strong> NetworkPolicies in the namespaces are evaluated.
These rules cannot be overwritten by project owners or developers and allow the administrators to enforce the security. Use cases could be, for example:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>You want to enforce only specific egress endpoints (e.g. only allow traffic to the specific database servers)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You want to be sure that traffic from OpenShift monitoring is always allowed&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You want to allow the management of NetworkPolicies to project owners and do not want to take care for them or during the onboarding.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The ANP allows cluster administrators to define:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A priority value that determines the order of its evaluation. The lower the value the higher the precedence.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A set of pods that consists of a set of namespaces or namespace on which the policy is applied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of ingress rules to be applied for all ingress traffic towards the subject.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of egress rules to be applied for all egress traffic from the subject.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adminnetworkpolicy_actions_for_rules">AdminNetworkPolicy Actions for Rules&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The AdminNetworkPolicy allows three actions for the rules:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Allow&lt;/strong>: The traffic is allowed, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Deny&lt;/strong>: The traffic is denied, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pass&lt;/strong>: The traffic is passed to the next tier (NetworkPolicy).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_subject_of_a_policy">Subject of a Policy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In any ANP (or BANP) a &lt;strong>subject&lt;/strong> can be defined and they specify the pods to which this AdminNetworkPolicy applies. (Note that host-networked pods are not included in subject.selection.) There are two ways to define the subject:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;strong>namespaces&lt;/strong>: The namespaces block is used to select pods via namespace selectors. Here, &lt;strong>matchLabels&lt;/strong> or &lt;strong>matchExpressions&lt;/strong> can be used to limit the namespaces.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>pods&lt;/strong>: The Pods-Array is used to select pods via namespace AND pod selectors. Here &lt;strong>namespaceSelector&lt;/strong> and &lt;strong>podSelector&lt;/strong> can be set to limit the Pods.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If &lt;strong>subject&lt;/strong> is not defined, the policy applies to all pods and namespaces in the cluster.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In my Helm chart the options are supported like the following snippets show:&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_select_namespaces_with_matchexpressions">Select Namespaces with matchExpressions&lt;/h3>
&lt;div class="paragraph">
&lt;p>Values in the Helm Chart:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">anp:
- name: sample-anp-rule-1
enabled: true
priority: 50
subject:
matchNamespaces: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
matchExpressions: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- key: kubernetes.io/metadata.name
operator: NotIn
values:
- kube-system
- openshift*
- default
- kubde-info&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>matchNamespaces is used to select namespaces&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>matchExpressions is used to select namespaces with &lt;strong>matchExpressions&lt;/strong>. In this example all namespaces that do not match (operator == NotIn) the values, so all namespaces except &amp;#34;kube-system, kube-info, default and openshift*&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will result in the following AdminNetworkPolicy snippet:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> subject:
namespaces:
matchExpressions:
- key: kubernetes.io/metadata.name
operator: NotIn
values:
- &amp;#34;kube-system&amp;#34;
- &amp;#34;openshift*&amp;#34;
- &amp;#34;default&amp;#34;
- &amp;#34;kubde-info&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_select_namespaces_with_matchlabels">Select Namespaces with matchLabels&lt;/h3>
&lt;div class="paragraph">
&lt;p>Values in the Helm Chart:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">anp:
- name: sample-anp-rule-1
enabled: true
priority: 5
subject:
matchNamespaces: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
matchLabels: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
apps: my-apps
tenant: my-tenant&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>matchNamespaces is used to select namespaces&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>&lt;strong>matchLabels&lt;/strong> is used to select namespaces based on labels. In this example, all namespaces that have the labels &amp;#34;apps: my-apps&amp;#34; and &amp;#34;tenant: my-tenant&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will result in the following AdminNetworkPolicy snippet:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">spec:
priority: 5
subject:
namespaces:
matchLabels:
apps: &amp;#34;my-apps&amp;#34;
tenant: &amp;#34;my-tenant&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_select_pods_with_podselectors_and_namespaceselectors">Select Pods with podSelectors and namespaceSelectors&lt;/h3>
&lt;div class="paragraph">
&lt;p>Values in the Helm Chart:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">anp:
- name: sample-anp-rule-1
enabled: true
priority: 5
subject:
matchPods:
- pods: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespaceSelector: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
labels:
kubernetes.io/metadata.name: openshift-dns
podSelector: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
labels:
app: dns&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>matchPods is used to select pods. Here a list of pods can be defined.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>&lt;strong>namespaceSelector&lt;/strong> is used to select namespaces based on labels. In this example all namespaces that have the label &amp;#34;kubernetes.io/metadata.name: openshift-dns&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>&lt;strong>podSelector&lt;/strong> is used to select pods based on labels. In this example all pods that have the label &amp;#34;app: dns&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will result in the following AdminNetworkPolicy snippet:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> subject:
- pods:
namespaceSelector:
matchLabels:
kubernetes.io/metadata.name: openshift-dns
podSelector:
matchLabels:
app: dns&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_baselineadminnetworkpolicy">BaselineAdminNetworkPolicy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>BaselineAdminNetworkPolicy (BANP) is a cluster-scoped resource, that allow cluster administrators to secure the network traffic &lt;strong>after&lt;/strong> NetworkPolicies in the namespaces have been evaluated. These rules can be overwritten by project owners or developers using NetworkPolicies.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
BANP is a singleton resource, meaning it can be defined only one time. Therefore, its name must be &lt;strong>default&lt;/strong>. Moreover, the &lt;strong>priority&lt;/strong> field is not required here.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Use cases could be, for example:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Creating default rules, such as blocking any intra-cluster traffic by default. Users will need to explicitly use NetworkPolicy objects to allow known traffic.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A BANP allows administrators to specify:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A subject that consists of a set of namespaces or namespace.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of ingress rules to be applied for all ingress traffic towards the subject.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of egress rules to be applied for all egress traffic from the subject.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_baselineadminnetworkpolicy_actions_for_rules">BaselineAdminNetworkPolicy Actions for Rules&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The BaselineAdminNetworkPolicy allows two actions for the rules. They are like the AdminNetworkPolicy, except for the &lt;strong>pass&lt;/strong> action, which does not make sense here as BANP is the last tier (nowhere to pass).&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Allow&lt;/strong>: The traffic is allowed, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Deny&lt;/strong>: The traffic is denied, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_examples_examples_examples">Examples Examples Examples&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following examples are taken directly from &lt;a href="https://network-policy-api.sigs.k8s.io/blog/2024/01/30/getting-started-with-the-adminnetworkpolicy-api/" target="_blank" rel="noopener">Kubernetes Blog: Getting started with the AdminNetworkPolicy API&lt;/a> and &lt;a href="https://docs.openshift.com/container-platform/4.16/networking/network_security/network-policy-apis.html" target="_blank" rel="noopener">Official OpenShift Documentation&lt;/a>. Verify the values-file of the &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/admin-networkpolicies" target="_blank" rel="noopener">Helm Chart&lt;/a> for the further examples.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
I will show, how to configure them using the Helm Chart &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/admin-networkpolicies" target="_blank" rel="noopener">admin-networkpolicies&lt;/a> and the actual result. The chart is already configured with these examples and prepared to be used with GitOps/Argo CD.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_1_allow_all_traffic_from_the_openshift_monitoring_namespace">Example 1: Allow all traffic from the OpenShift monitoring namespace&lt;/h3>
&lt;div class="paragraph">
&lt;p>Typically, it makes sense to allow the traffic from OpenShift Monitoring to all namespaces. After all, monitoring is useful :)
The following example shows the possible configuration for the Helm Chart, which will render a valid ANP resource for us. It will allow ALL (including OpenShift internal Namespaces) traffic from the OpenShift monitoring namespace (labeled as &lt;code>kubernetes.io/metadata.name: monitoring&lt;/code>).&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
anp:
- name: sample-anp-rule-1 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
enabled: true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: 10
priority: 5 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
subject: {} &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
ingress: &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
- name: allow-ingress-from-monitoring &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
enabled: true &lt;i class="conum" data-value="7">&lt;/i>&lt;b>(7)&lt;/b>
action: Allow &lt;i class="conum" data-value="8">&lt;/i>&lt;b>(8)&lt;/b>
peers: &lt;i class="conum" data-value="9">&lt;/i>&lt;b>(9)&lt;/b>
- type: namespaces
labels:
kubernetes.io/metadata.name: monitoring&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Name of the ANP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Enable or disable the ANP. If disabled, the ANP will not be created. (Default is &lt;code>false&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Priority of the ANP. The lower the value the higher the precedence. (Default is &lt;code>50&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Subject of the ANP. In this case, it is empty, which means all namespaces including OpenShift internal namespaces.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Ingress rules of the ANP. Here a list of ingress rules for this ANP can be defined&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>Name of the ingress rule&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="7">&lt;/i>&lt;b>7&lt;/b>&lt;/td>
&lt;td>Enable or disable the ingress rule. If disabled, the particular ingress rule will not be created. (Default is &lt;code>false&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="8">&lt;/i>&lt;b>8&lt;/b>&lt;/td>
&lt;td>Action of the ingress rule. In this case, it is &lt;code>Allow&lt;/code>, which means all traffic from the OpenShift monitoring namespace will be allowed. Other options are described at &lt;a href="#_adminnetworkpolicy_actions_for_rules">AdminNetworkPolicy Actions for Rules&lt;/a>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="9">&lt;/i>&lt;b>9&lt;/b>&lt;/td>
&lt;td>Peers of the ingress rule. In this case, all namespaces labeled as &lt;code>kubernetes.io/metadata.name: monitoring&lt;/code> are allowed to access all namespaces.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The ANP that will be created is the following. It is a valid ANP resource and can be applied to the cluster. (Typically applied by Argo CD)
As described above it will allow incoming access from the OpenShift monitoring namespace to all namespaces.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: policy.networking.k8s.io/v1alpha1
kind: AdminNetworkPolicy
metadata:
name: &amp;#34;sample-anp-rule-1&amp;#34;
labels:
helm.sh/chart: admin-networkpolicies-1.0.2
app.kubernetes.io/name: admin-networkpolicies
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
annotations:
argocd.argoproj.io/sync-wave: &amp;#34;10&amp;#34;
argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
spec:
priority: 5
subject:
namespaces: {}
ingress:
- name: &amp;#34;allow-ingress-from-monitoring&amp;#34;
action: &amp;#34;Allow&amp;#34;
from:
- namespaces:
matchLabels:
kubernetes.io/metadata.name: &amp;#34;monitoring&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_2_allow_all_traffic_from_labeled_namespaces">Example 2: Allow all traffic from labeled namespaces&lt;/h3>
&lt;div class="paragraph">
&lt;p>As a second example, we want to allow all traffic from namespaces that are labeled with &lt;code>tenant: restricted&lt;/code> to all namespaces that are labeled with &lt;code>anp: cluster-control-anp&lt;/code>.
This is useful, if you want to restrict access to certain namespaces. However, the rule action is configured as &lt;strong>Pass&lt;/strong> which means that the traffic will be allowed but might be further restricted by a NetworkPolicy in the tenant namespace.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
anp:
- name: sample-anp-rule-2
enabled: true
priority: 5
subject:
matchNamespaces: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
matchLabels:
anp: cluster-control-anp &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
ingress:
- name: pass-from-restricted-tenants
enabled: true
action: Pass &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
peers:
- type: namespaces &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
labels:
tenant: restricted&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Subject of the ANP. In this case, we select based on labels.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Label selector for the namespaces. In this case, all namespaces that are labeled with &lt;code>anp: cluster-control-anp&lt;/code> are subject of this ANP.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Action of the ingress rule. In this case, it is &lt;code>Pass&lt;/code>, which means the traffic is allowed, but might be restricted by NetworkPolicies in the tenant namespace. Other options are described at &lt;a href="#_adminnetworkpolicy_actions_for_rules">AdminNetworkPolicy Actions for Rules&lt;/a>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Peers of the ingress rule. In this case, all namespaces labeled as &lt;code>tenant: restricted&lt;/code> are allowed to access all namespaces.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: policy.networking.k8s.io/v1alpha1
kind: AdminNetworkPolicy
metadata:
name: &amp;#34;sample-anp-rule-2&amp;#34;
labels:
helm.sh/chart: admin-networkpolicies-1.0.2
app.kubernetes.io/name: admin-networkpolicies
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
annotations:
argocd.argoproj.io/sync-wave: &amp;#34;10&amp;#34;
argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
spec:
priority: 5
subject:
namespaces:
matchLabels:
anp: &amp;#34;cluster-control-anp&amp;#34;
ingress:
- name: &amp;#34;pass-from-restricted-tenants&amp;#34;
action: &amp;#34;Pass&amp;#34;
from:
- namespaces:
matchLabels:
tenant: &amp;#34;restricted&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_3_show_possible_peers_settings">Example 3: Show possible peers settings&lt;/h3>
&lt;div class="paragraph">
&lt;p>The most important settings for the rules are the &lt;code>peers&lt;/code> settings. The following examples show the snippets of possible peers.
For further information, please refer to the example in the values file: &lt;a href="https://github.com/tjungbauer/helm-charts/blob/main/charts/admin-networkpolicies/values.yaml" target="_blank" rel="noopener">Helm Chart Values with further examples&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The following rules are examples of &lt;strong>EGRESS&lt;/strong> rules.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to namespaces labeled&lt;/strong> splunk on ports 80 and 443:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: namespaces
labels:
tenant: splunk
ports:
- protocol: TCP
portNumber: 80
- portName: https&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="2">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to nodes&lt;/strong> where the key &amp;#34;node-role.kubernetes.io/control-plane&amp;#34; exists &lt;strong>on the port 6443&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: nodes
expr:
- key: node-role.kubernetes.io/control-plane
operator: Exists
ports:
- protocol: TCP
portNumber: 6443&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="3">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to pods&lt;/strong> labeled &amp;#34;app: dns&amp;#34; &lt;strong>in the namespace&lt;/strong> openshift-dns &lt;strong>on the port 53 and 5353&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: pods
namespaceSelector:
matchLabels:
kubernetes.io/metadata.name: openshift-dns
podSelector:
matchLabels:
app: dns
ports:
- protocol: TCP
port: 5353
- protocol: TCP
port: 53
- protocol: UDP
port: 53
- protocol: UDP
port: 5353&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="4">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to a list of IPs&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: networks
ips:
- 172.29.0.0/30
- 10.0.54.0/19
- 10.0.56.38/32
- 10.0.69.0/24&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="5">
&lt;li>
&lt;p>Allows egress traffic &lt;strong>to a list of domain names&lt;/strong> (*.kubernetes.io and kubernetes.io)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: domainNames
domains:
- &amp;#39;*.kubernetes.io&amp;#39;
- kubernetes.io&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="6">
&lt;li>
&lt;p>&lt;strong>Deny all egress traffic&lt;/strong>. This should be the last rule when full egress traffic shall be disabled. This might also be put into the BANP.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> - name: default-deny
enabled: true
action: Deny
peers:
- type: networks
ips:
- 0.0.0.0/0&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_4_baselineadminnetworkpolicy">Example 4: BaselineAdminNetworkPolicy&lt;/h3>
&lt;div class="paragraph">
&lt;p>The BANP is more or less identical to ANP, except that you cannot define a &amp;#34;name&amp;#34; and a &amp;#34;priority&amp;#34;. The following example creates a BANP that allows incoming and outgoing traffic to namespaces labeled &amp;#34;tenant-1&amp;#34;.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">banp: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- enabled: true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: 10
subject:
matchNamespaces:
matchLabels:
kubernetes.io/metadata.name: example.name
ingress:
- name: &amp;#34;deny-all-ingress-from-tenant-1&amp;#34;
enabled: true
action: Deny
peers:
- type: pods
namespaceSelector:
matchLabels:
custom-banp: tenant-1
podSelector:
matchLabels:
custom-banp: tenant-1
egress:
- name: allow-all-egress-to-tenant-1
enabled: true
action: Allow
peers:
- type: pods
namespaceSelector:
matchLabels:
custom-banp: tenant-1
podSelector:
matchLabels:
custom-banp: tenant-1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Using the key &lt;strong>banp&lt;/strong> (instead of &lt;strong>anp&lt;/strong>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>No &lt;strong>name&lt;/strong> or &lt;strong>priority&lt;/strong> are defined here.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_further_information">Further Information&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/blob/main/charts/admin-networkpolicies/values.yaml" target="_blank" rel="noopener">Helm Chart Values with further examples&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://docs.openshift.com/container-platform/4.16/networking/network_security/network-policy-apis.html" target="_blank" rel="noopener">Official OpenShift Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://network-policy-api.sigs.k8s.io/blog/2024/01/30/getting-started-with-the-adminnetworkpolicy-api/" target="_blank" rel="noopener">Kubernetes Blog: Getting started with the AdminNetworkPolicy API&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://network-policy-api.sigs.k8s.io/reference/spec/#policy.networking.k8s.io/v1alpha1.AdminNetworkPolicyEgressPeer" target="_blank" rel="noopener">Kubernetes API Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Setup &amp; Configure Advanced Cluster Security using GitOps</title><link>https://blog.stderr.at/gitopscollection/2024-04-28-installing-advanced-cluster-security/</link><pubDate>Sun, 28 Apr 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-04-28-installing-advanced-cluster-security/</guid><description>&lt;div class="paragraph">
&lt;p>Today I want to demonstrate the deployment and configuration of &lt;strong>Advanced Cluster Security&lt;/strong> (ACS) using a GitOps approach. The required operator shall be installed, verified if it is running and then ACS shall be initialized. This initialization contains the deployment of several components:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Central - as UI and as a main component of ACS&lt;/p>
&lt;/li>
&lt;li>
&lt;p>SecuredClusters - installs a Scanner, Controller pods etc.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Console link into OpenShift UI - to directly access the ACS Central UI&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Job to create an initialization bundle to install the Secured Cluster&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Job to configure authentication using OpenShift&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s start …​&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Argo CD (OpenShift GitOps) deployed&lt;/p>
&lt;/li>
&lt;li>
&lt;p>App-Of-Apps deployed&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_introduction">Introduction&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The main components of ACS are the two custom resources: &lt;strong>Central&lt;/strong> and &lt;strong>SecuredCluster&lt;/strong>. The recommended way to deploy ACS is to use the Operator (alternatives would be the command line or Helm Chart). When I first came across ACS I thought about how to automate the full deployment. I did not want to install the Operator, then the Central, then manually create a so-called init-bundle, then deploy the Secured Cluster, then find the route that has been used, then find the secret that stores the initial administrator credentials and then, finally, log into ACS and activate OpenShift authentication.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see there are a lot of tasks to do before I can start a customer demo.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>At the same time, I started to dig into GitOps and I thought this would be a good option to create my very first Helm Chart.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Long story short, I have now a Helm Chart (actually three, because I outsourced some of the features into sub-charts) that automatically does all these things above. Once I am synchronizing my Argo CD Application everything will happen automatically.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;a href="https://blog.stderr.at/gitopscollection/2024-04-02-configure_app_of_apps/">Configure App-of-Apps&lt;/a> installed an Argo CD Application called &lt;strong>in-cluster-setup-acs&lt;/strong>:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup-acs.png?width=720px" alt="Argo CD Application: setup-acs"/>
&lt;/div>
&lt;div class="title">Figure 1. Argo CD Application: setup-acs&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This Argo CD Application used the following path to find the Helm Chart: &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/setup-acs">setup-acs&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This Helm chart is a wrapper chart that uses sub-charts as dependencies to install and configure the operator as well as to do some OpenShift Jobs on top, for example, creating a ConsoleLink or creating an init-bundle.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Please check out the article &lt;a href="https://blog.stderr.at/gitopscollection/2024-04-25-installing-compliance-operator/#_why_empty_helm_charts">Setup Compliance Operator&lt;/a> on why I am using a wrapper chart.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_advanced_cluster_security">Installing Advanced Cluster Security&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="sect2">
&lt;h3 id="_analysing_chart_yaml">Analysing Chart.yaml&lt;/h3>
&lt;div class="paragraph">
&lt;p>Let’s examine the Chart.yaml file to see which dependencies are used:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The file looks like the following. Three sub-charts are defined as required to deploy and configure the ACS. This is pretty much the same as it was for the &lt;a href="https://blog.stderr.at/gitopscollection/2024-04-25-installing-compliance-operator/#_analysing_chart_yaml">Setup Compliance Operator&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v2
name: setup-acs
description: Deploys Advanced Cluster Security (ACS) on target cluster. If enabled Central will be deployed too.
version: 1.0.0
dependencies:
- name: rhacs-setup &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
version: ~1.0.0 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
repository: https://charts.stderr.at/
- name: helper-operator &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
version: ~1.0.23
repository: https://charts.stderr.at/
- name: helper-status-checker &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
version: ~4.0.0
repository: https://charts.stderr.at/
condition: helper-status-checker.enabled &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Dependency: &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/rhacs-setup" target="_blank" rel="noopener">RHACS Setup&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Version that will be used. The &amp;#34;~&amp;#34; means that the latest version of 1.0.X will be used.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Dependency: &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator" target="_blank" rel="noopener">Helper Operator&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Dependency: &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker" target="_blank" rel="noopener">Helper Status Checker&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Only use this dependency when &amp;#34;enabled&amp;#34; is set&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Verify the READMEs of the different Charts for detailed information on how to configure them.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configuration_of_the_chart">Configuration of the Chart&lt;/h3>
&lt;div class="paragraph">
&lt;p>To configure Advanced Cluster Security the &lt;strong>values file&lt;/strong> of the wrapper Chart must be prepared accordingly.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
The important thing here is, that any value that should be bypassed to a sub-chart is defined under the name of the sub-chart. For example, everything under &lt;strong>helper-operator:&lt;/strong> will be sent to the helper-operator Chart and is used there for its configuration.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Check out the example &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/setup-acs/values.yaml" target="_blank" rel="noopener">values file&lt;/a> I use to configure ACS and the
&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/rhacs-setup" target="_blank" rel="noopener">README&lt;/a> to find further information about the possible settings that can be done.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s check the main example, to quickly start:&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_installing_and_verifying_the_operator">Installing and verifying the Operator&lt;/h3>
&lt;div class="paragraph">
&lt;p>The first thing to do is to deploy the Operator and to verify if the Operator installation finished successfully.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The two Helm Charts &lt;strong>helper-operator&lt;/strong> and &lt;strong>helper-status-checker&lt;/strong> are responsible to do so.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>They are configured as follows:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">helper-operator:
operators:
rhacs-operator: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
enabled: true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: &amp;#39;0&amp;#39; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
namespace:
name: rhacs-operator &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
create: true
subscription:
channel: stable &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
approval: Automatic
operatorName: rhacs-operator
source: redhat-operators
sourceNamespace: openshift-marketplace
operatorgroup: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
create: true
# rhacs does not support to monitor own namespace,
# therefore the spec in the OperatorGroup must be empty
notownnamespace: true
# Subchart helper-status-checker
# checks if ACS operator is ready
helper-status-checker:
enabled: true &lt;i class="conum" data-value="7">&lt;/i>&lt;b>(7)&lt;/b>
checks: &lt;i class="conum" data-value="8">&lt;/i>&lt;b>(8)&lt;/b>
- operatorName: rhacs-operator &lt;i class="conum" data-value="9">&lt;/i>&lt;b>(9)&lt;/b>
namespace:
name: rhacs-operator &lt;i class="conum" data-value="10">&lt;/i>&lt;b>(10)&lt;/b>
syncwave: 3
serviceAccount:
name: &amp;#34;status-checker-acs&amp;#34; &lt;i class="conum" data-value="11">&lt;/i>&lt;b>(11)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Key that can be freely defined. Theoretically, you can deploy multiple operators at once.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Is this Operator enabled yes/no.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Syncwave for the Operator deployment. (Subscription and OperatorGroup etc.)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The Namespace where the Operator shall be deployed and if this namespace shall be created.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Configuration of the Subscription resource.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>Configuration of the OperatorGroup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="7">&lt;/i>&lt;b>7&lt;/b>&lt;/td>
&lt;td>Enable status checker or not. Default: false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="8">&lt;/i>&lt;b>8&lt;/b>&lt;/td>
&lt;td>List of operators to check. Typically, only one is checked, but there could be more.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="9">&lt;/i>&lt;b>9&lt;/b>&lt;/td>
&lt;td>Name of the Operator to check (same as for helper-operator)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="10">&lt;/i>&lt;b>10&lt;/b>&lt;/td>
&lt;td>Namespace where the Operator has been installed (same as for helper-operator)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="11">&lt;/i>&lt;b>11&lt;/b>&lt;/td>
&lt;td>Name of the ServiceAccount that will be created to check the status.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Verify the READMEs at &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator" target="_blank" rel="noopener">Helper Operator&lt;/a> and &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker" target="_blank" rel="noopener">Helper Operator Status Checker&lt;/a> to find additional possible configurations.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Also verify the separate article &lt;a href="https://blog.stderr.at/openshift/2023-03-20-operator-installation-with-argocd/">Operator Installation with Argo CD&lt;/a> to understand why I am verifying the status of the Operator installation.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configuring_advanced_cluster_security">Configuring Advanced Cluster Security&lt;/h3>
&lt;div class="paragraph">
&lt;p>Besides the deployment of the Operator, the configuration of ACS is the most important part here. The ACS Operator provides two custom resources: Central and SecuredCluster. On the Central cluster both CRDs are required. On any other (spoke) cluster, the SecuredCluster resource is enough.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In the following example, I am going to configure both Central and SecuredCluster. Since the values file is quite huge I removed most of the additional comments, to keep this article short and readable.
You can read the example values file or the README at &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/rhacs-setup" target="_blank" rel="noopener">Advanced Cluster Security Chart&lt;/a> to find additional possible configurations. Especially, if you like to add tolerations or set resource limits.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">#########################################
# Settings for Advanced Cluster Security
#########################################
rhacs-setup:
rhacs:
namespace: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
name: stackrox
syncwave: &amp;#39;0&amp;#39;
descr: &amp;#39;Red Hat Advanced Cluster Security&amp;#39;
################
# CENTRAL of ACS
################
# Settings for the Central of ACS
central: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
enabled: true
syncwave: &amp;#39;3&amp;#39;
egress:
connectivityPolicy: Online
###############
# CENTRAL DB
###############
# Settings for Central DB, which is responsible for data persistence.
db: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
# -- Set Central DB resources.requests for a DEMO environment to save resources.
resources:
requests:
cpu: &amp;#39;1&amp;#39;
memory: &amp;#39;1Gi&amp;#39;
# -- If you want this component to only run on specific nodes, you can
# configure tolerations of tainted nodes.
tolerations: {}
# - effect: NoSchedule
# key: infra
# operator: Equal
# value: reserved
# - effect: NoSchedule
# key: infra
# operator: Equal
# value: reserved
###############
# SCANNER
###############
scanner: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
enabled: true
analyzer:
# The following settings are NOT suitable for a production environment
autoscaling:
status: &amp;#34;Disabled&amp;#34;
max: 1
min: 1
# When autoscaling is disabled, the number of replicas will always be
# configured to match this value.
replicas: 1
tolerations: {}
###############
# SCANNER DB
###############
db:
tolerations: {}
#################
# SECURED CLUSTER
#################
secured_cluster: &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
enabled: true
syncwave: &amp;#39;4&amp;#39;
clustername: local-cluster
sensor:
tolerations: {}
admissioncontrol:
listenOn:
creates: true
events: true
updates: true
tolerations: {}
# -- Basic settings for ACS authentication
# This configuration is done by a Job, that will configure the OpenShift oauth for ACS.
basic_acs_settings: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
auth_provider: &amp;#39;OpenShift&amp;#39;
auth_provider_type: &amp;#39;openshift&amp;#39;
min_access_role: &amp;#39;None&amp;#39;
syncwave: 5
####################################################
# Additional settings for Central and possible Jobs
####################################################
job_vars: &lt;i class="conum" data-value="7">&lt;/i>&lt;b>(7)&lt;/b>
max_attempts: 20
job_init_bundle: &lt;i class="conum" data-value="8">&lt;/i>&lt;b>(8)&lt;/b>
enabled: true
syncwave: &amp;#39;3&amp;#39;
consolelink: &lt;i class="conum" data-value="9">&lt;/i>&lt;b>(9)&lt;/b>
enabled: true
syncwave: &amp;#39;3&amp;#39;
location: ApplicationMenu
text: Advanced Cluster Security
section: Observability&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Create the Namespace &lt;strong>stackrox&lt;/strong> and install the ACS resources there.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Enable the Central during Syncwave 3 and set the connectivityPolicy to Online&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The Central DB and its configuration. Here the resource requests are modified to allow a small installation on the DEMO environment. Also, tolerations might be set here, as well a PVCs etc.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Settings for the Scanner and its databases. Again, tolerations might be configurated here, but also, not shown in this example, resource limits and requests and other settings. Since I am configuring for a DEMO environment, I disabled the autoscaler and set the replica to 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The SecuredCluster is the 2nd CRD that is provided by ACS Operator. It is installed after the Central (thus a higher Syncwave). The most important setting here is the clustername. In our &amp;#34;local&amp;#34; example, the name is set to &lt;strong>local-cluster&lt;/strong>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>Some basic settings, that will configure the OpenShift authentication and the minimum role for authenticated users (None)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="7">&lt;/i>&lt;b>7&lt;/b>&lt;/td>
&lt;td>Some default settings for Jobs that are started by this Helm chart.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="8">&lt;/i>&lt;b>8&lt;/b>&lt;/td>
&lt;td>The Job that initializes the creation of the init-bundle&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="9">&lt;/i>&lt;b>9&lt;/b>&lt;/td>
&lt;td>The Job and its configuration to generate a direct link to ACS in the OpenShift UI.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With this ACS is about to be installed on the cluster. Let’s see what will happen during the synchronization.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_deploying_advanced_cluster_security_acs">Deploying Advanced Cluster Security (ACS)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Let’s hit the sync button inside OpenShift GitOps. This will start the whole process, walking through the syncwaves and the hooks that have been defined.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/syncing-argocd.png?width=720px" alt="Syncing Argo CD"/>
&lt;/div>
&lt;div class="title">Figure 2. Syncing Argo CD&lt;/div>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
Since hooks are used, you must sync the whole Argo CD Application. As you can see inside Argo CD, the hooks are not shown, because they will only appear when their time has come (and will disappear afterward again). This means, that if you perform a selective sync, Argo CD does not know when it should start such a hook and they are never triggered.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Operator installation is now started. At the moment the Operator has the status &lt;strong>Installing&lt;/strong>. Currently, no CRDs (Central or SecuredCluster) are available yet. If we would just let Argo CD continue, it would try to create the Central configuration, based on a CRD which does not yet exist. Thus, the syncing process will fail and therefore the &lt;strong>status-checker&lt;/strong> is going to verify if the installation was truly successful.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/installing-operator.png?width=720px" alt="Operator is installed"/>
&lt;/div>
&lt;div class="title">Figure 3. Operator is installed&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Status Checker is a simple Pod that is triggered by a Kubernetes Job. If waits until the status of the Operator is &lt;strong>Succeeded&lt;/strong>. Until this is the case, Argo CD waits before it continues with the synchronization. (It waits until the hook ends the Job)&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/status-checker.png?width=720px" alt="Status Checker"/>
&lt;/div>
&lt;div class="title">Figure 4. Status Checker&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In the logs file of the Pod, we can see that the Operator is ready.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/status-checker-logs.png?width=720px" alt="Status Checker Logs"/>
&lt;/div>
&lt;div class="title">Figure 5. Status Checker Logs&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And indeed, the status of the Operator is now &lt;strong>Succeeded&lt;/strong>. Now it is time for Argo CD to continue the synchronization.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/operator-ready.png?width=720px" alt="Operator Ready"/>
&lt;/div>
&lt;div class="title">Figure 6. Operator Ready&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The next step is to create the Central CRD. This will deploy the UI of ACS and the local Scanner. You can also see two other Jobs that have been created by the Helm Charts &lt;strong>create_cluster_link&lt;/strong> and &lt;strong>create_cluster_init_bundle&lt;/strong>. They will finish when the Central becomes ready.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
Until the Central becomes ready, these two additional Jobs may show errors. Do not worry, OpenShift will reschedule them.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/installing-central.png?width=720px" alt="Installing Central"/>
&lt;/div>
&lt;div class="title">Figure 7. Installing Central&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can also see two other Jobs that have been created by the Helm Charts &lt;strong>create_cluster_link&lt;/strong> and &lt;strong>create_cluster_init_bundle&lt;/strong>. They will finish when the Central becomes ready.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
Until the Central becomes ready, these two additional Jobs may show errors. Do not worry, OpenShift will reschedule them.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/init-job-waits.png?width=720px" alt="Init Job is waiting for Central"/>
&lt;/div>
&lt;div class="title">Figure 8. Init Job is waiting for Central&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Once the Central has been deployed, the second CRD &lt;strong>SecuredCluster&lt;/strong> will be added. This will trigger the installation of the Collectors and other components.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/installing-securedcluster.png?width=720px" alt="Installing Secured Cluster"/>
&lt;/div>
&lt;div class="title">Figure 9. Installing SecuredCluster&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Eventually, all Pods are running at the end. The additional Jobs are completed and ACS is ready to take care of the cluster security.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/acs-all-pods-running.png?width=720px" alt="All Pods running"/>
&lt;/div>
&lt;div class="title">Figure 10. All Pods running&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We can now use the console link that was created.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/acs-consolelink.png?width=720px" alt="ACS ConsoleLink"/>
&lt;/div>
&lt;div class="title">Figure 11. ACS ConsoleLink&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
If you disabled the creation of the ConsoleLink you would need to find the Route that ACS Operator created. Honestly, I do not know why the Operator does not create such ConsoleLink out of the box.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Since I am lazy I created another Job that automatically configures authentication via OpenShift for ACS. This way, we can simply use our OpenShift credentials to login.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/acs-login.png?width=720px" alt="ACS Login"/>
&lt;/div>
&lt;div class="title">Figure 12. ACS Login&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And that’s it, we can now use ACS, which was deployed fully automatically.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup_acs/acs.png?width=720px" alt="Advanced Cluster Security"/>
&lt;/div>
&lt;div class="title">Figure 13. Advanced Cluster Security&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As you can see Advanced Cluster Security was completely installed. This included the Operator, the Central, the creation and installation of an init-bundle, the creation of a ConsoleLink, the configuration of the SecuredCluster CRD and the initial configuration of the auth provider inside ACS. You can now start using ACS or add additional clusters.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Speaking of additional clusters: The create-cluster-init-bundle created three certificates: collector-tls, sensor-tls and admission-control-tls. They are required so that the SecuredClusters can communicate with the Central. You could now create a separate init-bundle for each SecuredCluster, which is not really easy to automate, or you simply take these created secrets and put them into your GitOps and re-use them for any other SecuredCluster.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>All these steps and configurations seem quite complicated but honestly, it is straightforward. I install any Operator using &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator" target="_blank" rel="noopener">Helper Operator&lt;/a> and in most cases. I also use &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker" target="_blank" rel="noopener">Helper Operator Status Checker&lt;/a> to find additional possible configurations. Both require simple configuration only, which you would need to know anyway when you create the Subscription object manually. Once done, you can repeat this for any other Operator.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The real magic happens when the Operator is configured at the same time because this is very individual to the Operator.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Setup &amp; Configure Compliance Operator using GitOps</title><link>https://blog.stderr.at/gitopscollection/2024-04-25-installing-compliance-operator/</link><pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/gitopscollection/2024-04-25-installing-compliance-operator/</guid><description>&lt;div class="paragraph">
&lt;p>In the previous articles, we have discussed the &lt;a href="https://blog.stderr.at/gitopscollection/2023-12-28-gitops-repostructure/">Git repository folder structure&lt;/a> and the configuration of the &lt;a href="gitopscollection/2024-04-02-configure_app_of_apps/">App-Of-Apps&lt;/a>. Now it is time to deploy our first configuration. One of the first things I usually deploy is the &lt;a href="https://docs.openshift.com/container-platform/4.15/security/compliance_operator/co-overview.html" target="_blank" rel="noopener">Compliance Operator&lt;/a>. This Operator is recommended for any cluster and can be deployed without any addition to the Subscription.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article, I will describe how it is installed and how the Helm Chart is configured.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Argo CD (OpenShift GitOps) deployed&lt;/p>
&lt;/li>
&lt;li>
&lt;p>App-Of-Apps deployed&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_introduction">Introduction&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As a reminder, at &lt;a href="https://blog.stderr.at/gitopscollection/2023-12-28-gitops-repostructure/">Git repository folder structure&lt;/a> I described my preferred folder structure. I would like to deploy the Compliance Operator in the Management Cluster now. All my examples can be found at GitHub repository &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops" target="_blank" rel="noopener">OpenShift Clusterconfig GitOps&lt;/a>. The folder &lt;strong>clusters/management-cluster/setup-compliance-operator&lt;/strong> is the one I am interested in.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Inside this folder, you will find another Helm Chart. The Helm Chart has no local templates, instead, it uses dependencies to call other (sub-) charts. However, the &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/setup-compliance-operator/values.yaml" target="_blank" rel="noopener">values.yaml&lt;/a> is the main part to configure everything.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
In case you want to have any local template, that you do NOT want to integrate into one of the sub-charts, you can easily do so, by storing them in the templates folder.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_why_empty_helm_charts">Why &amp;#34;empty&amp;#34; Helm Charts?&lt;/h3>
&lt;div class="paragraph">
&lt;p>Actually, it would be possible to use the Helm Chart of the Chart repository directly, without creating a separate chart, that does nothing else than using dependency charts.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The reasons why I am using such an &amp;#34;empty&amp;#34; Chart are the following (in no particular order):&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>With that way it is possible to add templates (i.e. SealedSecrets) and modify the values-file without packaging and releasing a new Chart version every time you change a small thing.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The Multi-Source Option, which allows you to use a Helm Chart from repository A and a values file from repository B is still a TechPreview feature (Argo CD 2.10). I am using this for the App-of-Apps already, but I did not do this for all charts. This feature is on the list for Argo CD version 2.11 to become globally available.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As an alternative, it is also possible to mix Kustomize and Helm. That way you only need a kustomization.yaml file and reference to a Helm Chart. In the folder &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/ingresscontroller" target="_blank" rel="noopener">clusters/management-cluster/ingresscontroller&lt;/a> I have such an example.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_compliance_operator">Installing Compliance Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="sect2">
&lt;h3 id="_analysing_chart_yaml">Analysing Chart.yaml&lt;/h3>
&lt;div class="paragraph">
&lt;p>As any Helm Chart a Chart.yaml file exists, that stores the basic information. The most important ones for now are the dependencies.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The file looks like the following. Three sub-charts are defined as required to deploy and configure the Compliance Operator.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v2
name: setup-compliance-operator
description: Deploy and configure the Compliance Operator
version: 1.0.1
dependencies:
- name: compliance-operator-full-stack &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
version: ~1.0.0 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
repository: https://charts.stderr.at/
- name: helper-operator &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
version: ~1.0.21
repository: https://charts.stderr.at/
- name: helper-status-checker &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
version: ~4.0.0
repository: https://charts.stderr.at/
condition: helper-status-checker.enabled &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Dependency: &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/compliance-operator-full-stack" target="_blank" rel="noopener">Compliance Operator Full Stack&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Version that will be used. The &amp;#34;~&amp;#34; means that the latest version of 1.0.X will be used.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Dependency: &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator" target="_blank" rel="noopener">Helper Operator&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Dependency: &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker" target="_blank" rel="noopener">Helper Status Checker&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Only use this dependency when &amp;#34;enabled&amp;#34; is set&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Verify the READMEs of the different Charts for detailed information on how to configure them.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see three other Helm Charts are used to actually deploy and configure the Operator.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configuration_of_the_chart">Configuration of the Chart&lt;/h3>
&lt;div class="paragraph">
&lt;p>To configure the Compliance Operator, the values files must be prepared accordingly.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
The important thing here is, that any value that should be bypassed to a sub-chart is defined under the name of the sub-chart. For example, everything under &lt;strong>helper-operator:&lt;/strong> will be sent to the helper-operator Chart and is used there for its configuration.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following is a full example of the values I typically use.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"># Install Operator Compliance Operator
# Deploys Operator --&amp;gt; Subscription and Operatorgroup
helper-operator:
operators:
compliance-operator:
enabled: true
syncwave: &amp;#39;0&amp;#39;
namespace:
name: openshift-compliance
create: true
subscription:
channel: stable
approval: Automatic
operatorName: compliance-operator
source: redhat-operators
sourceNamespace: openshift-marketplace
operatorgroup:
create: true
notownnamespace: true
# Verify if the Operator has been successfully deployed
helper-status-checker:
enabled: true
checks:
- operatorName: compliance-operator
namespace:
name: openshift-compliance
serviceAccount:
name: &amp;#34;status-checker-compliance&amp;#34;
# Setting for the Compliance Operator
compliance-operator-full-stack:
compliance:
namespace:
name: openshift-compliance
syncwave: &amp;#39;0&amp;#39;
descr: &amp;#39;Red Hat Compliance&amp;#39;
scansettingbinding:
enabled: true
syncwave: &amp;#39;3&amp;#39;
profiles:
- name: ocp4-cis-node
kind: Profile # Could be Profile or TailedProfile
- name: ocp4-cis
kind: Profile
scansetting: default&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let us walk through the settings in more detail.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_installing_the_operator">Installing the Operator&lt;/h3>
&lt;div class="paragraph">
&lt;p>The first thing to do is to deploy the Operator. Two resources are relevant to install an Operator:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Subscription&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OperatorGroup&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Both objects should be deployed at the very beginning of Argo CD synchronisation. This is done by setting the Syncwave to 0.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The main settings are the operatorName, the channel (which is the version of the operator) and the approval (which defines if the Operator is updated automatically or manually).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In addition, a Namespace object is deployed, because this Operator should run in its very own namespace.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will start the Operator installation process.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">helper-operator:
operators:
compliance-operator: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
enabled: true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: &amp;#39;0&amp;#39; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
namespace:
name: openshift-compliance &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
create: true
subscription: &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
channel: stable # Version of the Operator
approval: Automatic # Automatic or Manual
operatorName: compliance-operator # Name of the Operator
source: redhat-operators
sourceNamespace: openshift-marketplace
operatorgroup: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
create: true
notownnamespace: true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Key that can be freely defined. Theoretically, you can deploy multiple operators at once.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Is this Operator enabled yes/no.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Syncwave for the Operator deployment. (Subscription and OperatorGroup etc.)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The Namespace where the Operator shall be deployed and if this namespace shall be created.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Configuration of the Subscription resource.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>Configuration of the OperatorGroup&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Verify the README at &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator" target="_blank" rel="noopener">Helper Operator&lt;/a> to find additional possible configurations.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_verify_the_status_of_the_operator">Verify the Status of the Operator&lt;/h3>
&lt;div class="paragraph">
&lt;p>After Argo CD creates the subscription and operatorgroup resources (and namespace), OpenShift will start the installation of the Operator. This installation will take a while but Argo CD does not see this. All it sees is that the Subscription resource is available and it tries to continue with the configuration of the Operator. Here it will fail because the CRDs are not available yet.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Therefore, I created a mechanism to verify if an Operator is ready or not.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Also verify the separate article &lt;a href="https://blog.stderr.at/openshift/2023-03-20-operator-installation-with-argocd/">Operator Installation with Argo CD&lt;/a> that addresses the problem in more detail.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>All it does is to start a small Job inside OpenShift and to verify the status of the Operator installation. If everything is fine, the Job will end successfully and Argo CD will continue with the next syncwave. Argo CD Hook and syncwaves are required here. The Job should be started &lt;em>after&lt;/em> the Subscription/OperatorGroup resources have been created, which means any syncwave after &amp;#34;0&amp;#34;.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following annotations will be used by the Job:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> argocd.argoproj.io/hook: Sync &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
argocd.argoproj.io/hook-delete-policy: HookSucceeded &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
argocd.argoproj.io/sync-wave: {{ .syncwave | default 1 | quote }} &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Hooks are ways to run scripts before, during, and after a Sync operation.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Deletes the OpenShift Job again. The hook resource is deleted after the hook succeeded (e.g. Job/Workflow completed successfully).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Syncwave: can be configured. Must be after helper-operator (default 0) and before the Operator is configured further. Default value is 1.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The configuration for &lt;strong>hepler_status_checker&lt;/strong> will look like the following:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"># Verify if the Operator has been successfully deployed
helper-status-checker:
enabled: true &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
checks: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- operatorName: compliance-operator &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
namespace:
name: openshift-compliance &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
serviceAccount:
name: &amp;#34;status-checker-compliance&amp;#34; &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Enable status checker or not. Default: false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>List of operators to check. Typically, only one is checked, but there could be more.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Name of the Operator to check (same as for helper-operator)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Namespace where the Operator has been installed (same as for helper-operator)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Name of the ServiceAccount that will be created to check the status.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Verify the README at &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker" target="_blank" rel="noopener">Helper Operator Status Checker&lt;/a> to find additional possible configurations.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configuring_compliance_operator">Configuring Compliance Operator&lt;/h3>
&lt;div class="paragraph">
&lt;p>Finally, the Operator has been deployed and has been verified. Now the time is right to configure the Operator with any configuration we would like. This means, using CRDs to do whatever the Operator offers.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is reflected in the following part of the values file. All these settings are handed over to the sub-chart &lt;strong>compliance-operator-full-stack&lt;/strong>.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Verify the README at &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/compliance-operator-full-stack" target="_blank" rel="noopener">Compliance Operator Chart&lt;/a> to find additional possible configurations. Especially, if you like to do Tailored Profiles.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The compliance operator requires a so-called ScanSettingBinding that uses Profiles which are used to check the cluster compliance once a day. In this case, I am using CIS Benchmarks. There are two profiles:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>ocp4-cis-node: will check the node operating system for missing but suggested configuration.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ocp4-cis: will check the OpenShift cluster for missing but suggested configuration.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"># Setting for the Compliance Operator
compliance-operator-full-stack: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
compliance:
namespace:
name: openshift-compliance &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: &amp;#39;0&amp;#39;
descr: &amp;#39;Red Hat Compliance&amp;#39;
scansettingbinding: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
enabled: true
syncwave: &amp;#39;3&amp;#39;
profiles: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- name: ocp4-cis-node
kind: Profile # Could be Profile or TailedProfile
- name: ocp4-cis
kind: Profile
scansetting: default&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Handing everything that comes below to the sub-chart &lt;strong>compliance-operator-full-stack&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Namespace where the configuration should be deployed. The Syncwave at this point could be omitted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The configuration for the ScanSettingBinding. It is enabled (default = false) and has a Syncwave AFTER the helper-status-checker.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The list of profiles that shall be used. These must exist. The Compliance Operator offers several profiles. I usually use these two for full CIS compliance check.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>With this configuration, the Compliance Operator will not only be installed but also configured with the same Argo CD Application. All you need to do is to synchronize Argo CD and let the magic happen. After a few minutes, everything should be in sync.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/setup-compliance-operator.png?width=720px" alt="Sync Compliance Operator"/>
&lt;/div>
&lt;div class="title">Figure 1. Sync Compliance Operator&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Inside OpenShift the Operator is configured and starts doing its job:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/gitopscollection/images/configured-compliance-operator.png?width=720px" alt="Configured Compliance Operator"/>
&lt;/div>
&lt;div class="title">Figure 2. Configured Compliance Operator&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This concludes the deployment of the Compliance Operator. For further information about the Operator itself, please read the documentation or articles:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;a href="https://docs.openshift.com/container-platform/4.15/security/compliance_operator/co-overview.html" target="_blank" rel="noopener">Official Documentation: Compliance Operator&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.stderr.at/compliance/2021/07/compliance-operator/">Blog: Compliance Operator&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also, be sure to check out the READMEs of the different Charts:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator" target="_blank" rel="noopener">Helper Operator&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker" target="_blank" rel="noopener">Helper Operator Status Checker&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/compliance-operator-full-stack" target="_blank" rel="noopener">Compliance Operator Chart&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/setup-compliance-operator/" target="_blank" rel="noopener">Compliance Operator Setup&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you have any questions or problems, feel free to create a GitHub issue at any time.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Secrets Management - Vault on OpenShift</title><link>https://blog.stderr.at/openshift/2022/08/secrets-management-vault-on-openshift/</link><pubDate>Tue, 16 Aug 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2022/08/secrets-management-vault-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>Sensitive information in OpenShift or Kubernetes is stored as a so-called Secret. The management of these Secrets is one of the most important questions,
when it comes to OpenShift. Secrets in Kubernetes are encoded in base64. This is &lt;strong>not&lt;/strong> an encryption format.
Even if etcd is encrypted at rest, everybody can decode a given base64 string which is stored in the Secret.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For example: The string &lt;code>Thomas&lt;/code> encoded as base64 is &lt;code>VGhvbWFzCg==&lt;/code>. This is simply a masked plain text and it is not secure to share these values, especially not on Git.
To make your CI/CD pipelines or Gitops process secure, you need to think of a secure way to manage your Secrets. Thus, your Secret objects must be encrypted somehow. HashiCorp Vault is one option to achieve this requirement.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_hashicorp_vault">HashiCorp Vault&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>HashiCorp Vault is a solution to solve our Secret management problem. It stores and encrypts our sensitive information at rest and in transit and enables you to create fine grained access
controls (ACL). This defines who has access to a specific secret. Application A should only get access to secret A and so on. However, that is just the tip of the iceberg. Vault can do much more.
If you are interested in further details, check out the introduction video by Armon, the Co-Founder of Hashicorp Vault at: &lt;a href="https://learn.hashicorp.com/tutorials/vault/getting-started-intro?in=vault/getting-started" class="bare">https://learn.hashicorp.com/tutorials/vault/getting-started-intro?in=vault/getting-started&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For this article we will keep it simple and cover:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Installing HashiCorp Vault to OpenShift&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Integrating the plugin &amp;#34;Kubernetes Authentication&amp;#34; to access the Secrets&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Accessing a static secret stored in HashiCorp Vault by an example application&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_vault">Installing Vault&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The easiest way to install Vault is by using the supported Helm chart.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Add the Helm repository to your repo:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">helm repo add hashicorp https://helm.releases.hashicorp.com&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Update the repository to get the latest updates.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">helm repo update&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Before we install Vault, we need to create a values file to set certain variables. Let’s create a file called &amp;#34;overwrite-values.yaml&amp;#34; with the following content&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">global:
openshift: true
server:
ha:
enabled: true
replicas: 3
raft:
enabled: true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will tell HashiCorp Vault the environment we are going to install is (OpenShift), enables high availability with 3 replicas and enables RAFT (see below for some introduction).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally, let us deploy HashiCorp Vault into the namespace &lt;strong>vault&lt;/strong> using the values file we have created in the previous step:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">helm upgrade --install vault hashicorp/vault --values bootstrap/vault/overwrite-values.yaml --namespace=vault --create-namespace&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will start the agent-injector and 3 vault-pods:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get pods -n vault
NAME READY STATUS RESTARTS AGE
vault-0 0/1 Running 0 36s
vault-1 0/1 Running 0 36s
vault-2 0/1 Running 0 36s
vault-agent-injector-74c848f67b-sq4dq 1/1 Running 0 37s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>vault agent injector: detecting applications with annotations that require vault agent which will get injected&lt;/p>
&lt;/li>
&lt;li>
&lt;p>vault-0: vault server&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The vault servers remain in &lt;strong>not-ready&lt;/strong> state until Vault has been unsealed by you.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When you check the logs of one of the pods you will see:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc logs vault-0 -n vault
...
2022-08-11T12:31:22.497Z [INFO] core: security barrier not initialized
2022-08-11T12:31:22.497Z [INFO] core: seal configuration missing, not initialized&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Vault always starts uninitialized and sealed, to protect the secrets. You need to give at least three different unseal-keys in order to be able to use Vault.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Vault’s seal mechanism uses &lt;a href="https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing" target="_blank" rel="noopener">Shamir’s secret sharing&lt;/a>. This is a manual process to secure the cluster if it restarts. You can use auto-unseal for specific cloud providers to bypass the manual requirement.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_raft_storage">Raft Storage&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>During the deployment we have enabled Raft which is the integrated HA storage for Vault. Vault can use several different styles of storage backends, but when it comes to HA and Kubernetes, Raft is
easiest one since it has no other dependencies, and it is well known inside OpenShift. Etcd is using Raft as well. It is a distributed Consensus Algorithm where multiple members form a cluster and elect one leader. The leader has the responsibility to replicate everything to the followers. Since this leader election requires a majority an odd number of cluster members must be available to ensure there is a minimum number left if a member is failing.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_initialize_and_unseal_vault">Initialize and Unseal Vault&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As mentioned, the Vault Pods are not fully available yet, since Vault it currently sealed and cannot be used. The first thing to do is to initialize and unseal it.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The following commands will login into one Pod and execute commands from there.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s get the status of our Vault fist:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault operator init -status&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will return the message:
&lt;code>Vault is not initialized&lt;/code>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following command will initialize Vault for further usage:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti -n vault vault-0 -- vault operator init -format=json &amp;gt; unseal.json&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will create the file &lt;strong>unseal.json&lt;/strong> locally on your machine. &lt;strong>Keep this file secure&lt;/strong> It contains by default 5 key shards and the root token you will need to unseal Vault and authenticate as root.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Keep this file secure, it contains keys to unseal Vault and the root_token to authenticate against.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Never share this file. It will look like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">{
&amp;#34;unseal_keys_b64&amp;#34;: [
&amp;#34;key_1&amp;#34;,
&amp;#34;key_2&amp;#34;,
&amp;#34;key_3&amp;#34;,
&amp;#34;key_4&amp;#34;,
&amp;#34;key_5&amp;#34;
],
&amp;#34;unseal_keys_hex&amp;#34;: [
&amp;#34;key_hex_1&amp;#34;,
&amp;#34;key_hex_2&amp;#34;,
&amp;#34;key_hex_3&amp;#34;,
&amp;#34;key_hex_4&amp;#34;,
&amp;#34;key_hex_5&amp;#34;
],
&amp;#34;unseal_shares&amp;#34;: 5,
&amp;#34;unseal_threshold&amp;#34;: 3,
&amp;#34;recovery_keys_b64&amp;#34;: [],
&amp;#34;recovery_keys_hex&amp;#34;: [],
&amp;#34;recovery_keys_shares&amp;#34;: 5,
&amp;#34;recovery_keys_threshold&amp;#34;: 3,
&amp;#34;root_token&amp;#34;: &amp;#34;root.token&amp;#34;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the initialization in place Vault is put into a sealed mode. This means Vault cannot decrypt secrets at this moment.
To unseal Vault you need the unseal key, which is split into multiple shards using &lt;a href="https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing" target="_blank" rel="noopener">Shamir’s secret sharing&lt;/a>. A certain number of individual shards (default 3) must be provided to reconstruct the unseal key.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To unseal Vault lets login to our Pod &amp;#34;vault-0&amp;#34; and unseal it. Use the following command and provide one of the keys:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti -n vault vault-0 -- vault operator unseal
Unseal Key (will be hidden):
Key Value
--- -----
Seal Type shamir
Initialized true &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Sealed true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
Total Shares 5
Threshold 3
Unseal Progress 1/3 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
Unseal Nonce 08b01535-be15-e865-251c-f948ed0661c9
Version 1.11.2
Build Date 2022-07-29T09:48:47Z
Storage Type raft
HA Enabled true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Vault is initialized&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Vault is still sealed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The unseal progress: Currently 1 out of 3 keys have been provided&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Use the same command another 2 times using &lt;strong>different&lt;/strong> keys to complete the unseal process:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>At the end the following output should be shown:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Unseal Key (will be hidden):
Key Value
--- -----
Seal Type shamir
Initialized true
Sealed false &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Total Shares 5
Threshold 3
Version 1.11.2
Build Date 2022-07-29T09:48:47Z
Storage Type raft
Cluster Name vault-cluster-f7402e5b &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
Cluster ID aff648f0-b3a2-1fdd-12f6-492842b08b2b
HA Enabled true
HA Cluster https://vault-0.vault-internal:8201
HA Mode active &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
Active Since 2022-08-16T07:20:45.828215961Z
Raft Committed Index 36
Raft Applied Index 36&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Vault is now unsealed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Name of our cluster&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>High availability is enabled&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>Vault-0&lt;/strong> is now initialized, but there are 2 other members in our HA cluster which must be added.
Let &lt;strong>vault-1&lt;/strong> and &lt;strong>vault-2&lt;/strong> join the cluster and perform the same unseal process as previously: use 3 different keys:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti vault-1 -n vault -- vault operator raft join http://vault-0.vault-internal:8200
# 3 times....
oc exec -ti vault-1 -n vault -- vault operator unseal
oc exec -ti vault-2 -n vault -- vault operator raft join http://vault-0.vault-internal:8200
# 3 times...
oc exec -ti vault-2 -n vault -- vault operator unseal&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verify_vault_cluster">Verify Vault Cluster&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>To verify if the Raft cluster has successfully been initialized, run the following.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First, login using the &lt;strong>root_token&lt;/strong>, that was created above, on the vault-0 pod.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti vault-0 -n vault -- vault login
Token (will be hidden): &amp;lt;root_token&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti vault-0 -n vault -- vault operator raft list-peers&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This should return:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Node Address State Voter
---- ------- ----- -----
16ec7490-f621-42ea-976d-5f054cfaeecc vault-0.vault-internal:8201 leader true
60ba2885-432a-c7d3-d280-a824f0acce42 vault-1.vault-internal:8201 follower true
bcc4f551-79bc-47e5-d01b-97fc12d1afa5 vault-2.vault-internal:8201 follower true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see Vault-0 is the leader while the other two members are followers.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_kubernetes_authentication">Configure Kubernetes Authentication&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>There are multiple ways how an application can interact with Vault. One example is to use Tokens. This is quite easy but has the disadvantage that it does require additional steps of managing the life cycle of such token, moreover they might be shared, which is not what we want.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>HashiCorp Vault supports different authentication methods. One of which is the &lt;strong>Kubernetes Auth Method&lt;/strong> that must be enabled before we can use.
The Kubernetes Auth Method makes use of Jason Web Tokens (JWT)s that are bound to a Service Account. When we tell Vault that a Service Account is fine to authenticate, then a Deployment using this account is able to authenticate and
request Secrets.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Vault has a plugin ecosystem, which allows to enable certain plugins. To enable &lt;strong>Kubernetes Auth Method&lt;/strong> use the following process:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Login vault-0 pods
&lt;code>oc exec -it vault-0 -n vault — /bin/sh&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>execute the command:
&lt;code>vault auth enable kubernetes&lt;/code> which returns:
&lt;em>Success! Enabled kubernetes auth method at: kubernetes/&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set up the Kubernetes configuration to use Vault’s service account JWT.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
the address to the OpenShift API (KUBERNETES_PORT_443_TCP_ADDR) is automatically available via an environment variable.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">vault write auth/kubernetes/config issuer=&amp;#34;&amp;#34; \
token_reviewer_jwt=&amp;#34;$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&amp;#34; \
kubernetes_host=&amp;#34;https://$KUBERNETES_PORT_443_TCP_ADDR:443&amp;#34; \
kubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
Success! Data written to: auth/kubernetes/config&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With this step authentication against OpenShift is enabled.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_a_secret">Configure a Secret&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>With the Kubernetes Auth Method in place we can configure a secret to test our setup. We will use an example application called &lt;strong>expenses&lt;/strong> that has a MySQL database.
The static password to bootstrap this database shall be stored in Vault. A plugin called &lt;strong>key-value secrets&lt;/strong> engine will be used to achieve this.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There are other plugins that are specifically designed to automatically rotate secrets. For example, it is possible to dynamically create user credentials für MySQL.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
You can list available engines by using the command: &lt;code>oc -n vault exec -it vault-0 — vault secrets list&lt;/code>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There are currently two versions of this key/value engine:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>KV Version 1: does not versionize the key/values, thus updates will overwrite the old values.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>KV Version 2: does versionize the key/value pairs&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our example we will use version 2.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Like the authentication method, we need to enable the secrets engine:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault secrets enable \
-path=expense/static \ &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
-version=2 \ &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
kv &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>API path where our secrets are stored&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Version 2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>name of our engine&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can list the enabled engines with the following command:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault secrets list
Path Type Accessor Description
---- ---- -------- -----------
cubbyhole/ cubbyhole cubbyhole_f1e955f9 per-token private secret storage
expense/static/ kv kv_6db09e5d n/a
identity/ identity identity_ca05e6ab identity store &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
sys/ system system_e34a76c3 system endpoints used for control, policy and debugging&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Enabled KV secrets engine using the path &lt;strong>expense/static/&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now lets put a secret into our store. We will store our super-secure MySQL password into &lt;strong>expense/static/mysql&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">MYSQL_DB_PASSWORD=mysuperpassword$
oc -n vault exec -it vault-0 -- vault kv put expense/static/mysql db_login_password=${MYSQL_DB_PASSWORD}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This command will store the key &lt;strong>db_login_password&lt;/strong> with the database as value. We can get the secret by calling:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault kv get expense/static/mysql
====== Secret Path ======
expense/static/data/mysql &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
======= Metadata =======
Key Value
--- -----
created_time 2022-08-17T06:08:05.839663508Z
custom_metadata &amp;lt;nil&amp;gt;
deletion_time n/a
destroyed false
version 1
========== Data ==========
Key Value
--- -----
db_login_password mysuperpassword$ &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The data path of our secret&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>our password&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuring_policies">Configuring policies&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The Secret is now stored at &lt;strong>expense/static/mysql&lt;/strong> but there is no policy in place. Everybody who is authenticated and is calling this path will get to see the secrets.
Luckily, one or more policies can be assigned to the authentication method. A policy defines capabilities that allow you to perform certain actions.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following capabilities are known:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>create&lt;/strong> - to create new data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>read&lt;/strong> - to read data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>delete&lt;/strong> - to delete data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>list&lt;/strong> - to list data&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Policies can be written either in JSON or HCL (HashiCorp Configuration Language). Let’s create a file with the following content:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">path &amp;#34;expense/static/data/mysql&amp;#34; {
capabilities = [&amp;#34;read&amp;#34;, &amp;#34;list&amp;#34;]
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
KV Version2 stores the secrets in a path with the prefix &lt;code>data/&lt;/code>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will limit my access to &lt;strong>read&lt;/strong> and &lt;strong>list&lt;/strong> only.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Write the policy:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">cat my-policy.hcl | oc -n vault exec -it vault-0 -- vault policy write expense-db-mysql -&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next, we are going to bind the Vault secret to a service account and a namespace. Both objects will be created later, when we deploy the application.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault write auth/kubernetes/role/expense-db-mysql \ &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
bound_service_account_names=expense-db-mysql \ &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
bound_service_account_namespaces=expenses \ &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
policies=expense-db-mysql \ &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
ttl=1h &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Path or our new role&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Name of the service account we will create and that will be used by the application&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Name of the namespace we will create&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Name of the policy we created earlier&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The token is valid for 1 hour, after this period the service account must re-authenticate&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_lets_start_an_application">Let’s start an Application&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now we will create our MySQL application into the namespace &lt;strong>expenses&lt;/strong>. Use the following command to create the namespace and the application containing the objects Deployment, ServiceAccount (expense-db-mysql) and Service.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
See at the &lt;a href="https://raw.githubusercontent.com/joatmon08/vault-argocd/part-1/database/deployment.yaml" target="_blank" rel="noopener">Github Page&lt;/a> for a full yaml specification of the three objects.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc new-project expenses
oc apply -f https://raw.githubusercontent.com/joatmon08/vault-argocd/part-1/database/deployment.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The deployment will start a Pod with a sidecar container &lt;strong>vault-agent&lt;/strong>. This sidecar is automatically created and must not be defined inside the Deployment specification.
Instead, some annotations in the Deployment define what the container should be automatically injected and also where to find our secret:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> annotations:
vault.hashicorp.com/agent-inject: &amp;#34;true&amp;#34; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
vault.hashicorp.com/role: &amp;#34;expense-db-mysql&amp;#34; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
vault.hashicorp.com/agent-inject-secret-db: &amp;#34;expense/static/data/mysql&amp;#34; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
vault.hashicorp.com/agent-inject-template-db: | &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
{{ with secret &amp;#34;expense/static/data/mysql&amp;#34; -}}
export MYSQL_ROOT_PASSWORD=&amp;#34;{{ .Data.data.db_login_password }}&amp;#34;
{{- end }}
...
spec:
serviceAccountName: expense-db-mysql &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Defines that the &lt;strong>vault-agent&lt;/strong> side car container shall be automatically injected. This is the most important annotation.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Name of the role that was created created previously&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The agent will inject the data from &lt;strong>expense/static/data/mysql&lt;/strong> and stores it in a file &lt;strong>db&lt;/strong> The file name is everything that comes after &lt;strong>vault.hashicorp.com/agent-inject-secret-&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Configuration…​ the template that defines how the secret will be rendered&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The service account name we bound our secret to, using the Consul language. In this case the MySQL password is simply exported&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The vault-agent is requesting the database password from Vault and provides it to the application where it is stored at &lt;code>/vault/secrets/db&lt;/code>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n expenses exec -it $(oc get pods -l=app=expense-db-mysql -o jsonpath=&amp;#39;{.items[0].metadata.name}&amp;#39;) -c expense-db-mysql -- cat /vault/secrets/db
# output
export MYSQL_ROOT_PASSWORD=&amp;#34;mysuperpassword$&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Deployment sources this file when it starts and MySQL will take this information to configure itself.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_tip_using_vault_cli_on_your_local_environment">TIP: Using vault CLI on your local environment&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>All above commands that are dealing with Vault commands, first login to a pod and then execure the commands from there.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you have the &lt;a href="https://www.vaultproject.io/docs/install" target="_blank" rel="noopener">Vault CLI&lt;/a> installed on your local machine, you can open a port forwarding to your Vault cluster at OpenShift and execute the commands locally:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc port-forward -n vault svc/vault 8200
export VAULT_ADDR=http://localhost:8200
vault login
...&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_thanks">Thanks&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Thanks to the wonderful Rosemary Wang and her Github repository: &lt;a href="https://github.com/joatmon08/vault-argocd/tree/part-1" class="bare">https://github.com/joatmon08/vault-argocd/tree/part-1&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also check out the Youtube Video: &lt;a href="https://www.youtube.com/watch?v=Bce_0qa6ias" target="_blank" rel="noopener">GitOps Guide to the Galaxy (Ep 31) | GitOps With Vault Part 1&lt;/a> in which Rosemary and Christian discuss this setup&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Automated ETCD Backup</title><link>https://blog.stderr.at/day-2/etcd/2022-01-29-automatedetcdbackup/</link><pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/day-2/etcd/2022-01-29-automatedetcdbackup/</guid><description>&lt;div class="paragraph">
&lt;p>Securing ETCD is one of the major Day-2 tasks for a Kubernetes cluster. This article will explain how to create a backup using OpenShift Cronjob.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
There is absolutely no warranty. Verify your backups regularly and perform restore tests.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following is required:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift Cluster 4.x&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Integrated Storage, might be NFS or anything. Best practice would be a RWX enabled storage.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_project_cronjob">Configure Project &amp;amp; Cronjob&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Create the following objects in OpenShift. This fill create:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>A Project called &lt;code>ocp-etcd-backup&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A PersistentVolumeClaim to store the backups. &lt;strong>Change to your appropriate StorageClass and accessMode&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A ServiceAccount called &lt;code>openshift-backup&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A dedicated ClusterRole which is able to start (debug pods)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A ClusterRoleBinding between the created ServiceAccount and the customer ClusterRole&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A 2nd ClusterRoleBinding, which gives our ServiceAccount the permission to start privileged containers. This is required to start a debug pod on a control plane node.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A CronJob which performs the backup …​ see Callouts for inline explanations.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
A helm chart, which would create these objects below, can be found at: &lt;a href="https://github.com/tjungbauer/ocp-auto-backup" class="bare">https://github.com/tjungbauer/ocp-auto-backup&lt;/a>. This is probably a better way to manage the variables via the values.yaml file.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Namespace
apiVersion: v1
metadata:
name: ocp-etcd-backup
annotations:
openshift.io/description: Openshift Backup Automation Tool
openshift.io/display-name: Backup ETCD Automation
openshift.io/node-selector: &amp;#39;&amp;#39;
spec: {}
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
name: etcd-backup-pvc
namespace: ocp-etcd-backup
spec:
accessModes:
- ReadWriteOnce &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
resources:
requests:
storage: 100Gi
storageClassName: gp2
volumeMode: Filesystem
---
kind: ServiceAccount
apiVersion: v1
metadata:
name: openshift-backup
namespace: ocp-etcd-backup
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
name: cluster-etcd-backup
rules:
- apiGroups: [&amp;#34;&amp;#34;]
resources:
- &amp;#34;nodes&amp;#34;
verbs: [&amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;]
- apiGroups: [&amp;#34;&amp;#34;]
resources:
- &amp;#34;pods&amp;#34;
- &amp;#34;pods/log&amp;#34;
verbs: [&amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;create&amp;#34;, &amp;#34;delete&amp;#34;, &amp;#34;watch&amp;#34;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: openshift-backup
subjects:
- kind: ServiceAccount
name: openshift-backup
namespace: ocp-etcd-backup
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: cluster-etcd-backup
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
name: etcd-backup-scc-privileged
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: system:openshift:scc:privileged
subjects:
- kind: ServiceAccount
name: openshift-backup
namespace: ocp-etcd-backup
---
kind: CronJob
apiVersion: batch/v1
metadata:
name: cronjob-etcd-backup
namespace: ocp-etcd-backup
labels:
purpose: etcd-backup
spec:
schedule: &amp;#39;*/5 * * * *&amp;#39; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
startingDeadlineSeconds: 200
concurrencyPolicy: Forbid
suspend: false
jobTemplate:
metadata:
creationTimestamp: null
spec:
backoffLimit: 0
template:
metadata:
creationTimestamp: null
spec:
nodeSelector:
node-role.kubernetes.io/master: &amp;#39;&amp;#39; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
restartPolicy: Never
activeDeadlineSeconds: 200
serviceAccountName: openshift-backup
schedulerName: default-scheduler
hostNetwork: true
terminationGracePeriodSeconds: 30
securityContext: {}
containers:
- resources:
requests:
cpu: 300m
memory: 250Mi
terminationMessagePath: /dev/termination-log
name: etcd-backup
command: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- /bin/bash
- &amp;#39;-c&amp;#39;
- &amp;gt;-
oc get no -l node-role.kubernetes.io/master --no-headers -o
name | grep `hostname` | head -n 1 | xargs -I {} -- oc debug
{} -- bash -c &amp;#39;chroot /host sudo -E
/usr/local/bin/cluster-backup.sh /home/core/backup&amp;#39; ; echo
&amp;#39;Moving Local Master Backups to target directory (from
/home/core/backup to mounted PVC)&amp;#39;; mv /home/core/backup/*
/etcd-backup/; echo &amp;#39;Deleting files older than 30 days&amp;#39; ; find
/etcd-backup/ -type f -mtime +30 -exec rm {} \;
securityContext:
privileged: true
runAsUser: 0
imagePullPolicy: IfNotPresent
volumeMounts:
- name: temp-backup
mountPath: /home/core/backup &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
- name: etcd-backup
mountPath: /etcd-backup &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
terminationMessagePolicy: FallbackToLogsOnError
image: registry.redhat.io/openshift4/ose-cli
serviceAccount: openshift-backup
volumes:
- name: temp-backup
hostPath:
path: /home/core/backup
type: &amp;#39;&amp;#39;
- name: etcd-backup
persistentVolumeClaim:
claimName: etcd-backup-pvc
dnsPolicy: ClusterFirst
tolerations:
- operator: Exists
effect: NoSchedule
- operator: Exists
effect: NoExecute
successfulJobsHistoryLimit: 5
failedJobsHistoryLimit: 5&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>RWO is used here, since I have no other available storage on my test cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>How often shall the job be executed. Here, every 5 minutes.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Bind the job to &amp;#34;Master&amp;#34; nodes.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Command to be executed…​ It fetches the actual local master nodename and starts a debugging Pod there. The backup script is called and moves the backup to /home/core/backup which is a folder on the control plane itself. The move command will move the backups from the local folder to the actual backup target volume. Finally, it will remove backups older than 30 days.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Mounted /home/core/backup on the master nodes, here the command will store the backups before they are moved&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>Target destination for the etcd backup on the mounted PVC&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_start_a_job">Start a Job&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>If you do not want to wait until the CronJob is triggered, you can manually start the Job using the following commands:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc create job backup --from=cronjob/cronjob-etcd-backup -n ocp-etcd-backup&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will start a Pod which will do the backup:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code>Starting pod/ip-10-0-196-187us-east-2computeinternal-debug ...
To use host binaries, run `chroot /host`
found latest kube-apiserver: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-15
found latest kube-controller-manager: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-10
found latest kube-scheduler: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-9
found latest etcd: /etc/kubernetes/static-pod-resources/etcd-pod-3
etcdctl is already installed
{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1638199790.980932,&amp;#34;caller&amp;#34;:&amp;#34;snapshot/v3_snapshot.go:119&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;created temporary db file&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/home/core/backup/snapshot_2021-11-29_152949.db.part&amp;#34;}
{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:&amp;#34;2021-11-29T15:29:50.991Z&amp;#34;,&amp;#34;caller&amp;#34;:&amp;#34;clientv3/maintenance.go:200&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;opened snapshot stream; downloading&amp;#34;}
{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1638199790.9912837,&amp;#34;caller&amp;#34;:&amp;#34;snapshot/v3_snapshot.go:127&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;fetching snapshot&amp;#34;,&amp;#34;endpoint&amp;#34;:&amp;#34;https://10.0.196.187:2379&amp;#34;}
{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:&amp;#34;2021-11-29T15:29:53.306Z&amp;#34;,&amp;#34;caller&amp;#34;:&amp;#34;clientv3/maintenance.go:208&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;completed snapshot read; closing&amp;#34;}
Snapshot saved at /home/core/backup/snapshot_2021-11-29_152949.db
{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1638199793.3482974,&amp;#34;caller&amp;#34;:&amp;#34;snapshot/v3_snapshot.go:142&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;fetched snapshot&amp;#34;,&amp;#34;endpoint&amp;#34;:&amp;#34;https://10.0.196.187:2379&amp;#34;,&amp;#34;size&amp;#34;:&amp;#34;180 MB&amp;#34;,&amp;#34;took&amp;#34;:2.367303503}
{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;ts&amp;#34;:1638199793.348459,&amp;#34;caller&amp;#34;:&amp;#34;snapshot/v3_snapshot.go:152&amp;#34;,&amp;#34;msg&amp;#34;:&amp;#34;saved&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;/home/core/backup/snapshot_2021-11-29_152949.db&amp;#34;}
{&amp;#34;hash&amp;#34;:1180914745,&amp;#34;revision&amp;#34;:10182252,&amp;#34;totalKey&amp;#34;:19360,&amp;#34;totalSize&amp;#34;:179896320}
snapshot db and kube resources are successfully saved to /home/core/backup
Removing debug pod ...
Moving Local Master Backups to target directory (from /home/core/backup to mounted PVC)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verifying_the_backup">Verifying the Backup&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Let’s start a dummy Pod which can access the PVC to verify if the backup is really there.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
name: verify-etcd-backup
spec:
containers:
- name: verify-etcd-backup
image: registry.access.redhat.com/ubi8/ubi
command: [&amp;#34;sleep&amp;#34;, &amp;#34;3000&amp;#34;]
volumeMounts:
- name: etcd-backup
mountPath: /etcd-backup
volumes:
- name: etcd-backup
persistentVolumeClaim:
claimName: etcd-backup-pvc&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Logging into that Pod will show the available backups stored at /etcd-backup which is the mounted PVC.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc rsh -n ocp-etcd-backup verify-etcd-backup ls -la etcd-backup
total 1406196
drwxr-xr-x. 3 root root 4096 Nov 29 17:00 .
dr-xr-xr-x. 1 root root 25 Nov 29 17:06 ..
drwx------. 2 root root 16384 Nov 29 15:21 lost+found
-rw-------. 1 root root 179896352 Nov 29 15:21 snapshot_2021-11-29_152150.db
-rw-------. 1 root root 179896352 Nov 29 15:29 snapshot_2021-11-29_152949.db
-rw-------. 1 root root 179896352 Nov 29 15:32 snapshot_2021-11-29_153159.db
-rw-------. 1 root root 179896352 Nov 29 15:36 snapshot_2021-11-29_153618.db
-rw-------. 1 root root 179896352 Nov 29 15:55 snapshot_2021-11-29_155513.db
-rw-------. 1 root root 179896352 Nov 29 16:00 snapshot_2021-11-29_160020.db
-rw-------. 1 root root 179896352 Nov 29 16:55 snapshot_2021-11-29_165521.db
-rw-------. 1 root root 179896352 Nov 29 17:00 snapshot_2021-11-29_170020.db
-rw-------. 1 root root 89875 Nov 29 15:21 static_kuberesources_2021-11-29_152150.tar.gz
-rw-------. 1 root root 89875 Nov 29 15:29 static_kuberesources_2021-11-29_152949.tar.gz
-rw-------. 1 root root 89875 Nov 29 15:32 static_kuberesources_2021-11-29_153159.tar.gz
-rw-------. 1 root root 89875 Nov 29 15:36 static_kuberesources_2021-11-29_153618.tar.gz
-rw-------. 1 root root 89875 Nov 29 15:55 static_kuberesources_2021-11-29_155513.tar.gz
-rw-------. 1 root root 89875 Nov 29 16:00 static_kuberesources_2021-11-29_160020.tar.gz
-rw-------. 1 root root 89875 Nov 29 16:55 static_kuberesources_2021-11-29_165521.tar.gz
-rw-------. 1 root root 89875 Nov 29 17:00 static_kuberesources_2021-11-29_170020.tar.gz&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Advanced Cluster Security - Authentication</title><link>https://blog.stderr.at/acs/2021-12-11-acsauth/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/acs/2021-12-11-acsauth/</guid><description>&lt;div class="paragraph">
&lt;p>Red Hat Advanced Cluster Security (RHACS) Central is installed with one administrator user by default. Typically, customers request an integration with existing Identity Provider(s) (IDP). RHACS offers different options for such integration. In this article 2 IDPs will be configured as an example. First OpenShift Auth and second Red Hat Single Sign On (RHSSO) based on Keycloak&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>OpenShift 4 Cluster&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Advanced Cluster Security v3.66+&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Red Hat SSO Operator installed&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
While RHSSO will be installed during this article, only default and example values are used. These are by no means examples for a production system.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_introduction">Introduction&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Advanced Cluster Security comes with several default roles, which can be assigned to users:&lt;/p>
&lt;/div>
&lt;table class="tableblock frame-all grid-all stretch">
&lt;colgroup>
&lt;col style="width: 33.3333%;"/>
&lt;col style="width: 66.6667%;"/>
&lt;/colgroup>
&lt;thead>
&lt;tr>
&lt;th class="tableblock halign-left valign-top">System role&lt;/th>
&lt;th class="tableblock halign-left valign-top">Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">Admin&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">This role is targeted for administrators. Use it to provide read and write access to all resources.&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">Analyst&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">This role is targeted for a user who cannot make any changes, but can view everything. Use it to provide read-only access for all resources.&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">Continuous Integration&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">This role is targeted for CI (continuous integration) systems and includes the permission set required to enforce deployment policies.&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">None&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">This role has no read and write access to any resource. You can set this role as the minimum access role for all users.&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">Sensor Creator&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">Red Hat Advanced Cluster Security for Kubernetes uses this role to automate new cluster setups. It includes the permission set to create Sensors in secured clusters.&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">Scope Manager&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">This role includes the minimum permissions required to create and modify access scopes.&lt;/p>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
It is possible to create custom roles.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_rhacs_authentication_openshift_auth">Configure RHACS Authentication: OpenShift Auth&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
It is assumed that RHACS is already installed and login to the Central UI is available.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Login to your RHACS and select “Platform Configuration” &amp;gt; “Access Control”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the drop down menu &lt;strong>Add auth provider&lt;/strong> select &lt;strong>OpenShift Auth&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/acs/images/ACS-AuthProvider.png?width=940px" alt="ACS AuthProvider"/>
&lt;/div>
&lt;div class="title">Figure 1. ACS Auth Provider&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Enter a &lt;strong>Name&lt;/strong> for your provider and select a default role which is assigned to any user who can authenticate.&lt;/p>
&lt;div class="paragraph">
&lt;p>It is recommended to select the role &lt;strong>None&lt;/strong>, so new accounts will have no privileges in RHACS.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With Rules you can assign roles to specific users, based on their userid, name, mail address or groups.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For example the user with the name &lt;strong>poweruser&lt;/strong> gets the role &lt;strong>Admin&lt;/strong> assigned.&lt;/p>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verify_authentication_with_openshift_auth">Verify Authentication with OpenShift Auth&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Logout from the Central UI and reload the browser.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select from the drop down &lt;strong>OpenShift Auth&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/acs/images/ACS-LoginOpenShiftAuth.png?width=420px" alt="ACS LoginOpenShiftAuth"/>
&lt;/div>
&lt;div class="title">Figure 2. ACS Login&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Try to login with a valid OpenShift user.&lt;br/>
Depending on the Rules which have been defined during previous steps the appropriate permissions should be assigned.&lt;br/>
For example: If you login as user &lt;strong>poweruser&lt;/strong> the role &lt;strong>Admin&lt;/strong> is assigned.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;hr/>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_red_hat_single_sign_on">Configure Red Hat Single Sign On&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following steps will create some basic example objects to an existing RHSSO or Keycloak to test the authentication at RHACS.
Skip to step #5 if you have Keycloak already up and running and would like to reuse an existing client.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The RHSSO operator (or Keycloak) is installed at the namespace &lt;strong>single-sign-on&lt;/strong>.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Create an instance of Keycloak&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: keycloak.org/v1alpha1
kind: Keycloak
metadata:
name: example-keycloak
namespace: single-sign-on
spec:
externalAccess:
enabled: true
instances: 1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a Realm&lt;br/>
This will create a Realm called &lt;strong>Basic&lt;/strong>&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: keycloak.org/v1alpha1
kind: KeycloakRealm
metadata:
name: example-keycloakrealm
namespace: single-sign-on
spec:
instanceSelector:
matchLabels:
app: sso
realm:
displayName: Basic Realm
enabled: true
id: basic
realm: basic&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Login into Red Hat SSO&lt;br/>
Get the route to your RHSSO instance:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get route keycloak -n single-sign-on --template=&amp;#39;{{ .spec.host }}&amp;#39;
# keycloak-single-sign-on.apps.cluster-29t8z.29t8z.sandbox677.opentlc.com&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>and log into the Administration Interface.&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Extract the admin password for Keycloak&lt;/p>
&lt;div class="paragraph">
&lt;p>The secret name is build from &amp;#34;credential&amp;#34;&amp;lt;keycloak-instance-name&amp;gt;&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/credential-example-keycloak -n single-sign-on --to=-
# ADMIN_PASSWORD
&amp;lt;you password&amp;gt;
# ADMIN_USERNAME
admin&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Be sure to select your Realm (&lt;strong>Basic&lt;/strong> in our case), goto &lt;strong>Clients&lt;/strong> and select a ClientID.&lt;/p>
&lt;div class="olist loweralpha">
&lt;ol class="loweralpha" type="a">
&lt;li>
&lt;p>In this example we select &lt;strong>account&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/acs/images/ACS-SSOClientConfig.png?width=640px" alt="ACS SSOClientConfig"/>
&lt;/div>
&lt;div class="title">Figure 3. ACS Login&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Of course you can create or use any other Client.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Enable the option &lt;strong>Implicit Flow&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Get the &lt;strong>Issuer URL&lt;/strong> from your realm. This is typically your:&lt;br/>
&lt;a href="https://&amp;lt;KEYCLOAK_URL&amp;gt;/auth/realms/&amp;lt;REALM_NAME&amp;gt;" class="bare">https://&amp;lt;KEYCLOAK_URL&amp;gt;/auth/realms/&amp;lt;REALM_NAME&amp;gt;&lt;/a>;&lt;/p>
&lt;div class="paragraph">
&lt;p>For Example:
&lt;a href="https://keycloak-single-sign-on.apps.cluster-29t8z.29t8z.sandbox677.opentlc.com/auth/realms/basic" class="bare">https://keycloak-single-sign-on.apps.cluster-29t8z.29t8z.sandbox677.opentlc.com/auth/realms/basic&lt;/a>&lt;/p>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_create_test_users">Create Test Users&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In RHSSO create 2 user accounts to test the authentication later.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Goto &lt;strong>Users&lt;/strong> and create the users:&lt;/p>
&lt;div class="olist loweralpha">
&lt;ol class="loweralpha" type="a">
&lt;li>
&lt;p>User: acsadmin&lt;/p>
&lt;div class="paragraph">
&lt;p>First Name: acsadmin&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>User: user1&lt;/p>
&lt;div class="paragraph">
&lt;p>First Name: user 1&lt;/p>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>You can set any other values for these users. However, be sure to set a password for both, after they have been created.&lt;/strong>&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_rhacs_authentication_rhsso">Configure RHACS Authentication: RHSSO&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
It is assumed that RSACS is already installed and login to the Central UI is available.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Login to your RHACS and select “Platform Configuration” &amp;gt; “Access Control”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From the drop down menu &lt;strong>Add auth provider&lt;/strong> select &lt;strong>OpenID Connect&lt;/strong>&lt;/p>
&lt;div class="olist loweralpha">
&lt;ol class="loweralpha" type="a">
&lt;li>
&lt;p>Enter a “Name” for your provider i.e. “Single Sign On”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Leave the “Callback Mode” to the “Auto-Select” setting&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Enter your Issuer URL&lt;/p>
&lt;/li>
&lt;li>
&lt;p>As Client ID enter &lt;strong>account&lt;/strong> (or the ClientID you would like to use)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Leave the Client Secret empty and select the checkbox &lt;strong>Do not use Client Secret&lt;/strong> which is good enough for our tests.&lt;/p>
&lt;div class="paragraph">
&lt;p>Remember the two callback URL from the blue box. They must be configured in Keycloak.&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Select a default role which is assigned to any user who can authenticate.&lt;/p>
&lt;div class="paragraph">
&lt;p>It is recommended to select the role &lt;strong>None&lt;/strong>, so new accounts will have no privileges in RHACS.&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>With Rules you can assign roles to specific users, based on their userid, name, mail address or groups.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For example the user with the name &lt;strong>acsadmin&lt;/strong> (which have been created previously in our RHSSO) gets the role &lt;strong>Admin&lt;/strong> assigned.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The final settings are depict in the following image:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/acs/images/ACS-OpenIDConfig.png?width=640px" alt="ACS OpenIDConfig"/>
&lt;/div>
&lt;div class="title">Figure 4. ACS Login&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_continue_rhsso_configuration">Continue RHSSO Configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>What is left to do is the configuration of redirect URLs. These URLs are shown in the ACS Authentication Provider configuration (see blue field in the image above)&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Log back into RHSSO and select “Clients” &amp;gt; “account”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Into &lt;strong>Valid Redirect URLs&lt;/strong> enter the two URLs which you saved from the blue box in the RHACS configuration.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_troubleshoot_test_login">Troubleshoot: Test Login&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In RHACS you can test the login to you SSO.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Goto &amp;#34;Platform Configuration&amp;#34; &amp;gt; &amp;#34;Access Control&amp;#34;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Click the button &amp;#34;Test login&amp;#34;&lt;/p>
&lt;div class="paragraph">
&lt;p>A popup will appear which asks you to enter SSO credentials. The connection to RHSSO will be validated:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/acs/images/ACS-TestSSOAuth.png?width=420px" alt="ACS TestSSOAuth"/>
&lt;/div>
&lt;div class="title">Figure 5. ACS Test SSO&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verify_authentication_with_openshift_auth_2">Verify Authentication with OpenShift Auth&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Logout from the Central UI and reload the browser.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Select from the drop down &lt;strong>Single Sign On&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/acs/images/ACS-LoginSSOAuth.png?width=420px" alt="ACS LoginSSOAuth"/>
&lt;/div>
&lt;div class="title">Figure 6. ACS Login SSO&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Try to login with a valid SSO user.&lt;br/>
Depending on the Rules which have been defined during previous steps the appropriate permissions should be assigned.&lt;br/>
For example: If you login as user &lt;strong>acsadmin&lt;/strong> the role &lt;strong>Admin&lt;/strong> is assigned.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Secure your secrets with Sealed Secrets</title><link>https://blog.stderr.at/openshift/2021/09/secure-your-secrets-with-sealed-secrets/</link><pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021/09/secure-your-secrets-with-sealed-secrets/</guid><description>&lt;div class="paragraph">
&lt;p>Working with a GitOps approach is a good way to keep all configurations and settings versioned and in sync on Git. Sensitive data, such as passwords to a database connection, will quickly come around.
Obviously, it is not a idea to store clear text strings in a, maybe even public, Git repository. Therefore, all sensitive information should be stored in a secret object. The problem with secrets in Kubernetes is that they are actually not encrypted. Instead, strings are base64 encoded which can be decoded as well. Thats not good …​ it should not be possible to decrypt secured data. Sealed Secret will help here…​&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Sealed Secrets by Bitnami[&lt;a href="#source_1">1&lt;/a>] is one option to create real, encrypted secrets. It contains two parts:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>A cluster-side controller / operator, which decrypts the secrets server-side on OpenShift installed in a dedicated namespace usually called &lt;code>sealed secrets&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>kubeseal&lt;/code> - a client-side command line tool&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>An OpenShift 4 cluster with cluster-admin permissions.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_sealed_secrets_operator">Sealed Secrets Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Goto &lt;strong>OperatorHub&lt;/strong> and search for Sealed Secrets (This is a Community Operator)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/sealed-secrets/sealed-secrets-operatorhub.png?width=480px" alt="Search Sealed Secrets in OperatorHub"/>
&lt;/div>
&lt;div class="title">Figure 1. Search Sealed Secrets in OperatorHub&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Install the operator, using the default settings, into the namespace &lt;code>sealed-secrets&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/sealed-secrets/sealed-secrets-operator-install.png?width=480px" alt="Installed Sealed Secret Operator"/>
&lt;/div>
&lt;div class="title">Figure 2. Installed Sealed Secret Operator&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_install_the_crd_sealedsecretcontroller">Install the CRD SealedSecretController&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Install the following object. For now the default values can be used.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: bitnami.com/v1alpha1
kind: SealedSecretController
metadata:
name: controller &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: sealed-secrets
spec:
networkPolicy: false
nodeSelector: {}
podLabels: {}
resources: {}
affinity: {}
securityContext:
fsGroup: &amp;#39;&amp;#39;
runAsUser: &amp;#39;&amp;#39;
rbac:
create: true
pspEnabled: false
crd:
create: true
keep: true
ingress:
annotations: {}
enabled: false
hosts:
- chart-example.local
path: /v1/cert.pem
tls: []
serviceAccount:
create: true
name: &amp;#39;&amp;#39;
image:
pullPolicy: IfNotPresent
repository: &amp;gt;-
quay.io/bitnami/sealed-secrets-controller@sha256:8e9a37bb2e1a6f3a8bee949e3af0e9dab0d7dca618f1a63048dc541b5d554985
secretName: sealed-secrets-key
tolerations: []
controller:
create: true
priorityClassName: &amp;#39;&amp;#39;
podAnnotations: {}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Be aware of the name of the controller OBJECT (name: controller). It is used lated as part of the actual controller name&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_install_the_command_line_tool_kubeseal">Install the command line tool kubeseal&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The kubeseal binary can be easily installed using either&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>on Mac: &lt;code>brew install kubeseal&lt;/code> or&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>on Linux:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.16.0/kubeseal-linux-amd64 -O kubeseal
install -m 755 kubeseal /usr/local/bin/&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_testing_sealed_secrets">Testing Sealed Secrets&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Create a new project &lt;code>oc new-project myproject&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a secret&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">echo -n &amp;#34;my_super_secret_string&amp;#34; \
| kubectl create secret generic mypasswords --dry-run=client --from-file=password=/dev/stdin -o json \
| kubeseal --controller-namespace=sealed-secrets --controller-name=controller-sealed-secrets --format json &amp;gt; mysealedsecret.json &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The switches --controller-namespace define the namespace where the operator is installed, --controller-name is a combination of the SealedSecretController object name and the name of the namespace&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;code>password=my_super_secret_string&lt;/code> is created and piped into &lt;strong>kubeseal&lt;/strong> which is using the controller, where the server created a certificate for encryption, to create an encrypted json file &lt;strong>mysealedsecret.json&lt;/strong>. It is important to note, that the actually Kubernetes secret object is not created at this stage.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The file &lt;strong>mysealedsecret.json&lt;/strong> is encrypted now and it is safe to store this file on Github.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>It looks like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">{
&amp;#34;kind&amp;#34;: &amp;#34;SealedSecret&amp;#34;,
&amp;#34;apiVersion&amp;#34;: &amp;#34;bitnami.com/v1alpha1&amp;#34;,
&amp;#34;metadata&amp;#34;: {
&amp;#34;name&amp;#34;: &amp;#34;mypasswords&amp;#34;,
&amp;#34;namespace&amp;#34;: &amp;#34;myproject&amp;#34;, &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
&amp;#34;creationTimestamp&amp;#34;: null
},
&amp;#34;spec&amp;#34;: {
&amp;#34;template&amp;#34;: {
&amp;#34;metadata&amp;#34;: {
&amp;#34;name&amp;#34;: &amp;#34;mypasswords&amp;#34;,
&amp;#34;namespace&amp;#34;: &amp;#34;myproject&amp;#34;, &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
&amp;#34;creationTimestamp&amp;#34;: null
},
&amp;#34;data&amp;#34;: null
},
&amp;#34;encryptedData&amp;#34;: {
&amp;#34;password&amp;#34;: &amp;#34;AgBsSZVcTfzfNFI7ZlCsH3/4b3L7m52/O9f70pMtn1myPWHeY1QJFoxpWkH0tWosfeIoko+iB0kCyFk/iJEYSvd31zgnr90hv4e2qVtEBmm6n5B7V40ZERdiy2Cz7UXakUKDdhTjA0BTjcf0f0b2FRDenGxCHJB7cyOVGOZ36jF6IdP2k6kbsZXklti/4MXK7oskDXGzU7rTsESK0ttk5uQgrpfWrhaUip5+Db5vcG1OlHhMJ7In3NlNr0mbl+YiXsKKDNvyw9T14L3rlfvHz1xe0lIqC72i5LSCarpGoSKNOr+Sev9+b/+no6P4VDPuSLORbwVXlP5kt+8xnpZJIEqnetwhr78dt8F3xmjXVBZncdwKk22Y/b9L+uUKWPAvOT78khpUIHQPo9dV/nmz1ldvu58fCFL4TjOOtyTBcUPD3qQJp+sEXgy63l8hEaMXuLUlk+srSnJfMtwkFhl0CG2fKsg4CsQoZlvq5oKOl50sujg3Trv4W9qVVCYHA7BUXEj6J0DxjOCqSQixHRr7Z7JqIyhhdLYdHwMH80scsIb6Ok7keC82v1yae770NWWxJJ4M7Ieb2ERzgwy825gkdq9nx9I6fVxYJkkZlpKKoTvL0uno4sKjC1yQjCgW1vpiZeLIJO2f9TpvVdK2nrag0/gXPMboAL2BGnMPMwjR7OZm+iHq3NXNKiIV1aWRO4wkd/spWziLjOpeS7T1k9w4XxoACwv3g4it&amp;#34;
}
}
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The sealed secret will be created in your project&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Upload the sealed secret &lt;code>oc create -f mysealedsecret.json&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verify_secret">Verify Secret&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The object SealedSecret is created:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get SealedSecret
NAME AGE
mypasswords 3s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The SealedSecretController will decrypt the and store the secret in the namespace. This can take a few seconds:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get secret mypasswords
NAME TYPE DATA AGE
mypasswords Opaque 1 25s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Extract the secret and verify that your string has been stored as &amp;#34;normal&amp;#34; secret&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/mypasswords --to=-
# password
my_super_secret_string&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_updating_or_appending_new_values">Updating or appending new values&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The process for updateing or appending a secret is similar. The only difference is that a new value for the key string is new.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># Updaing string
echo -n &amp;#34;my_NEW_super_secret_string&amp;#34; \
| kubectl create secret generic mypasswords --dry-run=client --from-file=password=/dev/stdin -o json \
| kubeseal --controller-namespace=sealed-secrets --controller-name=controller-sealed-secrets --format json --merge-into mysealedsecret.json
# Appending
echo -n &amp;#34;my_appended_string&amp;#34; \
| kubectl create secret generic mypasswords --dry-run=client --from-file=appendedstring=/dev/stdin -o json \
| kubeseal --controller-namespace=sealed-secrets --controller-name=controller-sealed-secrets --format json --merge-into mysealedsecret.json&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be sure that you are in the namespace you want to install the secret
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Upload the sealed secret &lt;code>oc apply -f mysealedsecret.json&lt;/code> and extract it again to validate:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/mypasswords --to=-
# appendedstring
my_appended_string
# password
my_NEW_super_secret_string&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_sources">Sources&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a id="source_1">&lt;/a>[1]: &lt;a href="https://github.com/bitnami-labs/sealed-secrets" target="_blank" rel="noopener">Bitname Readme on Github&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>oc compliance command line plugin</title><link>https://blog.stderr.at/compliance/2021/07/oc-compliance-command-line-plugin/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/compliance/2021/07/oc-compliance-command-line-plugin/</guid><description>&lt;div class="paragraph">
&lt;p>As described at &lt;a href="https://blog.stderr.at/compliance/2021/07/compliance-operator/">Compliance Operator&lt;/a> the Compliance Operator can be used to scan the OpenShift cluster environment against security benchmark, like CIS.
Fetching the actual results might be a bit tricky tough.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With OpenShift 4.8 plugins to the &lt;code>oc&lt;/code> command are allowed. One of these plugin os &lt;code>oc compliance&lt;/code>, which allows you to easily fetch scan results, re-run scans and so on.
Let’s install and try it out.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installation">Installation&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>An oc plugin must be deployed into the same directory as the oc command itself.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following describes the building and installation of the plugin.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
You need Go installed on your node.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Clone the Git repository:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">git clone https://github.com/openshift/oc-compliance.git&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Build and install the plugin&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">make; make install
go build -o ./bin/oc-compliance ./cmd
which oc | xargs dirname | xargs -n1 cp ./bin/oc-compliance&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>The plugin allows the use of &lt;code>oc compliance&lt;/code>&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc compliance
You must specify a sub-command.
Usage:
oc-compliance [flags]
oc-compliance [command]
Available Commands:
bind Creates a ScanSettingBinding for the given parameters
controls Get a report of what controls you\&amp;#39;re complying with
fetch-fixes Download the fixes/remediations
fetch-raw Download raw compliance results
help Help about any command
rerun-now Force a re-scan for one or more ComplianceScans
view-result View a ComplianceCheckResult
Flags:
-h, --help help for oc-compliance
Use &amp;#34;oc-compliance [command] --help&amp;#34; for more information about a command.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_fetch_raw_results">Fetch Raw Results&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Without the oc-compliance plugin it was required to manually spin up a Pod and download the results from this Pod, where the PV is mounted.
Now, with a simple command we can select the ScanSettingBinding and define an output folder. For example:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc compliance fetch-raw &amp;lt;object-type&amp;gt; &amp;lt;object-name&amp;gt; -o &amp;lt;output-path&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Assuming the the compliance operator was configured as in the previous article, we have the ScanSettingBinding called &lt;code>cis-compliance&lt;/code>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc compliance fetch-raw scansettingbindings cis-compliance -n openshift-compliance -o /tmp/&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This starts downloading the result archives into /tmp&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Fetching results for cis-compliance scans: ocp4-cis-node-worker, ocp4-cis-node-master, ocp4-cis
Fetching raw compliance results for pod &amp;#39;raw-result-extractor-fxbw8&amp;#39;.Fetching raw compliance results for scan &amp;#39;ocp4-cis-node-worker&amp;#39;.........
The raw compliance results are avaliable in the following directory: /tmp/ocp4-cis-node-worker
Fetching raw compliance results for pod &amp;#39;raw-result-extractor-kqrw5&amp;#39;.Fetching raw compliance results for scan &amp;#39;ocp4-cis-node-master&amp;#39;.....
The raw compliance results are avaliable in the following directory: /tmp/ocp4-cis-node-master
Fetching raw compliance results for pod &amp;#39;raw-result-extractor-pfrgk&amp;#39;.Fetching raw compliance results for scan &amp;#39;ocp4-cis&amp;#39;..
The raw compliance results are avaliable in the following directory: /tmp/ocp4-cis
ls -la /tmp/ocp4-cis*
/tmp/ocp4-cis:
total 172
drwx------ 2 root root 4096 Jul 30 16:05 .
drwxrwxrwt. 18 root root 4096 Jul 30 16:05 ..
-rw-r--r-- 1 root root 166676 Jul 30 16:05 ocp4-cis-api-checks-pod.xml.bzip2
/tmp/ocp4-cis-node-master:
total 504
drwx------ 2 root root 4096 Jul 30 16:05 .
drwxrwxrwt. 18 root root 4096 Jul 30 16:05 ..
-rw-r--r-- 1 root root 168256 Jul 30 16:05 ocp4-cis-node-master-master-0-pod.xml.bzip2
-rw-r--r-- 1 root root 165716 Jul 30 16:05 ocp4-cis-node-master-master-1-pod.xml.bzip2
-rw-r--r-- 1 root root 166945 Jul 30 16:05 ocp4-cis-node-master-master-2-pod.xml.bzip2
/tmp/ocp4-cis-node-worker:
total 1112
drwx------ 2 root root 4096 Jul 30 16:05 .
drwxrwxrwt. 18 root root 4096 Jul 30 16:05 ..
-rw-r--r-- 1 root root 154943 Jul 30 16:05 ocp4-cis-node-worker-compute-0-pod.xml.bzip2
-rw-r--r-- 1 root root 154903 Jul 30 16:05 ocp4-cis-node-worker-compute-1-pod.xml.bzip2
-rw-r--r-- 1 root root 154939 Jul 30 16:05 ocp4-cis-node-worker-compute-2-pod.xml.bzip2
-rw-r--r-- 1 root root 154890 Jul 30 16:05 ocp4-cis-node-worker-compute-3-pod.xml.bzip2
-rw-r--r-- 1 root root 168175 Jul 30 16:05 ocp4-cis-node-worker-master-0-pod.xml.bzip2
-rw-r--r-- 1 root root 165603 Jul 30 16:05 ocp4-cis-node-worker-master-1-pod.xml.bzip2
-rw-r--r-- 1 root root 166914 Jul 30 16:05 ocp4-cis-node-worker-master-2-pod.xml.bzip2&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_re_run_scans">Re-Run Scans&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Sometimes it is necessary to re-run scans. This can be done by annotating the appropriate scan as described at:
&lt;a href="https://blog.stderr.at/compliance/2021/07/compliance-operator/#_performing_a_rescan">Performing a Rescan&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the oc plugin you can simply trigger a re-scan with a single command:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc compliance rerun-now scansettingbindings &amp;lt;name of scanbinding&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For example:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc compliance rerun-now scansettingbindings cis-compliance&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Example output:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Rerunning scans from &amp;#39;cis-compliance&amp;#39;: ocp4-cis-node-worker, ocp4-cis-node-master, ocp4-cis
Re-running scan &amp;#39;openshift-compliance/ocp4-cis-node-worker&amp;#39;
Re-running scan &amp;#39;openshift-compliance/ocp4-cis-node-master&amp;#39;
Re-running scan &amp;#39;openshift-compliance/ocp4-cis&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the command &lt;code>oc get compliancescan -n openshift-compliance&lt;/code> you can check when the scan has been done:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">NAME PHASE RESULT
ocp4-cis RUNNING NOT-AVAILABLE
ocp4-cis-node-master RUNNING NOT-AVAILABLE
ocp4-cis-node-worker AGGREGATING NOT-AVAILABLE&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_view_results_on_cli">View Results on CLI&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Once a scan process has finished you can verify the check results quick and easy using the command line:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get ComplianceCheckResult -A&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This prints for example:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">NAMESPACE NAME STATUS SEVERITY
[...]
openshift-compliance ocp4-cis-audit-log-forwarding-enabled FAIL medium
[...]&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;code>view-result&lt;/code> can print a human readable output, for example:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc compliance view-result ocp4-cis-audit-log-forwarding-enabled -n openshift-compliance&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Example:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">+----------------------+-----------------------------------------------------------------------------------------+
| KEY | VALUE |
+----------------------+-----------------------------------------------------------------------------------------+
| Title | Ensure that Audit Log |
| | Forwarding Is Enabled |
+----------------------+-----------------------------------------------------------------------------------------+
| Status | FAIL |
+----------------------+-----------------------------------------------------------------------------------------+
| Severity | medium |
+----------------------+-----------------------------------------------------------------------------------------+
| Description | OpenShift audit works at the |
| | API server level, logging |
| | all requests coming to the |
| | server. Audit is on by default |
| | and the best practice is |
| | to ship audit logs off the |
| | cluster for retention. The |
| | cluster-logging-operator is |
| | able to do this with the |
| | |
| | |
| | |
| | ClusterLogForwarders |
| | |
| | |
| | |
| | resource. The forementioned resource can be configured to logs to different third party |
| | systems. For more information on this, please reference the official documentation: |
| | https://docs.openshift.com/container-platform/4.6/logging/cluster-logging-external.html |
+----------------------+-----------------------------------------------------------------------------------------+
| Rationale | Retaining logs ensures the |
| | ability to go back in time to |
| | investigate or correlate any |
| | events. Offloading audit logs |
| | from the cluster ensures that |
| | an attacker that has access |
| | to the cluster will not be |
| | able to tamper with the logs |
| | because of the logs being |
| | stored off-site. |
+----------------------+-----------------------------------------------------------------------------------------+
| Instructions | Run the following command: |
| | |
| | oc get clusterlogforwarders |
| | instance -n openshift-logging |
| | -ojson | jq -r |
| | &amp;#39;.spec.pipelines[].inputRefs | |
| | contains([&amp;#34;audit&amp;#34;])&amp;#39; |
| | |
| | The output should return true. |
+----------------------+-----------------------------------------------------------------------------------------+
| CIS-OCP Controls | 1.2.23 |
+----------------------+-----------------------------------------------------------------------------------------+
| NIST-800-53 Controls | AC-2(12), AU-6, AU-6(1), |
| | AU-6(3), AU-9(2), SI-4(16), |
| | AU-4(1), AU-11, AU-7, AU-7(1) |
+----------------------+-----------------------------------------------------------------------------------------+
| Available Fix | No |
+----------------------+-----------------------------------------------------------------------------------------+
| Result Object Name | ocp4-cis-audit-log-forwarding-enabled |
+----------------------+-----------------------------------------------------------------------------------------+
| Rule Object Name | ocp4-audit-log-forwarding-enabled |
+----------------------+-----------------------------------------------------------------------------------------+
| Remediation Created | No |
+----------------------+-----------------------------------------------------------------------------------------+&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Compliance Operator</title><link>https://blog.stderr.at/compliance/2021/07/compliance-operator/</link><pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/compliance/2021/07/compliance-operator/</guid><description>&lt;div class="paragraph">
&lt;p>OpenShift comes out of the box with a highly secure operating system, called Red Hat CoreOS. This OS is immutable, which means that no direct changes are done inside the OS, instead any configuration is managed by OpenShift itself using MachineConfig objects. Nevertheless, hardening certain settings must still be considered. Red Hat released a hardening guide (CIS Benchmark) which can be downloaded at &lt;a href="https://www.cisecurity.org/" class="bare">https://www.cisecurity.org/&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>However, an automated way to perform such checks would be nice too. To achieve this the &lt;strong>Compliance Operator&lt;/strong> can be leveraged, which runs an OpenSCAP check to create reports of the clusters is compliant or as the official documentation describes:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;em>The Compliance Operator lets OpenShift Container Platform administrators describe the desired compliance state of a cluster and provides them with an overview of gaps and ways to remediate them. The Compliance Operator assesses compliance of both the Kubernetes API resources of OpenShift Container Platform, as well as the nodes running the cluster. The Compliance Operator uses OpenSCAP, a NIST-certified tool, to scan and enforce security policies provided by the content.&lt;/em>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article shall show how to quickly install the operator and retrieve the first result. It is not a full documentation, which is written by other people at: &lt;a href="https://docs.openshift.com/container-platform/4.7/security/compliance_operator/compliance-operator-installation.html">Compliance Operator&lt;/a>, especially remediation is not covered here.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As prerequisites we have:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Installed OpenShift 4.6+ cluster&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
The Compliance Operator is available for Red Hat Enterprise Linux CoreOS (RHCOS) deployments only.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_install_the_compliance_operator">Install the Compliance Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The easiest way to deploy the Compliance Operator is by searching the OperatorHub which is available inside OpenShift.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/compliance/images/install_compliance_operator_1.png?width=640" alt="Install"/>
&lt;/div>
&lt;div class="title">Figure 1. Install Compliance Operator&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Keep the default settings and wait until the operator has been installed.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/compliance/images/install_compliance_operator_2.png?width=640" alt="Install"/>
&lt;/div>
&lt;div class="title">Figure 2. Install Compliance Operator&lt;/div>
&lt;/div>
&lt;hr/>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_custom_resources_crds">Custom Resources (CRDs)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The operator brings a ton of new CRDs into the system:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>ScanSetting …​ defines when and on which roles (worker, master …​) a check shall be executed. It also defines a persistent volume (PV) to store the scan results. Two ScanSettings are created during the installation:&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;em>default&lt;/em>: just scans without automatically apply changes&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>default-auto-apply&lt;/em>: can automatically remediate without extra steps&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>ScanSettingBinding …​ binds one or more profiles to a scan&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Profile …​ Represent different compliance benchmarks with a set of rules. For this blog we will use CIS Benchmark profiles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ProfileBundle …​ Bundles a security image, which is later used by Profiles.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Rule …​ Rules which are used by profiles to verify the state of the cluster.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>TailoredProfile …​ Customized profile&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ComplianceScan …​ scans which have been performed&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ComplianceCheckResult …​ The results of a scan. Each ComplianceCheckResult represents the result of one compliance rule check&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ComplianceRemediation …​ If a rule ca be remediated automatically, this object is created.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_create_a_scanbinding_object">Create a ScanBinding object&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The first step to do is to create a ScanBiding objects. (We reuse the &lt;em>default&lt;/em> ScanSetting)&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s create the following object, which is using the profiles &lt;em>ocp4-cis&lt;/em> and &lt;em>ocp4-cis-node&lt;/em>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: compliance.openshift.io/v1alpha1
kind: ScanSettingBinding
metadata:
name: cis-compliance
profiles:
- name: ocp4-cis-node &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
kind: Profile
apiGroup: compliance.openshift.io/v1alpha1
- name: ocp4-cis &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
kind: Profile
apiGroup: compliance.openshift.io/v1alpha1
settingsRef:
name: default &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
kind: ScanSetting
apiGroup: compliance.openshift.io/v1alpha1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>use the profile ocp4-cis-node&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>use the profile ocp4-cis&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>reference to the &lt;em>default&lt;/em> scansetting&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As soon as the object is created the cluster is scan is started. The objects &lt;em>ComplianceSuite&lt;/em> and &lt;em>ComplianceScan&lt;/em> are created automatically and will eventually reach the phase &amp;#34;DONE&amp;#34; when the scan is completed.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following command will show the results of the scans&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get compliancescan -n openshift-compliance
NAME PHASE RESULT
ocp4-cis DONE NON-COMPLIANT
ocp4-cis-node-master DONE NON-COMPLIANT
ocp4-cis-node-worker DONE INCONSISTENT&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Three different checks have been done. One overall cluster check and 2 separated for master and worker nodes.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As we used the &lt;em>default&lt;/em> ScanSetting the next check will run a 1 am.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_profiles">Profiles&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The operator comes with a set of standard profiles which represent different compliance benchmarks.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To view available profiles:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get profiles.compliance -n openshift-compliance&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">NAME AGE
ocp4-cis 28m
ocp4-cis-node 28m
ocp4-e8 28m
ocp4-moderate 28m
rhcos4-e8 28m
rhcos4-moderate 28m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Each profile contains a description which explains the intention and a list of rules which used in this profile.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For example the profile &amp;#39;ocp4-cis-node&amp;#39; used above is containing:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get profiles.compliance -n openshift-compliance -oyaml ocp4-cis-node
# Output
description: This profile defines a baseline that aligns to the Center for Internet Security® Red
Hat OpenShift Container Platform 4 Benchmark™, V0.3, currently unreleased. This profile includes
Center for Internet Security® Red Hat OpenShift Container Platform 4 CIS Benchmarks™ content.
Note that this part of the profile is meant to run on the Operating System that Red Hat
OpenShift Container Platform 4 runs on top of. This profile is applicable to OpenShift versions
4.6 and greater.
[...]
name: ocp4-cis-node
namespace: openshift-compliance
[...]
rules:
- ocp4-etcd-unique-ca
- ocp4-file-groupowner-cni-conf
- ocp4-file-groupowner-controller-manager-kubeconfig
- ocp4-file-groupowner-etcd-data-dir
- ocp4-file-groupowner-etcd-data-files
- ocp4-file-groupowner-etcd-member
- ocp4-file-groupowner-etcd-pki-cert-files
- ocp4-file-groupowner-ip-allocations
[...]&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Like the profiles the different rules can be inspected:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get rules.compliance -n openshift-compliance ocp4-file-groupowner-etcd-member
-o jsonpath=&amp;#39;{&amp;#34;Title: &amp;#34;}{.title}{&amp;#34;\nDescription: \n&amp;#34;}{.description}&amp;#39;
# Output
Title: Verify Group Who Owns The etcd Member Pod Specification File
Description:
To properly set the group owner of /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml ,
run the command:
$ sudo chgrp root /etc/kubernetes/static-pod-resources/etcd-pod-*/etcd-pod.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_profile_customization">Profile Customization&lt;/h3>
&lt;div class="paragraph">
&lt;p>Sometimes is it required to modify (tailor) a profile to fit specific needs. With the &lt;em>TailoredProfile&lt;/em> object it is possible to enable or disable rules.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this blog, I just want to share a quick example from the official documentaiton: &lt;a href="https://docs.openshift.com/container-platform/4.7/security/compliance_operator/compliance-operator-tailor.html" class="bare">https://docs.openshift.com/container-platform/4.7/security/compliance_operator/compliance-operator-tailor.html&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following TailoredProfile disables 2 rules and sets a value for another rule:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: compliance.openshift.io/v1alpha1
kind: TailoredProfile
metadata:
name: nist-moderate-modified
spec:
extends: rhcos4-moderate
title: My modified NIST moderate profile
disableRules:
- name: rhcos4-file-permissions-node-config
rationale: This breaks X application.
- name: rhcos4-account-disable-post-pw-expiration
rationale: No need to check this as it comes from the IdP
setValues:
- name: rhcos4-var-selinux-state
rationale: Organizational requirements
value: permissive&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_working_with_scan_results">Working with scan results&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Once a scan finished you probably want to see what the status of the scan is.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you sse above the cluster failed to be compliant.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get compliancescan -n openshift-compliance
NAME PHASE RESULT
ocp4-cis DONE NON-COMPLIANT
ocp4-cis-node-master DONE NON-COMPLIANT
ocp4-cis-node-worker DONE INCONSISTENT&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_retrieving_results_via_oc_command">Retrieving results via oc command&lt;/h3>
&lt;div class="paragraph">
&lt;p>List all results which can be remediated automatically:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get compliancecheckresults -l &amp;#39;compliance.openshift.io/check-status=FAIL,compliance.openshift.io/automated-remediation&amp;#39; -n openshift-compliance
NAME STATUS SEVERITY
ocp4-cis-api-server-encryption-provider-cipher FAIL medium
ocp4-cis-api-server-encryption-provider-config FAIL medium&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Further information about remediation can be found at: &lt;a href="https://docs.openshift.com/container-platform/4.7/security/compliance_operator/compliance-operator-remediation.html">Compliance Operator Remediation&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>List all results which cannot be remediated automatically and must be fixed manually instead:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get compliancecheckresults -l &amp;#39;compliance.openshift.io/check-status=FAIL,!compliance.openshift.io/automated-remediation&amp;#39; -n openshift-compliance
NAME STATUS SEVERITY
ocp4-cis-audit-log-forwarding-enabled FAIL medium
ocp4-cis-file-permissions-proxy-kubeconfig FAIL medium
ocp4-cis-node-master-file-groupowner-ip-allocations FAIL medium
ocp4-cis-node-master-file-groupowner-openshift-sdn-cniserver-config FAIL medium
ocp4-cis-node-master-file-owner-ip-allocations FAIL medium
ocp4-cis-node-master-file-owner-openshift-sdn-cniserver-config FAIL medium
ocp4-cis-node-master-kubelet-configure-event-creation FAIL medium
ocp4-cis-node-master-kubelet-configure-tls-cipher-suites FAIL medium
ocp4-cis-node-master-kubelet-enable-protect-kernel-defaults FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-imagefs-available FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-imagefs-inodesfree FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-memory-available FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-nodefs-available FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-hard-nodefs-inodesfree FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-imagefs-available FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-imagefs-inodesfree FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-memory-available FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-nodefs-available FAIL medium
ocp4-cis-node-master-kubelet-eviction-thresholds-set-soft-nodefs-inodesfree FAIL medium
ocp4-cis-node-worker-file-groupowner-ip-allocations FAIL medium
ocp4-cis-node-worker-file-groupowner-openshift-sdn-cniserver-config FAIL medium
ocp4-cis-node-worker-file-owner-ip-allocations FAIL medium
ocp4-cis-node-worker-file-owner-openshift-sdn-cniserver-config FAIL medium
ocp4-cis-node-worker-kubelet-configure-event-creation FAIL medium
ocp4-cis-node-worker-kubelet-configure-tls-cipher-suites FAIL medium
ocp4-cis-node-worker-kubelet-enable-protect-kernel-defaults FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-imagefs-available FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-imagefs-inodesfree FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-memory-available FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-nodefs-available FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-hard-nodefs-inodesfree FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-imagefs-available FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-imagefs-inodesfree FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-memory-available FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-nodefs-available FAIL medium
ocp4-cis-node-worker-kubelet-eviction-thresholds-set-soft-nodefs-inodesfree FAIL medium&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_retrieving_raw_results">Retrieving RAW results&lt;/h3>
&lt;div class="paragraph">
&lt;p>Let’s first retrieve the raw result of the scan. For each of the ComplianceScans a volume claim (PVC) is created to store he results. We can use a Pod to mount the volume to download the scan results.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following PVC have been created on our example:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get pvc -n openshift-compliance
NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE
ocp4-cis Bound pvc-cc026ae3-2f42-4e19-bc55-016c6dd31d22 1Gi RWO managed-nfs-storage 4h17m
ocp4-cis-node-master Bound pvc-3bd47c5e-2008-4759-9d53-ba41b568688d 1Gi RWO managed-nfs-storage 4h17m
ocp4-cis-node-worker Bound pvc-77200e5f-0f15-410c-a4ee-f2fb3e316f84 1Gi RWO managed-nfs-storage 4h17m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now we can create a Pod which mounts all PVCs at once:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: &amp;#34;v1&amp;#34;
kind: Pod
metadata:
name: pv-extract
namespace: openshift-compliance
spec:
containers:
- name: pv-extract-pod
image: registry.access.redhat.com/ubi8/ubi
command: [&amp;#34;sleep&amp;#34;, &amp;#34;3000&amp;#34;]
volumeMounts: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- mountPath: &amp;#34;/workers-scan-results&amp;#34;
name: workers-scan-vol
- mountPath: &amp;#34;/masters-scan-results&amp;#34;
name: masters-scan-vol
- mountPath: &amp;#34;/ocp4-scan-results&amp;#34;
name: ocp4-scan-vol
volumes: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- name: workers-scan-vol
persistentVolumeClaim:
claimName: ocp4-cis-node-worker
- name: masters-scan-vol
persistentVolumeClaim:
claimName: ocp4-cis-node-master
- name: ocp4-scan-vol
persistentVolumeClaim:
claimName: ocp4-cis&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>mount paths&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>volumesclaims to mount&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This creates a Pod with the PVCs mounted inside:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">sh-4.4# ls -la | grep scan
drwxrwxrwx. 3 root root 4096 Jul 20 05:20 master-scan-results
drwxrwxrwx. 3 root root 4096 Jul 20 05:20 ocp4-scan-results
drwxrwxrwx. 3 root root 4096 Jul 20 05:20 workers-scan-results&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We can download the result-files to our local machine for further auditing. Therefore, we create the folder &lt;em>scan_results&lt;/em> in which we copy everything:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">mkdir scan-results; cd scan-results
oc -n openshift-compliance cp pv-extract:ocp4-scan-results ocp4-scan-results/.
oc -n openshift-compliance cp pv-extract:workers-scan-results workers-scan-results/.
oc -n openshift-compliance cp pv-extract:masters-scan-results masters-scan-results/.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will download several bzip2 archives for the appropriate scan result.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Once done, you can delete the &amp;#34;download pod&amp;#34; using: &lt;code>oc delete pod pv-extract -n openshift-compliance&lt;/code>&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_work_wth_raw_results">Work wth RAW results&lt;/h3>
&lt;div class="paragraph">
&lt;p>So above section described the download of the bzip2 files but what to do with it? First, you can import it into a tool which is able to read openScap reports. Or, secondly, you can use the &lt;em>oscap&lt;/em> command to create a html output.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We have downloaded the following files:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">./ocp4-scan-results/0/ocp4-cis-api-checks-pod.xml.bzip2
./masters-scan-results/0/ocp4-cis-node-master-master-0-pod.xml.bzip2
./masters-scan-results/0/ocp4-cis-node-master-master-2-pod.xml.bzip2
./masters-scan-results/0/ocp4-cis-node-master-master-1-pod.xml.bzip2
./workers-scan-results/0/ocp4-cis-node-worker-compute-0-pod.xml.bzip2
./workers-scan-results/0/ocp4-cis-node-worker-compute-1-pod.xml.bzip2
./workers-scan-results/0/ocp4-cis-node-worker-compute-3-pod.xml.bzip2
./workers-scan-results/0/ocp4-cis-node-worker-compute-2-pod.xml.bzip2&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To create the html output (be sure that open-scap is installed on you host):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">mkdir html
oscap xccdf generate report ocp4-scan-results/0/ocp4-cis-api-checks-pod.xml.bzip2 &amp;gt;&amp;gt; html/ocp4-cis-api-checks.html
oscap xccdf generate report masters-scan-results/0/ocp4-cis-node-master-master-0-pod.xml.bzip2 &amp;gt;&amp;gt; html/ocp4-cis-node-master-master-0.html
oscap xccdf generate report masters-scan-results/0/ocp4-cis-node-master-master-1-pod.xml.bzip2 &amp;gt;&amp;gt; html/ocp4-cis-node-master-master-1.html
oscap xccdf generate report masters-scan-results/0/ocp4-cis-node-master-master-2-pod.xml.bzip2 &amp;gt;&amp;gt; html/ocp4-cis-node-master-master-2.html
oscap xccdf generate report workers-scan-results/0/ocp4-cis-node-worker-compute-0-pod.xml.bzip2 &amp;gt;&amp;gt; html/ocp4-cis-node-worker-compute-0.html
...&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The resulted html files are too big to be show here, but some snippets should give an overview:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To view the html output as an example I have linked the html files:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://blog.stderr.at/files/ocp4-cis-api-checks.html">OCP4 - CIS&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.stderr.at/files/ocp4-cis-node-master-master-0.html">Example Master Node Results&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.stderr.at/files/ocp4-cis-node-worker-compute-0.html">Example Worker Node Results&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Overall Scoring of the result:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/compliance/images/compliance_scoring.png?width=940px" alt="Install"/>
&lt;/div>
&lt;div class="title">Figure 3. Scoring&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A list if passed or failed checks:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/compliance/images/compliance_scan_results.png?width=940px" alt="Scanresults"/>
&lt;/div>
&lt;div class="title">Figure 4. Scan Result list&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Scan details with a link to the CIS Benchmark section and further explainations on how to fix the issue:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/compliance/images/compliance_scan_details.png?width=940px" alt="Details"/>
&lt;/div>
&lt;div class="title">Figure 5. Scan details&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_performing_a_rescan">Performing a rescan&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>If it is necessary to run a rescan, the ComplianceScan object is simply annotated with:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc annotate compliancescans/&amp;lt;scan_name&amp;gt; compliance.openshift.io/rescan=&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
If &lt;em>default-auto-apply&lt;/em> is enabled, remediation which changes MachineConfigs will trigger a cluster reboot.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div></description></item></channel></rss>