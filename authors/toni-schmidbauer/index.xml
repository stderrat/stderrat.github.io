<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Articles by Toni Schmidbauer on TechBlog about OpenShift/Ansible/Satellite and much more</title><link>https://blog.stderr.at/authors/toni-schmidbauer/</link><description>TechBlog about OpenShift/Ansible/Satellite and much more</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Toni Schmidbauer &amp; Thomas Jungbauer</copyright><atom:link href="https://blog.stderr.at/authors/toni-schmidbauer/index.xml" rel="self" type="application/rss+xml"/><item><title>What's new in OpenShift, 4.20 Edition</title><link>https://blog.stderr.at/whatss-new/2025-11-10-whatsnew-420/</link><pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/whatss-new/2025-11-10-whatsnew-420/</guid><description>&lt;div class="paragraph">
&lt;p>This article covers news and updates in the OpenShift 4.20 release. We focus on points that got our attention, but this
is &lt;strong>not&lt;/strong> a complete summary of the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/release_notes/index">release notes&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuring_a_local_arbiter_node">Configuring a local arbiter node&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/installing_an_on-premise_cluster_with_the_agent-based_installer/index#installing-ocp-agent-local-arbiter-node_installing-with-agent-based-installer">Configuring a local arbiter node&lt;/a> describes how to configure an OCP cluster with only two control plane (ETCD) nodes. Might be useful in a pure bare metal environment where three bare metal control plane nodes might be overkill.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_two_node_clusters_with_fencing">Two node clusters with fencing&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/installing_on_bare_metal/index#bmo-about-the-hostfirmwarecomponents-resource_bare-metal-postinstallation-configuration">Two-node with Fencing&lt;/a> still in tech preview. Useful for environments with only two active datacenters. Especially if you have bare metal control plane nodes. We got quite a few customers with only to data centers available.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_about_the_hostfirmwarecomponents_resource">About the HostFirmwareComponents resource&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/installing_on_bare_metal/index#bmo-about-the-hostfirmwarecomponents-resource_bare-metal-postinstallation-configuration">About the HostFirmwareComponents&lt;/a>. When Metal3 is used it’s now possible to update the NIC (Network interface card) firmware.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_boot_image_updates_on_vmware">Boot image updates on Vmware&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/machine_configuration/index#mco-update-boot-images">Boot image management&lt;/a> can be used to update the boot image for new nodes. Up until now
when you installed you cluster on VMware with a certain boot image (let’s say 4.15) it never got updates. New nodes were always booted from this old image and later updated to the current cluster release.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_about_on_cluster_image_mode">About on-cluster image mode&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/machine_configuration/index#coreos-layering-configuring-on_mco-coreos-layering">About on-cluster image mode&lt;/a>. Image mode allows you to customize the node operating system image. You basically create a Containerfile, install custom RPM’s or deploy custom configuration files in the Containerfile and OCP creates a layered image for you cluster. The image is automatically rolled out to the cluster with the Machine Config Operator. Fancy stuff…​.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_pinning_images">Pinning images&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/machine_configuration/index#machine-config-pin-preload-images_machine-config-operator">Pinning images&lt;/a>. If your internet connection is flaky, or you have reasons to not trust the availablity of Red Hat registries like quay.io or registry.redhat.io you can now pin images those images. They are pulled down immediately and will not be garbage collected (hopefully…​).&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_bgp_routing">BGP routing&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/advanced_networking/index#about-bgp-routing">About BGP routing&lt;/a>. MetalLB had support for announcing IP’s via BGP for a long time, but now it’s also possible to announce UDN’s or EgressIP. IMHO this is especially interesting for EgressIP because there were some nasty &lt;a href="https://issues.redhat.com/browse/OCPBUGS-42303">bugs&lt;/a> around using &lt;a href="https://wiki.wireshark.org/Gratuitous_ARP">GRAP (Gratuitous ARP)&lt;/a> for announcing IP’s to switches.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_migrating_a_configured_br_ex_bridge_to_nmstate">Migrating a configured br-ex bridge to NMState&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/installing_on_bare_metal/index#migrating-br-ex-bridge-nmstate_bare-metal-postinstallation-configuration">Migrating a configured br-ex bridge to NMState&lt;/a>. There’s this ominous &lt;em>configure-ovs.sh&lt;/em> that reconfigures the public interface of a node an brings up br-ex. There was support for deploying an NMState-based configuration during cluster installation and not using &lt;em>configure-ovs.sh&lt;/em>. Now it’s also possible to get rid of the shell script &lt;strong>after&lt;/strong> installation.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuration_for_a_bond_cni_secondary_network">Configuration for a Bond CNI secondary network&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/multiple_networks/index#nw-multus-bond-cni-object_configuring-additional-network-cni">Configuration for a Bond CNI secondary network&lt;/a>. Bond interface can now be created for interface in containers. This currently only supports SR-IOV virtual functions.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_manage_secure_signatures_with_sigstore">Manage secure signatures with sigstore&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/nodes/index#nodes-sigstore-using">Manage secure signatures with sigstore&lt;/a>. Sigstore support can now be enabled on a cluster level or on an individual namespace level.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_running_pods_in_linux_user_namespaces">Running pods in Linux user namespaces&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/nodes/index#nodes-pods-user-namespaces">Running pods in Linux user namespaces&lt;/a>. This is IMHO a big one. Linux user namespaces are finally supported in OpenShift! So it’s possible to grant root inside a container and map the root UID to an unprivileged ID outside the container.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adjust_pod_resource_levels_without_pod_disruption">Adjust pod resource levels without pod disruption&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/nodes/index#nodes-pods-adjust-resources-in-place">Adjust pod resource levels without pod disruption&lt;/a>. Resize CPU and memory resource without restarting a Pod!&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_introducing_the_oc_adm_upgrade_recommend_command_general_availability">Introducing the &lt;em>oc adm upgrade recommend&lt;/em> command (General Availability)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/updating_clusters/index#understanding-openshift-updates">Understanding OpenShift upgrades&lt;/a>. &lt;em>oc&lt;/em> know officially supports cluster upgrade from the command line. &lt;em>oc adm upgrade recommended&lt;/em> performs some pre-flight checks before upgrading a cluster.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_additional_cluster_latency_requirements_for_etcd">Additional cluster latency requirements for etcd&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/etcd/index#recommended-cluster-latency-etcd_etcd-practices">Cluster latency requirements for etcd&lt;/a>. ETCD latency requirements were updated in the documentation.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_sunset_of_the_red_hat_marketplace_operated_by_ibm">Sunset of the Red Hat Marketplace, operated by IBM&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://access.redhat.com/articles/7130828">Sunset of the Red Hat Marketplace, operated by IBM&lt;/a>. It seems Red Hat Marktplace is no more…​&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_how_to_use_changed_block_tracking_dev_preview_in_openshift_4_20">How to use Changed Block Tracking (Dev Preview) in OpenShift 4.20&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;a href="https://access.redhat.com/solutions/7131061">How to use Changed Block Tracking (Dev Preview) in OpenShift 4.20&lt;/a>. Change block tracking for PV’s is now in dev preview. Whatever this means exactly, needs more investigation.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>A second look into the Kubernetes Gateway API on OpenShift</title><link>https://blog.stderr.at/openshift/2025/08/a-second-look-into-the-kubernetes-gateway-api-on-openshift/</link><pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/08/a-second-look-into-the-kubernetes-gateway-api-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>This is our second look into the Kubernetes Gateway API an it’s
integration into OpenShift. This post covers TLS configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Kubernetes Gateway API is new implementation of the ingress, load
balancing and service mesh API’s. See
&lt;a href="https://gateway-api.sigs.k8s.io/" target="_blank" rel="noopener">upstream&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-overview_ingress-gateway-api" target="_blank" rel="noopener">OpenShift documentation&lt;/a> provides an overview of the Gateway API and it’s integration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We demonstrate how to add TLS to our Nginx deployment, how to
implement a shared Gateway and finally how to implement HTTP to HTTPS
redirection with the Gateway API. Furthermore we cover how &lt;em>HTTPRoute&lt;/em>
objects attach to Gateways and dive into ordering of &lt;em>HTTPRoute&lt;/em>
objects.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_references">References&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;a href="https://blog.stderr.at/openshift/2025/08/gateway-api/">A first look into the Kubernetes Gateway API on OpenShift&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adding_tls_to_our_nginx_deployment">Adding TLS to our Nginx deployment&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In our fist post we simply exposed a Nginx web server via the
Gateway API. We only enabled HTTP, so let’s try to do the same with
HTTPS now.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Remember we use a DNS wildcard domain &lt;code>*.gtw.ocp.lan.stderr.at&lt;/code> which
points to our Gateway. The gateway is exposed via a &lt;em>Service&lt;/em> of type
&lt;em>LoadBalancer&lt;/em>. We use
&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/networking_operators/metallb-operator">MetalLB&lt;/a>
for this.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The first step is setting up a wildcard TLS certificate for our custom
domain &lt;em>*.gtw.ocp.lan.stderr.at&lt;/em>. We are using
&lt;a href="https://github.com/OpenVPN/easy-rsa">EasyRSA&lt;/a> here, but use whatever tool you like.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Just for reference this is how we created a wildcard cert with EasyRSA:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ EASYRSA_CERT_EXPIRE=3650 EASYRSA_EXTRA_EXTS=&amp;#34;subjectAltName=DNS:*.gtw.ocp.lan.stderr.at&amp;#34; ./easyrsa gen-req gtw.ocp.lan.stderr.at
$ EASYRSA_CERT_EXPIRE=3650 ./easyrsa sign-req serverClient gtw.ocp.lan.stderr.at&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>EasyRSA stores the public key under &lt;em>pki/issued&lt;/em> and the private key
under &lt;em>pki/private&lt;/em>. We copied the certificate and the private key to
a temporary directory.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we need to remove the private key passphrase and create a
Kubernetes secret from the private and pubic key:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ openssl rsa -in gtw.ocp.lan.stderr.at.key -out gtw.ocp.lan.stderr.at-insecure.key
$ oc create secret -n openshift-ingress tls gateway-api --cert=gtw.ocp.lan.stderr.at.crt --key=gtw.ocp.lan.stderr.at-insecure.key&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now it’s time to add a TLS listener to our &lt;em>Gateway&lt;/em> resource in the
&lt;em>openshift-ingress&lt;/em> namespace. Remember for the OpenShift Gateway API implementation, &lt;em>Gateways&lt;/em> have
to be deployed in the &lt;em>openshift-ingress&lt;/em> namespace.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
- name: https
protocol: HTTPS &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
port: 443 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
tls:
mode: Terminate &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
certificateRefs:
- name: gateway-api &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
allowedRoutes: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
namespaces:
from: All&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We want to support HTTPS&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>We use the default HTTPS port 443&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The URLs we support with this listener are the same as for HTTP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>We use edge termination for now, this means HTTP traffic will only be encrypted up to the gateway. From the gateway to our pod we speak plain HTTP.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>This is the name of the TLS secret we created above&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>We accept routes from all namespaces&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Also remember from our first post that we created a
&lt;em>ReferenceGrant&lt;/em> in the namespace where Nginx is running. Otherwise
HTTP routes will not be accepted.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally lets try to access our Nginx pod via HTTPS:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -v https://nginx.gtw.ocp.lan.stderr.at
* Host nginx.gtw.ocp.lan.stderr.at:443 was resolved.
* IPv6: (none)
* IPv4: 10.0.0.150
* Trying 10.0.0.150:443...
* ALPN: curl offers h2,http/1.1
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* CAfile: /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem
* CApath: none
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):
* TLSv1.3 (IN), TLS handshake, Certificate (11):
* TLSv1.3 (IN), TLS handshake, CERT verify (15):
* TLSv1.3 (IN), TLS handshake, Finished (20):
* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.3 (OUT), TLS handshake, Finished (20):
* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 / x25519 / RSASSA-PSS
* ALPN: server accepted h2
* Server certificate:
* subject: CN=gtw.ocp.lan.stderr.at
* start date: Aug 30 10:01:33 2025 GMT
* expire date: Aug 28 10:01:33 2035 GMT
* subjectAltName: host &amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34; matched cert&amp;#39;s &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
* issuer: CN=tntinfra CA
* SSL certificate verify ok.
* Certificate level 0: Public key type RSA (2048/112 Bits/secBits), signed using sha256WithRSAEncryption
* Certificate level 1: Public key type RSA (2048/112 Bits/secBits), signed using sha256WithRSAEncryption
* Connected to nginx.gtw.ocp.lan.stderr.at (10.0.0.150) port 443
* using HTTP/2
* [HTTP/2] [1] OPENED stream for https://nginx.gtw.ocp.lan.stderr.at/
* [HTTP/2] [1] [:method: GET]
* [HTTP/2] [1] [:scheme: https]
* [HTTP/2] [1] [:authority: nginx.gtw.ocp.lan.stderr.at]
* [HTTP/2] [1] [:path: /]
* [HTTP/2] [1] [user-agent: curl/8.11.1]
* [HTTP/2] [1] [accept: */*]
&amp;gt; GET / HTTP/2
&amp;gt; Host: nginx.gtw.ocp.lan.stderr.at
&amp;gt; User-Agent: curl/8.11.1
&amp;gt; Accept: */*
&amp;gt;
* Request completely sent off
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
&amp;lt; HTTP/2 200
&amp;lt; server: nginx/1.29.1
&amp;lt; date: Sat, 30 Aug 2025 14:30:20 GMT
&amp;lt; content-type: text/html
&amp;lt; content-length: 615
&amp;lt; last-modified: Wed, 13 Aug 2025 14:33:41 GMT
&amp;lt; etag: &amp;#34;689ca245-267&amp;#34;
&amp;lt; accept-ranges: bytes
(output omitted)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Yes, we can reach our Nginx via HTTPS, and the gateway presents the TLS certificate we created.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be aware that we are still using the same &lt;em>HTTPRoute&lt;/em> for Nginx from our previous blog post.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Just for completeness here is the &lt;em>HTTPRoute&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Also Remember that we are using a dedicated &lt;em>Gateway&lt;/em> and all
&lt;em>HTTPRoutes&lt;/em> must be in the namespace &lt;em>openshift-ingress&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_moving_to_a_shared_gateway">Moving to a shared gateway&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Up until now we had to create all &lt;em>HTTPRoute&lt;/em> objects in the
&lt;em>openshift-ingress&lt;/em> namespace. The Gateway API support two modes of
operations:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Dedicated gateway: all &lt;em>HTTPRoute&lt;/em> object need to be in the same namespace as the gateway&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Shared gateway: The gateway runs in the &lt;em>openshift-ingress&lt;/em>
namespace and we allow &lt;em>HTTPRoute&lt;/em> objects from all or specific namespaces.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The first step in creating a shared gateway is to modify the gateway resource:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
allowedRoutes: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespaces:
from: All&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We now allow &lt;em>HTTPRoute&lt;/em> objects from all namespaces in the cluster&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we delete the existing &lt;em>HTTPRoute&lt;/em> for Nginx in the
&lt;em>openshift-ingress&lt;/em> namespaces, and verify that we can’t reach Nginx:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc delete httproutes.gateway.networking.k8s.io -n openshift-ingress nginx-route
httproute.gateway.networking.k8s.io &amp;#34;nginx-route&amp;#34; deleted
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 404 Not Found &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
date: Sat, 30 Aug 2025 15:02:23 GMT
transfer-encoding: chunked&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Our Nginx route stopped working&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we apply our modified &lt;em>Gateway&lt;/em> resource in the
&lt;em>openshift-ingress&lt;/em> namespace and the &lt;em>HTTPRoute&lt;/em> object in the
&lt;em>gateway-api-test&lt;/em> namespace.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -n openshift-ingress -f gateway--selector.yaml
gateway.gateway.networking.k8s.io/http-gateway configured
$ oc apply -n gateway-api-test -f httproute.yaml &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
httproute.gateway.networking.k8s.io/nginx-route created
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
server: nginx/1.29.1
date: Sat, 30 Aug 2025 15:04:34 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We create the &lt;em>HTTPRoute&lt;/em> in the gateway-api-test namespace&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>We can reach our Nginx pod again&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So our shared gateway seems to be working. But what if we want to
restrict which namespaces are allowed to create route objects?&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Gateway API allows the following settings under &lt;em>spec.listeners[].allowedRoutes.namespaces.from&lt;/em> field&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>All&lt;/strong>: Allow from all namespaces&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Selector&lt;/strong>: Specify a selector&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Same&lt;/strong>: Only allow &lt;em>HTTPRoutes&lt;/em> in the same namespaces&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>None&lt;/strong>: Do not allow any routes to attach&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>See the API specification &lt;a href="https://gateway-api.sigs.k8s.io/reference/spec/#fromnamespaces">FromNamespaces&lt;/a> for details.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try to use a more specific selector for our gateway:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
allowedRoutes:
namespaces:
from: Selector &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
selector:
matchLabels:
kubernetes.io/metadata.name: gateway-api-test &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Now we are using the Selector option&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Because we do not have a specific label on the namespace we would like to use, let’s use the &lt;em>metadata.name&lt;/em> label Kubernetes created for us&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We create a new yaml file &lt;em>gateway-selector.yaml&lt;/em> and appy the new configuration:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -n openshift-ingress -f gateway-selector.yaml
gateway.gateway.networking.k8s.io/http-gateway configured
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK
server: nginx/1.29.1
date: Sat, 30 Aug 2025 15:17:17 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>All good, still working.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Just for testing we modified the namespace name in the Gateway definition to &lt;strong>NOT&lt;/strong> match the namespace of our Nginx deployment and confirmed that we receive a &lt;em>404&lt;/em> not found response.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_implementing_http_to_https_redirect">Implementing HTTP to HTTPS redirect&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As a last test for this post let’s try to implement HTTP to HTTPS redirects.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We deployed the following &lt;em>Gateway&lt;/em> configuration:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
allowedRoutes:
namespaces:
from: Selector
selector:
matchLabels:
kubernetes.io/metadata.name: gateway-api-test2
- name: https &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
protocol: HTTPS
port: 443
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
tls:
mode: Terminate
certificateRefs:
- name: gateway-api
allowedRoutes:
namespaces:
from: All&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Always deploy the gateway to the &lt;em>openshift-ingress&lt;/em> namespace for the OpenShift Gateway API implementation&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>We added the HTTPS configuration back&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;a href="https://gateway-api.sigs.k8s.io/guides/http-redirect-rewrite/">upstream&lt;/a> documentation contains an example on how to implements HTTP to HTTPS redirects. We created the following additional &lt;em>HTTPRoute&lt;/em> object in the &lt;em>gateway-api-test&lt;/em> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: http-https-redirect
spec:
parentRefs:
- name: http-gateway &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: openshift-ingress
sectionName: http &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
hostnames:
- nginx.gtw.ocp.lan.stderr.at
rules:
- filters:
- type: RequestRedirect
requestRedirect:
scheme: https
statusCode: 301&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Match our &lt;em>Gateway&lt;/em> &lt;em>http-gateway&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Match the &lt;em>http&lt;/em> section in our gateway&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Just for reference this is the &lt;em>HTTPRoute&lt;/em> object to expose Nginx:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First we re-applied our &lt;em>Gateway&lt;/em> configuration&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f gateway-https-selector.yaml
gateway.gateway.networking.k8s.io/http-gateway configured&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try and verify if our redirect is working, we need to apply both routes:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f httproute.yaml
httproute.gateway.networking.k8s.io/nginx-route created
$ oc apply -f http-https-redirect-route.yaml
httproute.gateway.networking.k8s.io/http-https-redirect created&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And test with curl:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
server: nginx/1.29.1
date: Sat, 30 Aug 2025 15:37:20 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Hm, strange we still get 200 OK and &lt;strong>NOT&lt;/strong> a redirect to HTTPS&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_understanding_httproute_ordering">Understanding HTTPRoute ordering&lt;/h3>
&lt;div class="paragraph">
&lt;p>After a longer search through the documentation we found some hints on why this is happening.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s take a more detailed look at our http-to-https route again, as a
&lt;em>HTTPRoute&lt;/em> &lt;strong>attaches&lt;/strong> to a &lt;em>Gateway&lt;/em>, we focus on the &lt;em>parentRefs&lt;/em> in
the &lt;em>HTTPRoute&lt;/em> object. In our current understanding &lt;em>parentRefs&lt;/em> select a &lt;em>Gateway&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: http-https-redirect
spec:
parentRefs: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- name: http-gateway &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
namespace: openshift-ingress &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
sectionName: http &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
hostnames:
- nginx.gtw.ocp.lan.stderr.at
rules:
- filters:
- type: RequestRedirect
requestRedirect:
scheme: https
statusCode: 301&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Ok, this is the &lt;em>parentRefs&lt;/em> section we are looking for&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>&lt;em>name&lt;/em> selects the name of the &lt;em>Gateway&lt;/em> we want to attach to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>&lt;em>namespace&lt;/em> specifies the namespace where we can find the &lt;em>Gateway&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>&lt;em>sectionName&lt;/em> selects the section in the &lt;em>Gateway&lt;/em> where we want to attach to.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So this &lt;em>HTTPRoute&lt;/em> explicitly attaches to a &lt;em>Gateway&lt;/em> in a
&lt;em>Namespace&lt;/em> that has a &lt;em>Section&lt;/em> http defined.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you look at the Gateway configuration above you will see that we
have a section for HTTP traffic and one for HTTPS traffic.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s compare this with our Nginx &lt;em>HTTPRoute&lt;/em> definition:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- name: http-gateway &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
namespace: openshift-ingress &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The &lt;em>parentRefs&lt;/em> section&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The &lt;em>Gateway&lt;/em> we would like to attach to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The &lt;em>namespace&lt;/em> where the &lt;em>Gateway&lt;/em> is deploy&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Note that &lt;em>Section&lt;/em> is missing in this configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So this &lt;em>HTTPRoute&lt;/em> actually attaches to &lt;strong>both&lt;/strong> sections in our
&lt;em>Gateway&lt;/em> definition, HTTP and HTTPS. Which is not what we want.&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>When a client hits the HTTP endpoint we want to redirect the traffic to HTTPS&lt;/p>
&lt;/li>
&lt;li>
&lt;p>When a client hits the HTTPS endpoint we want the traffic to be forward to our Nginx deployment&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We found the following statement
&lt;a href="https://gateway-api.sigs.k8s.io/reference/spec/#httprouterule">statement&lt;/a>
how ordering works in the Gateway API:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre>If ties still exist across multiple Routes, matching precedence MUST be
determined in order of the following criteria, continuing on ties:
The oldest Route based on creation timestamp.&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we look at the timestamps of our &lt;em>HTTPRoutes&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">oc get httproute -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.creationTimestamp}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
http-https-redirect 2025-08-31T09:17:46Z &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
nginx-route 2025-08-31T09:17:40Z &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the redirect route&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the nginx route&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Nginx &lt;em>HTTPRoute&lt;/em> is &lt;strong>older&lt;/strong> than the HTTP-to-HTTP &lt;em>HTTPRoute&lt;/em>. So
this matches first and a 200 OK is returned.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s try to revers how we applied our &lt;em>HTTPRoutes&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc delete httproutes.gateway.networking.k8s.io --all
httproute.gateway.networking.k8s.io &amp;#34;http-https-redirect&amp;#34; deleted
httproute.gateway.networking.k8s.io &amp;#34;nginx-route&amp;#34; deleted
$ oc apply -f http-to-https-httproute.yaml
httproute.gateway.networking.k8s.io/http-https-redirect created
$ oc apply -f nginx-httproute.yaml
httproute.gateway.networking.k8s.io/nginx-route created
$ oc get httproute -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.creationTimestamp}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
http-https-redirect 2025-08-31T10:34:55Z &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
nginx-route 2025-08-31T10:35:11Z &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the HTTP-to-HTTPS route&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the nginx route&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now the HTTP-to-HTTPS route is the oldest route. Let’s try again calling Nginx with curl:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 301 Moved Permanently &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
location: https://nginx.gtw.ocp.lan.stderr.at/
date: Sun, 31 Aug 2025 10:37:13 GMT
transfer-encoding: chunked
$ curl -I https://nginx.gtw.ocp.lan.stderr.at
HTTP/2 200 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
server: nginx/1.29.1
date: Sun, 31 Aug 2025 10:37:17 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The HTTP endpoint returns a redirect&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>the HTTPS endpoint returns 200 OK from Nginx&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So now we have the expected behavior: HTTP is redirect to HTTPS!&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As depending on the time when an object is created is definitely &lt;strong>NOT&lt;/strong>
a good idea, let’s be more specific in our Nginx &lt;em>HTTPRoute&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
sectionName: https &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We explicitly select the &lt;strong>HTTPS&lt;/strong> section in our &lt;em>Gateway&lt;/em> configuration&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we delete our &lt;em>HTTPRoutes&lt;/em> again, and re-apply them in the order that didn’t work the first time (Nginx is the oldest route):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc delete httproutes.gateway.networking.k8s.io --all
httproute.gateway.networking.k8s.io &amp;#34;http-https-redirect&amp;#34; deleted
httproute.gateway.networking.k8s.io &amp;#34;nginx-route&amp;#34; deleted
$ oc apply -f http-to-https-httproute.yaml
httproute.gateway.networking.k8s.io/http-https-redirect created
$ oc get httproute -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.creationTimestamp}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
http-https-redirect 2025-08-31T10:45:01Z
nginx-route 2025-08-31T10:44:57Z &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 301 Moved Permanently &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
location: https://nginx.gtw.ocp.lan.stderr.at/
date: Sun, 31 Aug 2025 10:46:22 GMT
transfer-encoding: chunked
$ curl -I https://nginx.gtw.ocp.lan.stderr.at
HTTP/2 200 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
server: nginx/1.29.1
date: Sun, 31 Aug 2025 10:46:30 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The Nginx route is the oldest route&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The HTTP endpoint returns a redirect to HTTPS&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The response from our Nginx deployment&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally everything works as expected!&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
A &lt;em>HTTPRoute&lt;/em> attaches to a &lt;em>Gateway&lt;/em>. Always be as specific as
possible which &lt;em>Gateway&lt;/em> to match and which &lt;em>section&lt;/em> in the
&lt;em>Gateway&lt;/em>.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this blog post we demonstrated to implement TLS with the
Gateway API. We also implemented a shared &lt;em>Gateway&lt;/em> with &lt;em>HTTPRoute&lt;/em>
objects in different namespaces.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Furthermore we configured HTTP to HTTPS redirects and dove into
&lt;em>HTTPRoute&lt;/em> ordering if a route matches multiple listeners in a
&lt;em>Gateway&lt;/em> definition.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>A first look into the Kubernetes Gateway API on OpenShift</title><link>https://blog.stderr.at/openshift/2025/08/a-first-look-into-the-kubernetes-gateway-api-on-openshift/</link><pubDate>Fri, 29 Aug 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/08/a-first-look-into-the-kubernetes-gateway-api-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>This blog post summarizes our first look into the Kubernetes Gateway
API and how it is integrated in OpenShift.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Kubernetes Gateway API is new implementation of the ingress, load
balancing and service mesh API’s. See
&lt;a href="https://gateway-api.sigs.k8s.io/" target="_blank" rel="noopener">upstream&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-overview_ingress-gateway-api" target="_blank" rel="noopener">OpenShift documentation&lt;/a> provides an overview of the Gateway API and it’s integration.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_things_to_consider_when_using_gateway_api_with_openshift">Things to consider when using Gateway API with OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Currently UDN (User Defined Networks) with Gateway API are not supported.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Only TLS termination on the edge is supported (no pass-through or re-encrypt), this needs to be confirmed. We can’t find the original source of this statement&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The standard OpenShift ingress controller manages Gateway API Resources&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Gateway API provides a standard on how to get client traffic into a
Kubernetes cluster. Vendors provide an implementation of the API. So
OpenShift provides &lt;strong>ONE&lt;/strong> possible implementation, but there could
be more than one in a cluster.&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>We found the following sentence in the OpenShift documentation
interesting:&lt;/p>
&lt;div class="literalblock">
&lt;div class="content">
&lt;pre>Because OpenShift Container Platform uses a specific
version of Gateway API CRDs, any use of third-party implementations
of Gateway API must conform to the OpenShift Container Platform
implementation to ensure that all fields work as expected&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_setting_up_gateway_api_on_openshift">Setting up Gateway API on OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before you begin, ensure you have the following:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.19 or higher with cluster-admin access&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First you need to create a &lt;code>GatewayClass&lt;/code> object.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be aware that the &lt;code>GatewayClass&lt;/code> object is &lt;strong>NOT&lt;/strong> namespaced.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: gateway.networking.k8s.io/v1
kind: GatewayClass
metadata:
name: openshift-default
spec:
controllerName: openshift.io/gateway-controller/v1 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The controller name needs to be exactly as shown. Otherwise the
ingress controller will &lt;strong>NOT&lt;/strong> manage the gateway and associated
resources.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This creates a new pod in the openshift-ingress namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po -n openshift-ingress
NAME READY STATUS RESTARTS AGE
istiod-openshift-gateway-7b567bc8b4-4lrt2 1/1 Running 0 12m &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
router-default-6db958cbd-dlbwz 1/1 Running 12 14d&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>this pod got create after applying the gateway class resource&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;code>router-default&lt;/code> is the default openshift ingress pod. The first
difference seems to be the SCC (security context constraint) the pods
are using.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po -n openshift-ingress -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.annotations.openshift\.io/scc}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
istiod-openshift-gateway-7b567bc8b4-4lrt2 restricted-v2
router-default-6db958cbd-dlbwz hostnetwork&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The standard router used host networking for listing on port 80 and 443
on the node where it is running. Our &lt;code>GatewayClass&lt;/code> currently only
provides a pod running Istiod awaiting further configuration. To
actually listen for client request additional configuration is
required.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A &lt;code>Gateway&lt;/code> is required to listen for client requests. We create the
following gateway:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.apps.ocp.lan.stderr.at&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We create this gateway in the same namespace as the istio
deployment. This is required for OpenShift.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This creates an additional pod in the &lt;code>openshift-ingress&lt;/code> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po
NAME READY STATUS RESTARTS AGE
http-gateway-openshift-default-d476664f5-h87mp 1/1 Running 0 36s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We also got a new service for the our http-gateway&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">➜ oc get svc
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
http-gateway-openshift-default LoadBalancer 172.30.183.48 10.0.0.150 15021:30251/TCP,80:30437/TCP 4m52s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The interesting thing is the &lt;code>TYPE&lt;/code> of the service. It’s of type
&lt;code>LoadBalancer&lt;/code>. We have
&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/networking_operators/metallb-operator">MetalLB&lt;/a>
deployed in our cluster, this might be the reason for this. We will
try to configure a gateway without MetalLB in in upcoming post.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Lets take a look at the gateway resource&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get gtw
NAME CLASS ADDRESS PROGRAMMED AGE
http-gateway openshift-default 10.0.0.150 True 3m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So this seems to be working. But know we have a problem: the &lt;code>*.apps&lt;/code>
domain that we used for our gateway points already to the default
OpenShift Ingress. We could either&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>redeploy the gateway with a different wildcard domain (e.g. *.gtw…​)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>create a more specific DNS record that points to our new load balancer&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try to confirm this with &lt;em>curl&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://bla.apps.ocp.lan.stderr.at
HTTP/1.0 503 Service Unavailable
pragma: no-cache
cache-control: private, max-age=0, no-cache, no-store
content-type: text/html&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;code>503&lt;/code> is the response of default OpenShift Ingress.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://10.0.0.150
HTTP/1.1 404 Not Found
date: Fri, 29 Aug 2025 14:31:31 GMT
transfer-encoding: chunked&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Our new gateway returns a &lt;code>404&lt;/code> not found response. We choose the
first option and create another wildcard DNS entry for
&lt;code>*.gtw.ocp.lan.stderr.at&lt;/code>. We re-deployed our gateway with the new hostname:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>New hostname for resources exposed via our gateway&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f gateway.yaml
gateway.gateway.networking.k8s.io/http-gateway created&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This also creates a DNSRecord resource:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc describe dnsrecords.ingress.operator.openshift.io -n openshift-ingress http-gateway-c8d7bfc67-wildcard
Name: http-gateway-c8d7bfc67-wildcard
Namespace: openshift-ingress
Labels: gateway.istio.io/managed=openshift.io-gateway-controller-v1
gateway.networking.k8s.io/gateway-name=http-gateway
istio.io/rev=openshift-gateway
Annotations: &amp;lt;none&amp;gt;
API Version: ingress.operator.openshift.io/v1
Kind: DNSRecord
Metadata:
Creation Timestamp: 2025-08-29T14:49:45Z
Finalizers:
operator.openshift.io/ingress-dns
Generation: 1
Owner References:
API Version: v1
Kind: Service
Name: http-gateway-openshift-default
UID: a023de5d-c428-4249-a190-de3cbfeb6964
Resource Version: 141150968
UID: 7a61a867-216e-40b7-88f3-e3934493c477
Spec:
Dns Management Policy: Managed
Dns Name: *.gtw.ocp.lan.stderr.at.
Record TTL: 30
Record Type: A
Targets:
10.0.0.150
Events: &amp;lt;none&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This resource is only internally used by the OpenShift ingress
operator (see &lt;code>oc explain dnsrecord&lt;/code> for details).&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_httproutes_for_exposing_our_service">Creating HTTPRoutes for exposing our service.&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>To actually expose a HTTP pod via our new gateway we need:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A &lt;em>Namespace&lt;/em> to deploy an example pod. We will use a Nginx for this&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A &lt;em>Service&lt;/em> that exposes our Nginx pod&lt;/p>
&lt;/li>
&lt;li>
&lt;p>and finally a &lt;em>HTTPRoute&lt;/em> resource&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For the nginx deployment we used the following manifest:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: v1
kind: Namespace
metadata:
name: gateway-api-test
spec:
finalizers:
- kubernetes
---
apiVersion: apps/v1
kind: Deployment
metadata:
name: nginx-deployment
namespace: gateway-api-test
labels:
app: nginx
spec:
replicas: 1
selector:
matchLabels:
app: nginx
template:
metadata:
labels:
app: nginx
spec:
containers:
- name: nginx
image: quay.io/nginx/nginx-unprivileged:1.29.1
ports:
- containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
name: nginx
namespace: gateway-api-test
spec:
selector:
app: nginx
ports:
- protocol: TCP
port: 8080
targetPort: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s see if our nginx pod got deployed successfully:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po,svc -n gateway-api-test
NAME READY STATUS RESTARTS AGE
pod/nginx-deployment-796cdf7474-b7bqz 1/1 Running 0 20s
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/nginx ClusterIP 172.30.42.36 &amp;lt;none&amp;gt; 8080/TCP 21s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And finally confirm our &lt;code>Service&lt;/code> is working:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc port-forward -n gateway-api-test svc/nginx 8080 &amp;amp;
Forwarding from 127.0.0.1:8080 -&amp;gt; 8080
Forwarding from [::1]:8080 -&amp;gt; 8080
$ curl -I localhost:8080
Handling connection for 8080
HTTP/1.1 200 OK
Server: nginx/1.29.1
Date: Fri, 29 Aug 2025 15:45:12 GMT
Content-Type: text/html
Content-Length: 615
Last-Modified: Wed, 13 Aug 2025 14:33:41 GMT
Connection: keep-alive
ETag: &amp;#34;689ca245-267&amp;#34;
Accept-Ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We received a response from our nginx pod, hurray!&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So next let’s try to create a &lt;code>HTTPRoute&lt;/code> to expose our nginx service to external clients:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>One important point here, the &lt;code>Gateway&lt;/code> actually come in two flavors&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>dedicated gateways, only accepting HTTP routes in the same namespace (&lt;code>openshift-ingress&lt;/code>) in our case.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>shared gateways, which also accept HTTP route objects from other namespaces&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>see &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-deployment_ingress-gateway-api">Gateway API deployment topologies&lt;/a> in the OpenShift documentation for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As this post is already rather long, we focus on the dedicated gateway topology for now.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The HTTP route must be deployed in the same namespace as the
gateway if the dedicated topology is used.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s deploy our &lt;code>HTTPRoute&lt;/code>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f httproute.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Verify we can reach our nginx pod:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 500 Internal Server Error
date: Fri, 29 Aug 2025 15:57:34 GMT
transfer-encoding: chunked&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This return a &lt;em>500&lt;/em> error, something seems to be wrong with our route,
let’s take a look at the status of the &lt;code>HTTPRoute&lt;/code>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc describe gtw http-gateway
.
. (output omitted)
.
Status:
Parents:
Conditions:
Last Transition Time: 2025-08-29T15:54:43Z
Message: Route was valid
Observed Generation: 1
Reason: Accepted
Status: True
Type: Accepted
Last Transition Time: 2025-08-29T15:54:43Z
Message: backendRef nginx/gateway-api-test not accessible to a HTTPRoute in namespace &amp;#34;openshift-ingress&amp;#34; (missing a ReferenceGrant?) &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
Observed Generation: 1
Reason: RefNotPermitted
Status: False &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Type: ResolvedRefs
Controller Name: openshift.io/gateway-controller/v1
Parent Ref:
Group: gateway.networking.k8s.io
Kind: Gateway
Name: http-gateway
Namespace: openshift-ingress&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Something seems to be wrong as the status is &lt;em>False&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Seems we are missing a ReferenceGrant&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Looking at the
&lt;a href="https://gateway-api.sigs.k8s.io/api-types/referencegrant/" target="_blank" rel="noopener">upstream&lt;/a>
documentation reveals a security feature of the Gateway API. Before a
&lt;code>HTTPRoute&lt;/code> can reach a service in a &lt;em>different&lt;/em> namespace we must
create a &lt;code>ReferenceGrant&lt;/code> in the namespace providing the service.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s try to deploy following &lt;code>ReferenceGrant&lt;/code> in the &lt;em>gateway-api-test&lt;/em> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1beta1
kind: ReferenceGrant
metadata:
name: nginx
namespace: gateway-api-test
spec:
from:
- group: gateway.networking.k8s.io
kind: HTTPRoute
namespace: openshift-ingress
to:
- group: &amp;#34;&amp;#34;
kind: Service&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Checking the status field of our &lt;code>HTTPRoute&lt;/code> again:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">(output omitted)
Status:
Addresses:
Type: IPAddress
Value: 10.0.0.150
Conditions:
Last Transition Time: 2025-08-29T15:47:07Z
Message: Resource accepted
Observed Generation: 1
Reason: Accepted
Status: True
Type: Accepted
Last Transition Time: 2025-08-29T15:47:08Z
Message: Resource programmed, assigned to service(s) http-gateway-openshift-default.openshift-ingress.svc.cluster.local:80
Observed Generation: 1
Reason: Programmed
Status: True &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Type: Programmed&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>&lt;em>Status&lt;/em> is now &lt;em>True&lt;/em>&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>and finally calling the nginx pod again via our gateway:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK
server: nginx/1.29.1
date: Fri, 29 Aug 2025 16:01:33 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally everything seems to be in place and working.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this blog post we took a first look at the Kubernetes Gateway API
and it’s integration into OpenShift. We enabled the Gateway API via a
&lt;code>GatewayClass&lt;/code> resource, created a simple HTTP Gateway via a
&lt;code>Gateway&lt;/code>, deploy a Nginx pod and a Service and exposed the service
via a &lt;code>HTTPRoute&lt;/code> and a &lt;code>ReferenceGrant&lt;/code>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Hopefully an upcoming blog post will cover how to&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>How to deploy a Gateway without MetalLB&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Deploy a TLS secured service&lt;/p>
&lt;/li>
&lt;li>
&lt;p>implement HTTP redirects&lt;/p>
&lt;/li>
&lt;li>
&lt;p>rewriting URL’s (if possible)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>and other possibilities of the Gateway API&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Running Falco on OpenShift 4.12</title><link>https://blog.stderr.at/openshift/2023/11/running-falco-on-openshift-4.12/</link><pubDate>Sun, 26 Nov 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/11/running-falco-on-openshift-4.12/</guid><description>&lt;p>
As mentioned in our &lt;a href="https://blog.stderr.at/openshift/2023-10-23-openshift-falco/">previous post&lt;/a> about &lt;a href="https://falco.org/">Falco&lt;/a>, Falco is a security
tool to monitor kernel events like system calls or Kubernetes audit
logs to provide real-time alerts.&lt;/p>
&lt;p>
In this post I&amp;#39;ll show to customize Falco for a specific use case.
We would like to monitor the following events:&lt;/p>
&lt;ul>
&lt;li>An interactive shell is opened in a container&lt;/li>
&lt;li>Log all commands executed in an interactive shell in a container&lt;/li>
&lt;li>Log read and writes to files within an interactive shell inside a container&lt;/li>
&lt;li>Log commands execute via `kubectl/oc exec` which leverage the
&lt;code>pod/exec&lt;/code> K8s endpoint&lt;/li>
&lt;/ul>
&lt;p>
The rules we created for those kind of events are available &lt;a href="https://raw.githubusercontent.com/tosmi-gitops/openshift-gitops/main/components/apps/falco/overlays/custom-rules/falco-extra-rules.yaml">here&lt;/a>.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Deploying custom rules and disabling the default ruleset
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
Falco comes with a quite elaborate ruleset for creating security
relevant events. But for our use case we just want to deploy a
specific set of rules (see the list above).&lt;/p>
&lt;p>
As we are deploying Falco via &lt;a href="https://github.com/falcosecurity/charts">Helm&lt;/a>, we use the following values for
`rules_files`:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">rules_file&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/etc/falco/extra-rules.d&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/etc/falco/rules.d&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
This instructs Falco to only load rules from the directories mentioned
above.&lt;/p>
&lt;p>
We use a &lt;span style="text-decoration: underline;">Kustomize&lt;/span> &lt;code>configMapGenerator&lt;/code> to create a Kubernetes &lt;code>ConfigMap&lt;/code>
from our custom rules file:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">configMapGenerator&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">options&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">disableNameSuffixHash&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">files&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">falco-extra-rules.yaml&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
The complete &lt;span style="text-decoration: underline;">Kustomize&lt;/span> configuration is &lt;a href="https://raw.githubusercontent.com/tosmi-gitops/openshift-gitops/main/components/apps/falco/overlays/custom-rules/kustomization.yaml">here&lt;/a>.&lt;/p>
&lt;p>
Furthermore we instruct Falco to mount our custom rule &lt;code>ConfigMap&lt;/code>
created above in the Helm values file:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">mounts&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules-volume&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">optional&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMap&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumeMounts&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/falco/extra-rules.d&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules-volume&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
The complete Helm values files is available &lt;a href="https://raw.githubusercontent.com/tosmi-gitops/openshift-gitops/main/components/apps/falco/base/values.yaml">here&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-2" class="outline-2">
&lt;h2 id="headline-2">
Disable automatic rule updates
&lt;/h2>
&lt;div id="outline-text-headline-2" class="outline-text-2">
&lt;p>
Falco updates all rules when it starts (via an &lt;span style="text-decoration: underline;">initContainer&lt;/span>) and also
updates those rules on a regular basis. We would also like to disable
this behavior:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falcoctl&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">artifact&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">install&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">follow&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Create events for &lt;span style="text-decoration: underline;">kubectl/oc exec&lt;/span>
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
One problem problem is monitoring pod exec events. Using Falcos eBPF
monitoring capabilities we found no way to limit those events to pod
exec&amp;#39;s. This might be because the Falco rule language is new to us
and maybe there is a way to use eBPF filtering. Just let us know if
you find a solution!&lt;/p>
&lt;p>
But we came up with a different way of capturing pod/exec events:&lt;/p>
&lt;p>
Falco also allows monitoring Kubernetes audit events, logged by the
&lt;code>kube-apiserver&lt;/code>. Every time you hit the &lt;code>pod/exec&lt;/code> endpoint, K8s logs the
following event in the audit log:&lt;/p>
&lt;div class="src src-json">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#f92672">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;Event&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;audit.k8s.io/v1&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;level&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;Metadata&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;auditID&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;5c19c1d0-00a7-4af5-a236-5345b5963581&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;stage&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ResponseComplete&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;requestURI&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/api/v1/namespaces/falco/pods/falco-8mqj7/exec?command=cat\u0026command=%2Fetc%2Ffalco%2Fextra-rules.d%2Ffalco-extra-rules.yaml\u0026container=falco\u0026stderr=true\u0026stdout=true&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;verb&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;create&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;user&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;username&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;root&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;uid&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;d82ec74a-75e3-4798-a084-4b766dcea5ef&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;groups&amp;#34;&lt;/span>:[&lt;span style="color:#e6db74">&amp;#34;cluster-admins&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;system:authenticated:oauth&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;system:authenticated&amp;#34;&lt;/span>],&lt;span style="color:#f92672">&amp;#34;extra&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;scopes.authorization.openshift.io&amp;#34;&lt;/span>:[&lt;span style="color:#e6db74">&amp;#34;user:full&amp;#34;&lt;/span>]}},&lt;span style="color:#f92672">&amp;#34;sourceIPs&amp;#34;&lt;/span>:[&lt;span style="color:#e6db74">&amp;#34;10.0.32.220&amp;#34;&lt;/span>],&lt;span style="color:#f92672">&amp;#34;userAgent&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;oc/4.13.0 (linux/amd64) kubernetes/92b1a3d&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;objectRef&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;resource&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;pods&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;namespace&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;falco-8mqj7&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;v1&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;subresource&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;exec&amp;#34;&lt;/span>},&lt;span style="color:#f92672">&amp;#34;responseStatus&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;metadata&amp;#34;&lt;/span>:{},&lt;span style="color:#f92672">&amp;#34;code&amp;#34;&lt;/span>:&lt;span style="color:#ae81ff">101&lt;/span>},&lt;span style="color:#f92672">&amp;#34;requestReceivedTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2023-11-13T17:23:16.999602Z&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;stageTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2023-11-13T17:23:17.231121Z&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;annotations&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;authorization.k8s.io/decision&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;allow&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;authorization.k8s.io/reason&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;RBAC: allowed by ClusterRoleBinding \&amp;#34;root-cluster-admin\&amp;#34; of ClusterRole \&amp;#34;cluster-admin\&amp;#34; to User \&amp;#34;root\&amp;#34;&amp;#34;&lt;/span>}}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
As you can hopefully see, the command executed is available in the
&lt;span style="text-decoration: underline;">requestURI&lt;/span> field.&lt;/p>
&lt;p>
So we enabled the &lt;span style="text-decoration: underline;">k8saudit&lt;/span> Falco plugin and created an additional rule
for those kind of events.&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">plugins&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">k8saudit&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">library_path&lt;/span>: &lt;span style="color:#ae81ff">libk8saudit.so&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">init_config&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># maxEventSize: 262144&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># webhookMaxBatchSize: 12582912&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># sslCertificate: /etc/falco/falco.pem&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># open_params: &amp;#34;http://:9765/k8s-audit&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">open_params&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/host/var/log/kube-apiserver/audit.log&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">json&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">library_path&lt;/span>: &lt;span style="color:#ae81ff">libjson.so&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">init_config&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-4" class="outline-2">
&lt;h2 id="headline-4">
Implementing event routing
&lt;/h2>
&lt;div id="outline-text-headline-4" class="outline-text-2">
&lt;p>
We had an additional requirement to route events based on the following rules:&lt;/p>
&lt;ul>
&lt;li>Events that &lt;strong>do not&lt;/strong> contain sensitive data (like usernames) should go
to a specific Kafka topic&lt;/li>
&lt;li>Events that &lt;strong>do&lt;/strong> contain sensitive data (like usernames) should be
routed to another Kafka topic&lt;/li>
&lt;/ul>
&lt;p>Our first thought was to leverage Falcosidekick&amp;#39;s &lt;a href="https://github.com/falcosecurity/falcosidekick/blob/2.28.0/config_example.yaml#L279">minimumpriority&lt;/a>
field for routing. Events with sensitive data would get a higher
priority. But the sink with a lower &lt;span style="text-decoration: underline;">minimumpriority&lt;/span> would get events
with higher priority as well, which means events with sensitive data.&lt;/p>
&lt;p>
Furthermore as far as we know Falco currently only supports one Kafka
configuration (we need two for two topics).&lt;/p>
&lt;p>
At this point in time we are not aware of a possibility to implement
this with Falco or Falcosidekick directly.&lt;/p>
&lt;p>
There are some discussions upstream on implementing such a feature:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/falcosecurity/falcosidekick/issues/161">https://github.com/falcosecurity/falcosidekick/issues/161&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/falcosecurity/falcosidekick/issues/161#issuecomment-747714289">https://github.com/falcosecurity/falcosidekick/issues/161#issuecomment-747714289&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/falcosecurity/falcosidekick/issues/224">https://github.com/falcosecurity/falcosidekick/issues/224&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Our current idea is to use &lt;a href="https://vector.dev/">Vector&lt;/a> for event routing. We will try to
implement the following pipeline:&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/openshift/images/falco/falco-pipeline.png" alt="/openshift/images/falco/falco-pipeline.png" title="/openshift/images/falco/falco-pipeline.png" />&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-2">
&lt;h2 id="headline-5">
Tips and Tricks
&lt;/h2>
&lt;div id="outline-text-headline-5" class="outline-text-2">
&lt;div id="outline-container-headline-6" class="outline-3">
&lt;h3 id="headline-6">
Monitor Redis disk usage
&lt;/h3>
&lt;div id="outline-text-headline-6" class="outline-text-3">
&lt;p>
One small hint when using &lt;code>falcosidekick-ui&lt;/code> to debug/monitor events. It
happened to us that the Redis volume was full and suddenly we couldn&amp;#39;t
see new events in the UI.&lt;/p>
&lt;p>
We stopped the UI and Redis pods, removed the PVC and just ran our kustomization
again, to recreate the PVC and the pods.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-7" class="outline-3">
&lt;h3 id="headline-7">
Monitor &lt;span style="text-decoration: underline;">falco&lt;/span> pod logs when changing rules
&lt;/h3>
&lt;div id="outline-text-headline-7" class="outline-text-3">
&lt;p>
It&amp;#39;s always wise to monitor one Falco pod for errors when deploying
new rules, for example at one point we hit the following error:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>{&amp;#34;hostname&amp;#34;:&amp;#34;falco-2hlkm&amp;#34;,&amp;#34;output&amp;#34;:&amp;#34;Falco internal: hot restart failure: /etc/falco/extra-rules.d/falco-extra-rules.yaml: Invalid\n1 Errors:\nIn rules content: (/etc/falco/extra-rules.d/falco-extra-rules.yaml:0:0)\n rule &amp;#39;Terminal shell in container&amp;#39;: (/etc/falco/extra-rules.d/falco-extra-rules.yaml:25:2)\n condition expression: (\&amp;#34;spawned_process a...\&amp;#34;:26:71)\n------\n...ocess and container and shell_procs and proc.tty != 0 and container_entrypoint\n ^\n------\nLOAD_ERR_VALIDATE (Error validating rule/macro/list/exception objects): Undefined macro &amp;#39;container_entrypoint&amp;#39; used in filter.\n&amp;#34;,&amp;#34;output_fields&amp;#34;:{},&amp;#34;priority&amp;#34;:&amp;#34;Critical&amp;#34;,&amp;#34;rule&amp;#34;:&amp;#34;Falco internal: hot restart failure&amp;#34;,&amp;#34;source&amp;#34;:&amp;#34;internal&amp;#34;,&amp;#34;time&amp;#34;:&amp;#34;2023-11-13T11:47:14.639547735Z&amp;#34;}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Falco is quite resilient when it comes to errors in rules files and
provides useful hints on what might be wrong:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Undefined macro &amp;#39;container_entrypoint&amp;#39; used in filter&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So we just added the missing macro and all was swell again.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Setting up Falco on OpenShift 4.12</title><link>https://blog.stderr.at/openshift/2023/10/setting-up-falco-on-openshift-4.12/</link><pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/10/setting-up-falco-on-openshift-4.12/</guid><description>&lt;p>
&lt;a href="https://falco.org/">Falco&lt;/a> is a security tool to monitor kernel events like system calls to
provide real-time alerts. In this post I&amp;#39;ll document the steps taken
to get Open Source &lt;a href="https://falco.org/">Falco&lt;/a> running on an OpenShift 4.12 cluster.&lt;/p>
&lt;p>
&lt;a href="https://blog.stderr.at/openshift/2023-10-23-openshift-falco/#headline-4">UPDATE&lt;/a>: Use the &lt;code>falco-driver-loader-legacy&lt;/code> image for OpenShift 4.12 deployments.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
First Try
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
We will use the &lt;a href="https://falcosecurity.github.io/charts">Falco Helm chart&lt;/a> version 3.8.0 for our first try of setting up Falco on our OpenShift cluster.&lt;/p>
&lt;p>
This is our values file:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>driver:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: ebpf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> json_output: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> json_include_output_property: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log_syslog: false
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log_level: info
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falcosidekick:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> webui:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: true&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We would like to use the eBPF driver to monitor kernel events, enable
falco sidekick, which is used to route events and the falco sidekick
UI for easier testing.&lt;/p>
&lt;p>
Because of reasons we leverage kustomize to render the helm chart. The
final kustomize config is &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/tree/main/components/apps/falco/base">here&lt;/a> (after fixing all problems mentioned
below).&lt;/p>
&lt;p>
So after deploying the chart via ArgoCD (another story), we have the following pods:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc get pods -n falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-4cc8j 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>95s ago&lt;span style="color:#f92672">)&lt;/span> 4m31s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-bx87j 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>75s ago&lt;span style="color:#f92672">)&lt;/span> 4m29s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-ds9w6 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>99s ago&lt;span style="color:#f92672">)&lt;/span> 4m30s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 4m28s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-gxznz 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">3&lt;/span> &lt;span style="color:#f92672">(&lt;/span>14s ago&lt;span style="color:#f92672">)&lt;/span> 4m30s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-vtnk5 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>98s ago&lt;span style="color:#f92672">)&lt;/span> 4m29s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-wbn2k 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>80s ago&lt;span style="color:#f92672">)&lt;/span> 4m29s&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
hm, not so good. Seems like some &lt;code>initContainers&lt;/code> are failing.&lt;/p>
&lt;p>
Let&amp;#39;s check the &lt;code>falco-driver-loader&lt;/code> initContainer:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>* Setting up /usr/src links from host
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader &lt;span style="color:#66d9ef">for&lt;/span>: falco version&lt;span style="color:#f92672">=&lt;/span>0.36.1, driver version&lt;span style="color:#f92672">=&lt;/span>6.0.1+driver, arch&lt;span style="color:#f92672">=&lt;/span>x86_64, kernel release&lt;span style="color:#f92672">=&lt;/span>4.18.0-372.73.1.el8_6.x86_64, kernel version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader with: driver&lt;span style="color:#f92672">=&lt;/span>bpf, compile&lt;span style="color:#f92672">=&lt;/span>yes, download&lt;span style="color:#f92672">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Mounting debugfs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mount: /sys/kernel/debug: permission denied.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dmesg&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> may have more information after failed mount system call.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Filename &lt;span style="color:#e6db74">&amp;#39;falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&amp;#39;&lt;/span> is composed of:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - driver name: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - target identifier: rhcos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel release: 4.18.0-372.73.1.el8_6.x86_64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel version: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to download a prebuilt eBPF probe from https://download.falco.org/driver/6.0.1%2Bdriver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl: &lt;span style="color:#f92672">(&lt;/span>22&lt;span style="color:#f92672">)&lt;/span> The requested URL returned error: &lt;span style="color:#ae81ff">404&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find a prebuilt falco eBPF probe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to compile the eBPF probe &lt;span style="color:#f92672">(&lt;/span>falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>expr: syntax error: unexpected argument &lt;span style="color:#e6db74">&amp;#39;1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span>: *** /lib/modules/4.18.0-372.73.1.el8_6.x86_64/build: No such file or directory. Stop.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make: *** &lt;span style="color:#f92672">[&lt;/span>Makefile:38: all&lt;span style="color:#f92672">]&lt;/span> Error &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv: cannot stat &lt;span style="color:#e6db74">&amp;#39;/usr/src/falco-6.0.1+driver/bpf/probe.o&amp;#39;&lt;/span>: No such file or directory
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to load the falco eBPF probe&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Seems to be an issue with a missing directory &lt;span style="text-decoration: underline;">/lib/modules/4.18.0-372.73.1.el8_6.x86_64/build&lt;/span>.&lt;/p>
&lt;p>
And we told the helm chart to enable &lt;code>falco-sidekick&lt;/code> and
&lt;code>falco-sidekick-ui&lt;/code>, but where are they?&lt;/p>
&lt;p>
Let&amp;#39;s check the events with &lt;code>oc get events&lt;/code> as well, and what do we see?&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>8s Warning FailedCreate replicaset/falco-falcosidekick-7cfbbbf89f Error creating: pods &lt;span style="color:#e6db74">&amp;#34;falco-falcosidekick-7cfbbbf89f-&amp;#34;&lt;/span> is forbidden: unable to validate against any security context constraint: &lt;span style="color:#f92672">[&lt;/span>provider &lt;span style="color:#e6db74">&amp;#34;anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider restricted-v2: .spec.securityContext.fsGroup: Invalid value: &lt;span style="color:#f92672">[]&lt;/span>int64&lt;span style="color:#f92672">{&lt;/span>1234&lt;span style="color:#f92672">}&lt;/span>: &lt;span style="color:#ae81ff">1234&lt;/span> is not an allowed group, provider restricted-v2: .containers&lt;span style="color:#f92672">[&lt;/span>0&lt;span style="color:#f92672">]&lt;/span>.runAsUser: Invalid value: 1234: must be in the ranges: &lt;span style="color:#f92672">[&lt;/span>1000730000, 1000739999&lt;span style="color:#f92672">]&lt;/span>, provider &lt;span style="color:#e6db74">&amp;#34;restricted&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostmount-anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;machine-api-termination-handler&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostaccess&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;node-exporter&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;privileged&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>6s Warning FailedCreate replicaset/falco-falcosidekick-ui-76885bd484 Error creating: pods &lt;span style="color:#e6db74">&amp;#34;falco-falcosidekick-ui-76885bd484-&amp;#34;&lt;/span> is forbidden: unable to validate against any security context constraint: &lt;span style="color:#f92672">[&lt;/span>provider &lt;span style="color:#e6db74">&amp;#34;anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider restricted-v2: .spec.securityContext.fsGroup: Invalid value: &lt;span style="color:#f92672">[]&lt;/span>int64&lt;span style="color:#f92672">{&lt;/span>1234&lt;span style="color:#f92672">}&lt;/span>: &lt;span style="color:#ae81ff">1234&lt;/span> is not an allowed group, provider restricted-v2: .containers&lt;span style="color:#f92672">[&lt;/span>0&lt;span style="color:#f92672">]&lt;/span>.runAsUser: Invalid value: 1234: must be in the ranges: &lt;span style="color:#f92672">[&lt;/span>1000730000, 1000739999&lt;span style="color:#f92672">]&lt;/span>, provider &lt;span style="color:#e6db74">&amp;#34;restricted&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostmount-anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;machine-api-termination-handler&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostaccess&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;node-exporter&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;privileged&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount&lt;span style="color:#f92672">]&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Looks like a problem with OpenShifts Security Context constraints (SCC&amp;#39;s).&lt;/p>
&lt;div id="outline-container-headline-2" class="outline-3">
&lt;h3 id="headline-2">
Summary of problems
&lt;/h3>
&lt;div id="outline-text-headline-2" class="outline-text-3">
&lt;ul>
&lt;li>The falco &lt;code>DaemonSet&lt;/code> fails to start pods because there is an issue with a missing directory&lt;/li>
&lt;li>Falco Sidekick and Falco Sidekick UI fails to start because of
Security Context Constraint (SCC) issues&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Fixing the Falco daemonset
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
Falco tries to download a pre-compiled eBPF probe, fails and then
tries to compile that probe for our host OS kernel. This fails with the message:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span>: *** /lib/modules/4.18.0-372.73.1.el8_6.x86_64/build: No such file or directory. Stop.&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
As far as we know there are no kernel sources installed on RHCOS nodes
in OpenShift. After a little bit of searching the interweb we found
the following issue comment on Github:&lt;/p>
&lt;p>
&lt;a href="https://github.com/falcosecurity/falco/issues/1505#issuecomment-754745960">OpenShift under vsphere: Download failed, consider compiling your own falco module and loading it or getting in touch with the Falco community&lt;/a>&lt;/p>
&lt;p>
So we need to enable the &lt;code>kernel-devel&lt;/code> extension, the official docs are
&lt;a href="https://docs.openshift.com/container-platform/4.12/post_installation_configuration/machine-configuration-tasks.html#rhcos-add-extensions_post-install-machine-configuration-tasks">here&lt;/a>. It does not mention &lt;code>kernel-devel&lt;/code>, but there&amp;#39;s a &lt;a href="https://access.redhat.com/solutions/6972423">knowledge base
article&lt;/a> mentioning &lt;code>kernel-devel&lt;/code>, so let&amp;#39;s give it a try.&lt;/p>
&lt;p>
We deploy two &lt;code>MachineConfigs&lt;/code>, one for &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/worker-machineconfig.yaml">worker&lt;/a> and one for &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/master-machineconfig.yaml">master&lt;/a> nodes
to rollout the extension, the worker configuration looks like this:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">machineconfiguration.openshift.io/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">MachineConfig&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">machineconfiguration.openshift.io/role&lt;/span>: &lt;span style="color:#ae81ff">worker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">99&lt;/span>-&lt;span style="color:#ae81ff">worker-kernel-devel-extensions&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">extensions&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">kernel-devel&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
See also our Kustomize configuration &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/kustomization.yaml">here&lt;/a>.&lt;/p>
&lt;p>
As soon as we apply our &lt;code>MachineConfigs&lt;/code>, OpenShift starts the rollout via MaschineConfigPool&amp;#39;s:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>$ oc get mcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME CONFIG UPDATED UPDATING DEGRADED MACHINECOUNT READYMACHINECOUNT UPDATEDMACHINECOUNT DEGRADEDMACHINECOUNT AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>master rendered-master-ce464ff45cc049fce3e8a63e36a4ee9e False True False 3 0 0 0 13d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>worker rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d False True False 3 0 0 0 13d&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
When the rollout is done, let&amp;#39;s restart all Falco &lt;code>DaemonSet&lt;/code> pods:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc delete pods -l app.kubernetes.io/name&lt;span style="color:#f92672">=&lt;/span>falco&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
And check the status:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc get pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-5wfnk 0/2 Init:Error &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>3s ago&lt;span style="color:#f92672">)&lt;/span> 7s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-66fxw 0/2 Init:0/2 &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-6fbc7 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 8s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-8h8n4 0/2 Init:0/2 &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 18m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-nhld2 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-xqv4b 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>3s ago&lt;span style="color:#f92672">)&lt;/span> 8s&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
still, the &lt;code>initContainers&lt;/code> fail. Lets check the log again&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc logs -c falco-driver-loader falco-5wfnk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Setting up /usr/src links from host
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader &lt;span style="color:#66d9ef">for&lt;/span>: falco version&lt;span style="color:#f92672">=&lt;/span>0.36.1, driver version&lt;span style="color:#f92672">=&lt;/span>6.0.1+driver, arch&lt;span style="color:#f92672">=&lt;/span>x86_64, kernel release&lt;span style="color:#f92672">=&lt;/span>4.18.0-372.73.1.el8_6.x86_64, kernel version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader with: driver&lt;span style="color:#f92672">=&lt;/span>bpf, compile&lt;span style="color:#f92672">=&lt;/span>yes, download&lt;span style="color:#f92672">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Mounting debugfs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mount: /sys/kernel/debug: permission denied.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dmesg&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> may have more information after failed mount system call.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Filename &lt;span style="color:#e6db74">&amp;#39;falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&amp;#39;&lt;/span> is composed of:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - driver name: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - target identifier: rhcos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel release: 4.18.0-372.73.1.el8_6.x86_64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel version: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to download a prebuilt eBPF probe from https://download.falco.org/driver/6.0.1%2Bdriver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl: &lt;span style="color:#f92672">(&lt;/span>22&lt;span style="color:#f92672">)&lt;/span> The requested URL returned error: &lt;span style="color:#ae81ff">404&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find a prebuilt falco eBPF probe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to compile the eBPF probe &lt;span style="color:#f92672">(&lt;/span>falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile:1005: *** &lt;span style="color:#e6db74">&amp;#34;Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel&amp;#34;&lt;/span>. Stop.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make: *** &lt;span style="color:#f92672">[&lt;/span>Makefile:38: all&lt;span style="color:#f92672">]&lt;/span> Error &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv: cannot stat &lt;span style="color:#e6db74">&amp;#39;/usr/src/falco-6.0.1+driver/bpf/probe.o&amp;#39;&lt;/span>: No such file or directory
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to load the falco eBPF probe&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So this time we get another error, the culprit is the following line&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>Makefile:1005: *** &lt;span style="color:#e6db74">&amp;#34;Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel&amp;#34;&lt;/span>. Stop.&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Back to searching the interweb only reveals an old &lt;a href="https://github.com/falcosecurity/falco/issues/376">issue&lt;/a>, that should
be fixed already.&lt;/p>
&lt;p>
So as a quick hack we &lt;a href="https://github.com/tosmi/playground/blob/master/openshift/falco/custom-falco-driver-loader/Dockerfile">modified&lt;/a> the &lt;code>falco-driver-loader&lt;/code> image to
contain &lt;code>libelf-dev&lt;/code> and pushed to image to &lt;a href="https://quay.io/repository/tosmi/falco-driver-loader?tab=tags">quay&lt;/a>.&lt;/p>
&lt;p>
We then modified our falco helm configuration to use the updated image:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">driver&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ebpf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">loader&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">initContainer&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">registry&lt;/span>: &lt;span style="color:#ae81ff">quay.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">repository&lt;/span>: &lt;span style="color:#ae81ff">tosmi/falco-driver-loader&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tag&lt;/span>: &lt;span style="color:#ae81ff">0.36.1&lt;/span>-&lt;span style="color:#ae81ff">libelf-dev&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_output&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_include_output_property&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_syslog&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_level&lt;/span>: &lt;span style="color:#ae81ff">info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falcosidekick&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">webui&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Note the updated &lt;code>diver.loader.initContainer&lt;/code> section.&lt;/p>
&lt;p>
Let&amp;#39;s check the our pods again:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-2ssgx 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 66s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-5hqgg 1/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 66s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-82kq9 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-99zxw 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-test-connection 0/1 Error &lt;span style="color:#ae81ff">0&lt;/span> 67s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 31m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-slx5k 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-tzm8d 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Success! This time the &lt;code>DaemonSet&lt;/code> pods started successfully. Just note
that you have to be patient. The first start took about 1-2 minutes to
complete.&lt;/p>
&lt;p>
Let&amp;#39;s check the logs of one &lt;code>DaemonSet&lt;/code> pod just to sure:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>oc logs -c falco-driver-loader falco-2ssgx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Setting up /usr/src links from host
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader &lt;span style="color:#66d9ef">for&lt;/span>: falco version&lt;span style="color:#f92672">=&lt;/span>0.36.1, driver version&lt;span style="color:#f92672">=&lt;/span>6.0.1+driver, arch&lt;span style="color:#f92672">=&lt;/span>x86_64, kernel release&lt;span style="color:#f92672">=&lt;/span>4.18.0-372.73.1.el8_6.x86_64, kernel version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader with: driver&lt;span style="color:#f92672">=&lt;/span>bpf, compile&lt;span style="color:#f92672">=&lt;/span>yes, download&lt;span style="color:#f92672">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Mounting debugfs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mount: /sys/kernel/debug: permission denied.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dmesg&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> may have more information after failed mount system call.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Filename &lt;span style="color:#e6db74">&amp;#39;falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&amp;#39;&lt;/span> is composed of:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - driver name: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - target identifier: rhcos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel release: 4.18.0-372.73.1.el8_6.x86_64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel version: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to download a prebuilt eBPF probe from https://download.falco.org/driver/6.0.1%2Bdriver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl: &lt;span style="color:#f92672">(&lt;/span>22&lt;span style="color:#f92672">)&lt;/span> The requested URL returned error: &lt;span style="color:#ae81ff">404&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find a prebuilt falco eBPF probe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to compile the eBPF probe &lt;span style="color:#f92672">(&lt;/span>falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* eBPF probe located in /root/.falco/6.0.1+driver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Success: eBPF probe symlinked to /root/.falco/falco-bpf.o&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Especially the line&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>* Success: eBPF probe symlinked to /root/.falco/falco-bpf.o&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
looks promising. So up to the next problem, getting falco-sidekick and falco-sidekick-ui running.&lt;/p>
&lt;p>
We also &lt;a href="https://github.com/falcosecurity/falco/issues/2884">opened a bug&lt;/a> report upstream to get feedback from the
developers on this issue.&lt;/p>
&lt;div id="outline-container-headline-4" class="outline-3">
&lt;h3 id="headline-4">
UPDATE
&lt;/h3>
&lt;div id="outline-text-headline-4" class="outline-text-3">
&lt;p>
&lt;a href="https://github.com/Andreagit97">Andreagit97&lt;/a> was so nice mentioning in the issue above that
actually there is an image with libelf-dev available,
&lt;a href="https://hub.docker.com/r/falcosecurity/falco-driver-loader-legacy">falco-driver-loader-legacy&lt;/a>. We can confirm that this image fixes the
problem mentioned above.&lt;/p>
&lt;p>
So this is our final falco helm chart values.yaml:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">driver&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ebpf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">loader&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">initContainer&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">repository&lt;/span>: &lt;span style="color:#ae81ff">falcosecurity/falco-driver-loader-legacy&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_output&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_include_output_property&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_syslog&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_level&lt;/span>: &lt;span style="color:#ae81ff">info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falcosidekick&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">webui&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-2">
&lt;h2 id="headline-5">
Fixing falco-sidekick and falco-sidekick-ui
&lt;/h2>
&lt;div id="outline-text-headline-5" class="outline-text-2">
&lt;p>
Remember pod startup actually failed because of the following event (check with &lt;code>oc get events&lt;/code>):&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>.spec.securityContext.fsGroup: Invalid value: []int64{1234}: 1234 is not an allowed group&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
It seems the sidekick pods want to run with a specific UID. The
default OpenShift Security Context Constraint (SCC) &lt;code>restricted&lt;/code>
prohibits this.&lt;/p>
&lt;p>
Lets confirm our suspicion:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.securityContext}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;fsGroup&amp;#34;&lt;/span>:1234,&lt;span style="color:#e6db74">&amp;#34;runAsUser&amp;#34;&lt;/span>:1234&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.securityContext}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick-ui
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;fsGroup&amp;#34;&lt;/span>:1234,&lt;span style="color:#e6db74">&amp;#34;runAsUser&amp;#34;&lt;/span>:1234&lt;span style="color:#f92672">}&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Bingo! &lt;code>securityContext&lt;/code> is set to 1234 for both deployments. There is
another SCC that we could leverage, &lt;code>nonroot&lt;/code>, which basically allows any
UID expect 0. We just need to get the &lt;code>ServiceAccount&lt;/code> that
falco-sidekick and falco-sidekick-ui are actually using:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.serviceAccount}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.serviceAccount}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick-ui
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So falco-sidekick uses &lt;code>falco-sidekick&lt;/code> as &lt;code>ServiceAccount&lt;/code> and falco-sidekick-ui &lt;code>falco-sidekick-ui&lt;/code>. Lets
grant both &lt;code>ServiceAccounts&lt;/code> access to the &lt;code>nonroot&lt;/code> SCC.&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>kind: ClusterRoleBinding
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: falco-falcosidekick-scc:nonroot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>roleRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiGroup: rbac.authorization.k8s.io
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: ClusterRole
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: system:openshift:scc:nonroot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>subjects:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: ServiceAccount
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: ServiceAccount
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: falco-falcosidekick-ui
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: falco&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We&amp;#39;ve already added this &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/falcosidekick-any-uid-scc.yaml">file&lt;/a> to our &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/falcosidekick-any-uid-scc.yaml#L19">Kustomize&lt;/a> configuration.&lt;/p>
&lt;p>
Let&amp;#39;s trigger a redeployment by deleting the &lt;code>ReplicaSets&lt;/code> of both deployments, they will be re-created automatically:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc delete rs -l app.kubernetes.io/name&lt;span style="color:#f92672">=&lt;/span>falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc delete rs -l app.kubernetes.io/name&lt;span style="color:#f92672">=&lt;/span>falcosidekick-ui&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Finally let&amp;#39;s confirm everything is up and running:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get deploy,ds,pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY UP-TO-DATE AVAILABLE AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/falco-falcosidekick 2/2 &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> 5d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/falco-falcosidekick-ui 2/2 &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> 5d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>daemonset.apps/falco &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &amp;lt;none&amp;gt; 6d2h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-2ssgx 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-5hqgg 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-82kq9 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-99zxw 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-7cfbbbf89f-qxwxs 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 118s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-7cfbbbf89f-rz5lj 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 118s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-ui-76885bd484-p7lqm 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 2m18s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-ui-76885bd484-sfgh4 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 2m18s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 51m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-slx5k 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-tzm8d 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-6" class="outline-2">
&lt;h2 id="headline-6">
Testing Falco
&lt;/h2>
&lt;div id="outline-text-headline-6" class="outline-text-2">
&lt;p>
Now that everything seems to be running, lets do a quick test. First
we will try to access the Falco Sidekick user interface.&lt;/p>
&lt;p>
Falco will not deploy a route for the UI automatically, instead we&amp;#39;ve
created a &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/tree/main/components/apps/falco/overlays/sidekick-ui-route">Kustomize overlay&lt;/a> with a custom route:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">route.openshift.io/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Route&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-falcosidekick-ui&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">falco&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">host&lt;/span>: &lt;span style="color:#ae81ff">falcosidekick-ui.apps.hub.aws.tntinfra.net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">port&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetPort&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tls&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">termination&lt;/span>: &lt;span style="color:#ae81ff">edge&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">to&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-falcosidekick-ui&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">wildcardPolicy&lt;/span>: &lt;span style="color:#ae81ff">None&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
After deploying the &lt;code>Route&lt;/code> we can access the Falco UI with the hostname
specified in the route object. The default username seems to be
&lt;span style="text-decoration: underline;">admin/admin&lt;/span> which is kind of strange for a security tool, maybe that&amp;#39;s
the reason Falco does not expose the UI per default.&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/openshift/images/falco/falco-ui.png" alt="/openshift/images/falco/falco-ui.png" title="/openshift/images/falco/falco-ui.png" />&lt;/p>
&lt;div id="outline-container-headline-7" class="outline-3">
&lt;h3 id="headline-7">
Creating an event
&lt;/h3>
&lt;div id="outline-text-headline-7" class="outline-text-3">
&lt;p>
As a last test let&amp;#39;s try to trigger an event. We open a shell to one
of the falco &lt;code>DaemonSet&lt;/code> pods and execute a suspicious command:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc rsh falco-2ssgx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Defaulted container &lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span> out of: falco, falcoctl-artifact-follow, falco-driver-loader &lt;span style="color:#f92672">(&lt;/span>init&lt;span style="color:#f92672">)&lt;/span>, falcoctl-artif# cat /etc/shadow
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>daemon:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bin:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sys:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sync:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>games:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>man:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lp:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mail:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>news:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>uucp:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>proxy:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>www-data:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>backup:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>list:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>irc:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>_apt:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nobody:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
and we can see an event with priority &lt;strong>Warning&lt;/strong> in the Falco ui.&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/openshift/images/falco/falco-cat-etc-shadow.png" alt="/openshift/images/falco/falco-cat-etc-shadow.png" title="/openshift/images/falco/falco-cat-etc-shadow.png" />&lt;/p>
&lt;p>
That&amp;#39;s it, seems like Falco is successfully running on OpenShift 4.12.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>How to force a MachineConfig rollout</title><link>https://blog.stderr.at/openshift/2023/10/how-to-force-a-machineconfig-rollout/</link><pubDate>Wed, 18 Oct 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/10/how-to-force-a-machineconfig-rollout/</guid><description>&lt;p>
While playing around with &lt;a href="https://falco.org/">Falco&lt;/a> (worth another post) I had to force a
MachineConfig update even so the actual configuration of the machine
did not change.&lt;/p>
&lt;p>
This posts documents the steps taken.&lt;/p>
&lt;p>
As this seems to be not clearly documented here it comes&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Get the list of current MachineConfigs&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get mc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME GENERATEDBYCONTROLLER IGNITIONVERSION AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>00-master 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>00-worker 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-master-container-runtime 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-master-kubelet 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-worker-container-runtime 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-worker-kubelet 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-kernel-devel-extensions 25h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-master-generated-registries 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-master-ssh 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-worker-generated-registries 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-worker-ssh 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-master-b8a2011b0b09e36088acf47e225b0ed2 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 5h49m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-master-ce464ff45cc049fce3e8a63e36a4ee9e 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 25h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>We want to force the rollout of a worker node, so remember the name of an old worker config, in our case &lt;code>rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Currently the desiredConfig and the currentConfig should have the same value&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$oc get node node1 -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.metadata.annotations.machineconfiguration\.openshift\.io/desiredConfig}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc get node node1 -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.metadata.annotations.machineconfiguration\.openshift\.io/currentConfig}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Touch a file called 4 touch /run/machine-config-daemon-force&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>oc debug node/node1 -- touch /host/run/machine-config-daemon-force&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>patch the node and set the annotation &lt;code>machineconfiguration.openshift.io/currentConfig&lt;/code> to the &lt;strong>old&lt;/strong> rendered config rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>oc patch node ip-10-0-182-18.eu-central-1.compute.internal --patch &lt;span style="color:#e6db74">&amp;#39;{ &amp;#34;metadata&amp;#34;: { &amp;#34;annotations&amp;#34;: { &amp;#34;machineconfiguration.openshift.io/currentConfig&amp;#34;: &amp;#34;rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3&amp;#34; } } }&amp;#39;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Watch the MachineConfigPool&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get mcp&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;p>Wait for the config rollout to complete.&lt;/p></description></item><item><title>Overview of Red Hat's Multi Cloud Gateway (Noobaa)</title><link>https://blog.stderr.at/openshift/2022/04/overview-of-red-hats-multi-cloud-gateway-noobaa/</link><pubDate>Fri, 22 Apr 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2022/04/overview-of-red-hats-multi-cloud-gateway-noobaa/</guid><description>
&lt;p>
This is my personal summary of experimenting with Red Hat&amp;#39;s Multi
Cloud Gateway (MCG) based on the upstream &lt;a href="https://www.noobaa.io/">Noobaa&lt;/a> project. MCG is part
of Red Hat&amp;#39;s OpenShift Data Foundation (ODF). ODF bundles the upstream
projects &lt;a href="https://ceph.io/en/">Ceph&lt;/a> and &lt;a href="https://noobaa.io">Noobaa&lt;/a>.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Overview
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
Noobaa, or the Multicloud Gateway (MCG), is a S3 based data federation
tool. It allows you to use S3 backends from various sources and&lt;/p>
&lt;ul>
&lt;li>sync&lt;/li>
&lt;li>replicate&lt;/li>
&lt;li>or simply use existing&lt;/li>
&lt;/ul>
&lt;p>S3 buckets. Currently the following sources, or backing stores are supported:&lt;/p>
&lt;ul>
&lt;li>AWS S3&lt;/li>
&lt;li>Azure Blob&lt;/li>
&lt;li>Google Cloud Storage&lt;/li>
&lt;li>
&lt;p>Any other S3 compatible storage, for example&lt;/p>
&lt;ul>
&lt;li>Ceph&lt;/li>
&lt;li>Minio&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Noobaa also supports using a local file system as a backing store for S3.&lt;/p>
&lt;p>
The main purpose is to provide a single API endpoint for applications
using various S3 backends.&lt;/p>
&lt;p>
One of the main features of Noobaa is the storage pipeline. With a
standard Noobaa S3 bucket, when storing a new Object Noobaa executes
the following steps:&lt;/p>
&lt;ul>
&lt;li>Chunking of the Object&lt;/li>
&lt;li>De-duplication&lt;/li>
&lt;li>Compression&lt;/li>
&lt;li>and Encryption&lt;/li>
&lt;/ul>
&lt;p>This means that data stored in public cloud S3 offerings is
automatically encrypted. Noobaa also supports using Hashicorp &lt;a href="https://www.hashicorp.com/products/vault">Vault&lt;/a>
for storing and retrieving encryption keys.&lt;/p>
&lt;p>
If you need to skip the storage pipeline, Noobaa also supports
namespace buckets. For example these type of buckets allow you to
write directly to AWS S3 and retrieve Objects via Noobaa. Or it could
be used to migrate buckets from one cloud provider to another.&lt;/p>
&lt;p>
Noobaa also has support for triggering JavaScript based function when&lt;/p>
&lt;ul>
&lt;li>creating new objects&lt;/li>
&lt;li>reading existing objects&lt;/li>
&lt;li>deleting objects&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-2" class="outline-2">
&lt;h2 id="headline-2">
Setup
&lt;/h2>
&lt;div id="outline-text-headline-2" class="outline-text-2">
&lt;p>
With OpenShift Plus or an OpenShift Data Foundation subscription you
can use the OpenShift Data Foundation Operator.&lt;/p>
&lt;p>
For testing Noobaa we used the standalone installation method
&lt;span style="text-decoration: underline;">without&lt;/span> setting up Ceph storage (see &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.10/html/deploying_openshift_data_foundation_using_amazon_web_services/deploy-standalone-multicloud-object-gateway">here&lt;/a>). OpenShift was running in
AWS for testing.&lt;/p>
&lt;p>
If you would like to use the upstream version you can use the Noobaa
operator (&lt;a href="https://github.com/noobaa/noobaa-operator">https://github.com/noobaa/noobaa-operator&lt;/a>). This is what the
OpenShift Data Foundation (ODF) is using as well.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Command line interface
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
Noobaa also comes with a command line interface &lt;code>noobaa&lt;/code>. It&amp;#39;s
available via an ODF subscription or can be installed separately. See
the noobaa-operator &lt;a href="https://github.com/noobaa/noobaa-operator/blob/master/README.md">readme&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-4" class="outline-2">
&lt;h2 id="headline-4">
Resources
&lt;/h2>
&lt;div id="outline-text-headline-4" class="outline-text-2">
&lt;p>
Before using an S3 object store with Noobaa we need to create so
called &lt;span style="text-decoration: underline;">Resources&lt;/span>. This can be done via the Noobaa user interface or
via the command line. For example the following commands create a new
Resource using an AWS S3 bucket as a backing store&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create an S3 bucket in eu-north-1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aws s3api create-bucket &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-north-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --bucket tosmi-eu-north-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --create-bucket-configuration LocationConstraint&lt;span style="color:#f92672">=&lt;/span>eu-north-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create an S3 bucket in eu-north-1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aws s3api create-bucket &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-west-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --bucket tosmi-eu-west-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --create-bucket-configuration LocationConstraint&lt;span style="color:#f92672">=&lt;/span>eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create Noobaa backing store using the tosmi-eu-north-1 bucket above&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>noobaa backingstore create aws-s3 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-north-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --target-bucket tosmi-eu-north-1 aws-eu-north
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create Noobaa backing store using the tosmi-eu-west-1 bucket above&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>noobaa backingstore create aws-s3 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-west-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --target-bucket tosmi-eu-west-1 aws-eu-west&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Or if we would like to use Azure blob&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create two resource groups for storage&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az group create --location northeurope -g mcg-northeurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create two storage accounts&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account create --name mcgnortheurope -g mcg-northeurope --location northeurope --sku Standard_LRS --kind StorageV2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create containers for storing blobs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage container create --account-name mcgnortheurope -n mcg-northeurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># list storage account keys for noobaa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account list
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account show -g mcg-northeurope -n mcgnortheurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account keys list -g mcg-westeurope -n mcgwesteurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account keys list -g mcg-northeurope -n mcgnortheurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>noobaa backingstore create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> azure-blob azure-northeurope &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --account-key&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;lt;the key&amp;gt;&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --account-name&lt;span style="color:#f92672">=&lt;/span>mcgnortheurope &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --target-blob-container&lt;span style="color:#f92672">=&lt;/span>mcg-northeurope&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Using&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>noobaa backingstore list&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
we are able to confirm that our stores were created successfully.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-2">
&lt;h2 id="headline-5">
Buckets
&lt;/h2>
&lt;div id="outline-text-headline-5" class="outline-text-2">
&lt;p>
After creating the backend stores we are able to create Buckets and define the
layout of backends.&lt;/p>
&lt;p>
There are two ways how to create buckets, either directly via the Noobaa UI,
or using Kubernetes (K8s) objects.&lt;/p>
&lt;p>
We will focus on using K8s objects in this post.&lt;/p>
&lt;div id="outline-container-headline-6" class="outline-3">
&lt;h3 id="headline-6">
Required K8s objects
&lt;/h3>
&lt;div id="outline-text-headline-6" class="outline-text-3">
&lt;p>
The Noobaa operator provides the following Custom Resource Definitions:&lt;/p>
&lt;ul>
&lt;li>&lt;code>BackingStore&lt;/code>: we already created &lt;code>BackingStores&lt;/code> in the Resources
section&lt;/li>
&lt;li>&lt;code>BucketClass&lt;/code>: a bucket class defines the layout of our bucket
(single, mirrored or tiered)&lt;/li>
&lt;li>&lt;code>StorageClass&lt;/code>: a standard K8s &lt;code>StorageClass&lt;/code> referencing the &lt;code>BucketClass&lt;/code>&lt;/li>
&lt;li>&lt;code>ObjectBucketClaim&lt;/code>: A OBC or &lt;code>ObjectBucketClaim&lt;/code> creates the bucket
for us in Noobaa. Additionally the Noobaa operator creates a
&lt;code>ConfigMap&lt;/code> and a &lt;code>Secret&lt;/code> with the same name as the Bucket, storing
access details (&lt;code>ConfigMap&lt;/code>) and credentials (&lt;code>Secret&lt;/code>) for accessing
the bucket.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-7" class="outline-3">
&lt;h3 id="headline-7">
BucketClass
&lt;/h3>
&lt;div id="outline-text-headline-7" class="outline-text-3">
&lt;p>
Let&amp;#39;s create a example &lt;code>BucketClass&lt;/code> which mirrors objects between the
AWS S3 buckets eu-west-1 and eu-north-1.&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">noobaa.io/v1alpha1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">BucketClass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">noobaa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-bucket-class&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">openshift-storage&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">placementPolicy&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tiers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">backingStores&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">aws-eu-north&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">aws-eu-west&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">placement&lt;/span>: &lt;span style="color:#ae81ff">Mirror&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So we are defining a &lt;code>BucketClass&lt;/code> &lt;span style="text-decoration: underline;">aws-mirrored-bucket-class&lt;/span> that
has the following placement policy:&lt;/p>
&lt;ul>
&lt;li>A single tier with one backing store&lt;/li>
&lt;li>
&lt;p>The backing store uses two AWS buckets&lt;/p>
&lt;ul>
&lt;li>aws-eu-north&lt;/li>
&lt;li>aws-eu-west&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>The placement policy is mirror, so all objects uploaded to buckets
using this &lt;code>BucketClass&lt;/code> will be mirrored between &lt;span style="text-decoration: underline;">aws-eu-north&lt;/span> and
&lt;span style="text-decoration: underline;">aws-eu-west&lt;/span>.&lt;/li>
&lt;/ul>
&lt;p>A &lt;code>BucketClass&lt;/code> could have multiple tiers, moving cold data
transparently to a lower tier, but let&amp;#39;s keep this simple.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-8" class="outline-3">
&lt;h3 id="headline-8">
StorageClass
&lt;/h3>
&lt;div id="outline-text-headline-8" class="outline-text-3">
&lt;p>
After creating our &lt;code>BucketClass&lt;/code> we are now able to define a standard
K8s &lt;code>StorageClass&lt;/code>:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">storage.k8s.io/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">StorageClass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">description&lt;/span>: &lt;span style="color:#ae81ff">Provides Mirrored Object Bucket Claims (OBCs) in AWS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-openshift-storage.noobaa.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">parameters&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">bucketclass&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-bucket-class&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">provisioner&lt;/span>: &lt;span style="color:#ae81ff">openshift-storage.noobaa.io/obc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">reclaimPolicy&lt;/span>: &lt;span style="color:#ae81ff">Delete&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">volumeBindingMode&lt;/span>: &lt;span style="color:#ae81ff">Immediate&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
This &lt;code>StorageClass&lt;/code> uses our &lt;code>BucketClass&lt;/code> &lt;span style="text-decoration: underline;">aws-mirrored-bucket-class&lt;/span>
as a backend. All buckets created leveraging this &lt;code>StorageClass&lt;/code> will
mirror data between &lt;span style="text-decoration: underline;">aws-eu-north&lt;/span> and &lt;span style="text-decoration: underline;">aws-eu-west&lt;/span> (see the previous
chapter).&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-9" class="outline-3">
&lt;h3 id="headline-9">
ObjectBucketClaim
&lt;/h3>
&lt;div id="outline-text-headline-9" class="outline-text-3">
&lt;p>
Finally we are able to create &lt;code>ObjectBucketClaims&lt;/code> for projects
requiring object storage. An &lt;code>ObjectBucketClaim&lt;/code> is similar to an
&lt;code>PersistentVolumeClaim&lt;/code>. Every time a claim is created the Noobaa
operator will create a corresponding S3 bucket for us.&lt;/p>
&lt;p>
Let&amp;#39;s start testing this out by creating a new OpenShift project&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>oc new-project obc-test&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Now we define a &lt;code>ObjectBucketClaim&lt;/code> to create a new bucket for our application:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">objectbucket.io/v1alpha1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ObjectBucketClaim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">noobaa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">generateBucketName&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">storageClassName&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-openshift-storage.noobaa.io&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We use the &lt;code>StorageClass&lt;/code> created in the previous step. This will create&lt;/p>
&lt;ul>
&lt;li>a S3 Bucket in the requested &lt;code>StorageClass&lt;/code>&lt;/li>
&lt;li>a &lt;code>ConfigMap&lt;/code> storing access information&lt;/li>
&lt;li>a &lt;code>Secret&lt;/code> storing credentials for accessing the S3 Bucket&lt;/li>
&lt;/ul>
&lt;p>For testing we will upload some data via &lt;a href="https://s3tools.org/s3cmd">&lt;span style="text-decoration: underline;">s3cmd&lt;/span>&lt;/a> and use a pod to monitor
data within the bucket.&lt;/p>
&lt;p>
Let&amp;#39;s do the upload with &lt;span style="text-decoration: underline;">s3cmd&lt;/span>, we need the following config file:&lt;/p>
&lt;div class="src src-ini">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">[default]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">check_ssl_certificate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">check_ssl_hostname&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">access_key&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;lt;access key&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">secret_key&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;lt;secret key&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">host_base&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">s3-openshift-storage.apps.ocp.aws.tntinfra.net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">host_bucket&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">%(bucket).s3-openshift-storage.apps.ocp.aws.tntinfra.net&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Of course you must change &lt;span style="text-decoration: underline;">host-base&lt;/span> according to your cluster
name. It&amp;#39;s a route in the &lt;span style="text-decoration: underline;">openshift-storage&lt;/span> namespace:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>oc get route -n openshift-storage s3 -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.host}&amp;#39;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
You can extract the access and secret key from the
K8s secret via:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>oc extract secret/aws-mirrored-claim --to&lt;span style="color:#f92672">=&lt;/span>-&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Copy the access key and the secret key to the s3 command config file
(we&amp;#39;ve called our config &lt;span style="text-decoration: underline;">noobaa-s3.cfg&lt;/span>). Now we can list all
available buckets via:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ s3cmd ls -c noobaa-s3.cfg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2022-04-22 13:56 s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Now we are going to upload a sample file:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ s3cmd -c noobaa-s3.cfg put simple-aws-mirrored-obc.yaml s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>upload: &lt;span style="color:#e6db74">&amp;#39;simple-aws-mirrored-obc.yaml&amp;#39;&lt;/span> -&amp;gt; &lt;span style="color:#e6db74">&amp;#39;s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4/simple-aws-mirrored-obc.yaml&amp;#39;&lt;/span> &lt;span style="color:#f92672">[&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> of 1&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">226&lt;/span> of &lt;span style="color:#ae81ff">226&lt;/span> 100% in 0s 638.18 B/s &lt;span style="color:#66d9ef">done&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We can also list available files via&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>s3cmd -c noobaa-s3.cfg ls s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2022-04-22 13:57 &lt;span style="color:#ae81ff">226&lt;/span> s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4/simple-aws-mirrored-obc.yaml&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Our we could use a &lt;code>Pod&lt;/code> to list available files from within
OpenShift. Note how we use the &lt;code>ConfigMap&lt;/code> and the &lt;code>Secret&lt;/code> the Noobaa
operater created for us, when we created the &lt;code>ObjectBucketClaim&lt;/code>:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">batch/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Job&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">s3-test-job&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">s3-pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">d3fk/s3cmd:latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">s3-pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_NAME&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMapKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_NAME&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_HOST&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMapKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_HOST&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_PORT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMapKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_PORT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">AWS_ACCESS_KEY_ID&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">secretKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">AWS_ACCESS_KEY_ID&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">AWS_SECRET_ACCESS_KEY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">secretKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">AWS_SECRET_ACCESS_KEY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">command&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/bin/sh&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - -&lt;span style="color:#ae81ff">c&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#39;s3cmd --host $BUCKET_HOST --host-bucket &amp;#34;%(bucket).$BUCKET_HOST&amp;#34; --no-check-certificate ls s3://$BUCKET_NAME&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restartPolicy&lt;/span>: &lt;span style="color:#ae81ff">Never&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
That&amp;#39;s all for now. If time allows we are going to write a follow up blog post on&lt;/p>
&lt;ul>
&lt;li>Replicating Buckets and&lt;/li>
&lt;li>Functions&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Adventures in Java Land: JPA disconnected entities</title><link>https://blog.stderr.at/java/2022-02-25-jpa-disconnected-entity/</link><pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/java/2022-02-25-jpa-disconnected-entity/</guid><description>
&lt;p>
An old man tries to refresh his Java skills and does &lt;a href="https://www.redhat.com/en/services/training/red-hat-cloud-native-microservices-development-quarkus-do378">DO378&lt;/a>. He fails
spectacularly at the first real example but learns a lot on the way.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
The exception
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
There is this basic example where you build a minimal REST API for
storing speaker data in a database. Quarkus makes this quite easy. You
just have to define your database connection properties in
&lt;code>resources/application.properties&lt;/code> and off you go developing your Java
Quarkus REST service:&lt;/p>
&lt;div class="src src-ini">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">quarkus.datasource.db-kind&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">h2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">quarkus.datasource.jdbc.url&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">jdbc:h2:mem:default&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">quarkus.datasource.username&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">admin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">quarkus.hibernate-orm.database.generation&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">drop-and-create&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">quarkus.hibernate-orm.log.sql&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">true&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So next we define our entity class to be stored in the database. I
will skip the import statements and any other code not relevant for
this post.&lt;/p>
&lt;div class="src src-java">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// import statements skipped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@Entity&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Speaker&lt;/span> &lt;span style="color:#66d9ef">extends&lt;/span> PanacheEntity {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> UUID uuid;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> String nameFirst;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> String nameLast;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> String organization;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">@JsonbTransient&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> String biography;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> String picture;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> String twitterHandle;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Constructors, getters and setters, toString and other methods skipped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ....
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We define an entity &lt;code>Speaker&lt;/code> which extends the &lt;a href="https://github.com/quarkusio/quarkus/blob/main/extensions/panache/hibernate-orm-panache/runtime/src/main/java/io/quarkus/hibernate/orm/panache/PanacheEntity.java">&lt;code>PanacheEntity&lt;/code>&lt;/a>
class. &lt;a href="https://quarkus.io/guides/hibernate-orm-panache">Panache&lt;/a> is a thin wrapper around &lt;a href="https://hibernate.org/">Hibernate&lt;/a> providing convince
features. For example the base class &lt;code>PanacheEntity&lt;/code> defines a
autoincrement &lt;code>Id&lt;/code> column for us. This inherited &lt;code>Id&lt;/code> column is of
importance for understanding the problem ahead of us.&lt;/p>
&lt;p>
So next you define your &lt;code>SpeakerService&lt;/code> class which uses the
entity. Once again I will skip the imports and any code not relevant
for understanding the problem:&lt;/p>
&lt;div class="src src-java">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// imports omitted&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@ApplicationScoped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">SpeakerService&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// other code omitted&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> Speaker &lt;span style="color:#a6e22e">create&lt;/span>(Speaker speaker) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> speaker.&lt;span style="color:#a6e22e">persist&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> speaker;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We focus on the &lt;code>create&lt;/code> method here because the call to
&lt;code>speaker.persist()&lt;/code> was the reason for all the headache.&lt;/p>
&lt;p>
But we are still in coding mode and last but not least we define our
&lt;code>SpeakerResource&lt;/code> class, again everything not relevant for
understanding the problem was removed:&lt;/p>
&lt;div class="src src-java">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// import statements omitted&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@Path&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/speaker&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@Produces&lt;/span>(MediaType.&lt;span style="color:#a6e22e">APPLICATION_JSON&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@Consumes&lt;/span>(MediaType.&lt;span style="color:#a6e22e">APPLICATION_JSON&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">SpeakerResource&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">@Inject&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> SpeakerService service;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// other code omitted&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">@POST&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">@Transactional&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> Speaker &lt;span style="color:#a6e22e">create&lt;/span>(Speaker newSpeaker) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service.&lt;span style="color:#a6e22e">create&lt;/span>(newSpeaker);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> newSpeaker;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
The root path for our &lt;code>SpeakerResource&lt;/code> is &lt;span style="text-decoration: underline;">/speaker&lt;/span>. We inject the
&lt;code>SpeakerService&lt;/code> and define a method &lt;code>create()&lt;/code> for creating a &lt;code>Speaker&lt;/code>. We
would like to be able to send &lt;code>@Post&lt;/code> requests to this endpoint and &lt;a href="https://javaee.github.io/jsonb-spec/">Jsonb&lt;/a>
or&lt;a href="https://github.com/FasterXML/jackson"> Jackson,&lt;/a> whichever we currently prefer, will deserialize the JSON
body in a &lt;code>Speaker&lt;/code> object for us.&lt;/p>
&lt;p>
Splendid, time to switch from coding mode to testing.&lt;/p>
&lt;p>
We launch that Quarkus application in developer mode&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>mvn quarkus:dev&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Quarkus is so friendly and provides a swagger-ui in dev mode for testing
our endpoint. Super duper lets call the &lt;code>create()&lt;/code> endpoint via Swagger:&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/java/images/swagger_post_500.png" alt="/java/images/swagger_post_500.png" title="/java/images/swagger_post_500.png" />&lt;/p>
&lt;p>
Because we are lazy we accept the default Swagger provides for us and
just click &lt;span style="text-decoration: underline;">Execute&lt;/span>.&lt;/p>
&lt;p>
BOOM, 500 internal server error. And a beautiful Java exception:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>org.jboss.resteasy.spi.UnhandledException: javax.persistence.PersistenceException: org.hibernate.PersistentObjectException: detached entity passed to persist: org.acme.conference.speaker.Speaker&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
What? Detached entity what does this mean and why?&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-2" class="outline-2">
&lt;h2 id="headline-2">
Enlightenment
&lt;/h2>
&lt;div id="outline-text-headline-2" class="outline-text-2">
&lt;p>
Behind the scenes &lt;a href="https://hibernate.org">Hibernate&lt;/a> uses a so called EntityManager for
managing entities. An Entity can be in the following states when
managed by Hibernate:&lt;/p>
&lt;ul>
&lt;li>NEW: The entity object was just created and is not persisted to the database&lt;/li>
&lt;li>MANAGED: The entity is managed by a running Session and all changes
to the entity will be propagated to the database. After call to
&lt;code>entitymanager.persist()&lt;/code> or in our case &lt;code>newSpeaker.persist()&lt;/code> the
entity is stored in the database and in the &lt;code>managed&lt;/code> state.&lt;/li>
&lt;li>REMOVED: The entity is removed from the database. And finally&lt;/li>
&lt;li>DETACHED: The Entity was detached from the EntityManager, e.g. by
calling &lt;code>entitymanager.detach()&lt;/code> or &lt;code>entitymanager.close()&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>See &lt;a href="https://www.baeldung.com/hibernate-entity-lifecycle">this&lt;/a> blog for a way better explanation what is going on with
entity states.&lt;/p>
&lt;p>
Ok, cool but why the hell is our &lt;code>Speaker&lt;/code> entity in the &lt;span style="text-decoration: underline;">DETACHED&lt;/span>
state? It was just created and never saved to the database before!&lt;/p>
&lt;p>
After checking the database (was empty), I started my Java debugger of
choice (IntellJ, but use whatever fit&amp;#39;s your needs. I&amp;#39;m to old for IDE
vs Editor and Editor vs Editor wars).&lt;/p>
&lt;p>
So looking at the &lt;code>Speaker&lt;/code> entity before calling &lt;code>persist()&lt;/code> revealed the following:&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/java/images/speaker_object_debugger.png" alt="/java/images/speaker_object_debugger.png" title="/java/images/speaker_object_debugger.png" />&lt;/p>
&lt;p>
The &lt;code>Speaker&lt;/code> object passed into &lt;code>create()&lt;/code> has an &lt;span style="text-decoration: underline;">Id&lt;/span> of 0 and all
the internal Hibernate fields are set to null. So this seems to
indicate that this &lt;code>Speaker&lt;/code> object is currently not attached to an
&lt;code>EntityManager&lt;/code> session. This might explain the &lt;strong>DETACHED&lt;/strong> state.&lt;/p>
&lt;p>
I started playing around with &lt;code>EntityManager&lt;/code> and calling &lt;code>merge()&lt;/code> on the
speaker object. The code looked like this:&lt;/p>
&lt;div class="src src-java">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-java" data-lang="java">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@ApplicationScoped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">SpeakerService&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">@Inject&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> EntityManager em;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// lots of code skipped&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">public&lt;/span> Speaker &lt;span style="color:#a6e22e">create&lt;/span>(Speaker speaker) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> newSpeaker &lt;span style="color:#f92672">=&lt;/span> em.&lt;span style="color:#a6e22e">merge&lt;/span>(speaker);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> newSpeaker.&lt;span style="color:#a6e22e">persist&lt;/span>();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> speaker;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Looking at the &lt;code>newSpeaker&lt;/code> object returned by calling &lt;code>entitymanager.merge()&lt;/code>
in the debugger revealed the following:&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/java/images/speaker_object_entitymanager_debugger.png" alt="/java/images/speaker_object_entitymanager_debugger.png" title="/java/images/speaker_object_entitymanager_debugger.png" />&lt;/p>
&lt;p>
&lt;code>newSpeaker&lt;/code> has an Id of 1 (hm, why no 0?) and some those special
Hibernate fields starting with $$ have a value assigned. So for me
this indicates that the object is now managed by an &lt;code>EntityManager&lt;/code>
session and in the &lt;strong>MANAGED&lt;/strong> state.&lt;/p>
&lt;p>
And the &lt;code>Id&lt;/code>, already assigned to the original &lt;code>Speaker&lt;/code> object,
de-serialized form JSON is actually the reason for the beautiful
exception above.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Explanation
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
So after a little bit of internet search magic I found an explanation
for the exception:&lt;/p>
&lt;p>
&lt;div class="admonitionblock important" >&lt;table>&lt;tbody>&lt;tr>&lt;td class="icon">&lt;i class="fa icon-important" title="important">&lt;/i>&lt;/td>&lt;td class="content">&lt;p>
If an &lt;code>Id&lt;/code> is already assigned to an entity object, Hibernate assumes
that this is an entity in the &lt;strong>DETACHED&lt;/strong> state (if the &lt;span style="text-decoration: underline;">Id&lt;/span> is
auto-generated). For an entity to be persisted to the database it has
to be transferred in the &lt;strong>MANAGED&lt;/strong> state by calling
&lt;code>entitymanager.merge()&lt;/code>&lt;/p>
&lt;p>
For more information see the &lt;a href="https://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#pc">Hibernate documentation&lt;/a>.&lt;/p>
&lt;/td>&lt;/tr>&lt;/tbody>&lt;/table>&lt;/div>
&lt;/p>
&lt;p>
We can only call &lt;code>persist()&lt;/code> if the object is in the transient state,
to quote the &lt;a href="https://docs.jboss.org/hibernate/orm/current/userguide/html_single/Hibernate_User_Guide.html#pc">Hibernate documentation&lt;/a>:&lt;/p>
&lt;p>
&lt;span style="text-decoration: underline;">transient&lt;/span>: the entity has just been instantiated and is not associated
with a persistence context. It has no persistent representation in the
database and &lt;strong>typically no identifier value has been assigned (unless
the assigned generator was used)&lt;/strong>.&lt;/p>
&lt;p>
And reading on we also get explanation for the detached state:&lt;/p>
&lt;p>
&lt;span style="text-decoration: underline;">detached&lt;/span>: &lt;strong>the entity has an associated identifier&lt;/strong> but is no longer
associated with a persistence context (usually because the persistence
context was closed or the instance was evicted from the context)&lt;/p>
&lt;p>
Just removing the &lt;code>Id&lt;/code> from the POST request will solve the issue and
the example started to work.&lt;/p>
&lt;p>
This is also why the &lt;code>Id&lt;/code> column is different in the &lt;code>Speaker&lt;/code> object
(deserialized from JSON) and &lt;code>newSpeaker&lt;/code> object (create by calling
&lt;code>entitymanager.merge()&lt;/code>). The &lt;code>Speaker&lt;/code> &lt;span style="text-decoration: underline;">Id&lt;/span> got passed in from JSON,
and has nothing to do with the auto generated primary key &lt;span style="text-decoration: underline;">Id&lt;/span> within
our database. After calling &lt;code>entitymanager.merge()&lt;/code> the entity is
actually associated with a database session and the &lt;span style="text-decoration: underline;">Id&lt;/span> is
auto generated.&lt;/p>
&lt;p>
So maybe this is basic stuff, but it took me quite a few hours to
understand what was going on.&lt;/p>
&lt;p>
Maybe this is also a bad example. Should one expose the &lt;code>Id&lt;/code> if it is
auto generated and only used internally? Or the code just needs to
handle that case… But this needs me more learning about API design.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>Stumbling into Azure Part II: Setting up a private ARO cluster</title><link>https://blog.stderr.at/azure/2021-10-29-private-aro/</link><pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/azure/2021-10-29-private-aro/</guid><description>
&lt;p>
In Part I of our blog post we covered setting up required resources in
Azure. Now we are finally going to set up a private cluster. Private&lt;/p>
&lt;p>
As review from Part I here is our planned setup, this time including
the ARO cluster.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Azure Setup
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
The diagram below depicts our planned setup:&lt;/p>
&lt;p>&lt;img src="https://blog.stderr.at/azure/images/azure_network_setup_with_aro.png" alt="/azure/images/azure_network_setup_with_aro.png" title="/azure/images/azure_network_setup_with_aro.png" />&lt;/p>
&lt;p>
On the right hand side can see the resources required for our lab:&lt;/p>
&lt;ul>
&lt;li>a virtual network (vnet 192.168.128.0/19). This vnet will be split
into 3 separate subnets&lt;/li>
&lt;li>a master subnet (192.168.129.0/24) holding the ARO control plane nodes&lt;/li>
&lt;li>a node subnet (192.168.130.0/24) holding ARO worker nodes&lt;/li>
&lt;li>and finally a subnet call &lt;code>GatewaySubnet&lt;/code> where we are going to
deploy our Azure VPN gateway (called a &lt;code>vnet-gateway&lt;/code>)
&lt;div class="admonitionblock warning" >&lt;table>&lt;tbody>&lt;tr>&lt;td class="icon">&lt;i class="fa icon-warning" title="warning">&lt;/i>&lt;/td>&lt;td class="content">&lt;p>
The subnet where the Azure VPN gateway is located needs to have
the name &lt;code>GatewaySubnet&lt;/code>. Otherwise creating the Azure VPN gateway
will fail.&lt;/p>
&lt;/td>&lt;/tr>&lt;/tbody>&lt;/table>&lt;/div>
&lt;/li>
&lt;li>we also need a &lt;code>publicIP&lt;/code> resource that we are going to connect to
our &lt;code>vnet-gateway&lt;/code> (the VPN gateway)&lt;/li>
&lt;li>and finally a &lt;code>local-gateway&lt;/code> resource that tells the
&lt;code>vnet-gateway&lt;/code> which networks are reachable on the left, in our
case the Hetzner server.&lt;/li>
&lt;/ul>
&lt;div id="outline-container-headline-2" class="outline-3">
&lt;h3 id="headline-2">
Creating the private Azure Red Hat OpenShift cluster
&lt;/h3>
&lt;div id="outline-text-headline-2" class="outline-text-3">
&lt;ol>
&lt;li>
&lt;p>Register required resource providers&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>az provider register -n Microsoft.RedHatOpenShift --wait
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az provider register -n Microsoft.Compute --wait
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az provider register -n Microsoft.Storage --wait
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az provider register -n Microsoft.Authorization --wait&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;ol>
&lt;li>
&lt;p>First we are going to set some environment variable. Those
variables are used in the upcoming commands:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>export RESOURCEGROUP&lt;span style="color:#f92672">=&lt;/span>aro-rg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export CLUSTER&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;aro1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export GATWAY_SUBNET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;192.168.128.0/24&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export MASTER_SUBNET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;192.168.129.0/24&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export WORKER_SUBNET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;192.168.130.0/24&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export HETZNER_VM_NETWORKS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;10.0.0.0/24 192.168.122.0/24 172.16.100.0/24&amp;#34;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Disable subnet private endpoint policies&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vnet subnet update &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name master-subnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet-name aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--disable-private-link-service-network-policies true&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a private DNS zone for our cluster&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network private-dns zone create -n private2.tntinfra.net -g aro-rg&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create the cluster&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az aro create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name $CLUSTER &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--master-subnet master-subnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--worker-subnet worker-subnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--apiserver-visibility Private &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--ingress-visibility Private &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--domain private.tntinfra.net
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># --pull-secret @pull-secret.txt # [OPTIONAL]&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>After successful cluster creating add DNS entry for the API and Ingress&lt;/p>
&lt;p>
Query the Azure API for the API server IP and the ingress IP addresses:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>az aro show -n aro1 -g aro-rg --query &amp;#39;{api:apiserverProfile.ip, ingress:ingressProfiles[0].ip}&amp;#39;&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Example output&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Api Ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>------------- ---------------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>192.168.129.4 192.168.130.254&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Add entries to Azure private DNS&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network private-dns record-set a add-record -g aro-rg -z private.tntinfra.net -a &lt;span style="color:#e6db74">&amp;#34;192.168.129.4&amp;#34;&lt;/span> -n api
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az network private-dns record-set a add-record -g aro-rg -z private.tntinfra.net -a &lt;span style="color:#e6db74">&amp;#34;192.168.130.254&amp;#34;&lt;/span> -n &lt;span style="color:#e6db74">&amp;#34;*.apps&amp;#34;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
List entries to verify configuration&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network private-dns record-set a list -g aro-rg -z private.tntinfra.net&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Output:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>Name ResourceGroup Ttl Type AutoRegistered Metadata
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>------ --------------- ----- ------ ---------------- ----------
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>api aro-rg &lt;span style="color:#ae81ff">3600&lt;/span> A False
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>*.apps aro-rg &lt;span style="color:#ae81ff">3600&lt;/span> A False&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>List cluster credentials after successful setup&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az aro list-credentials &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name $CLUSTER &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Get the console URL&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az aro show &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name $CLUSTER &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--query &lt;span style="color:#e6db74">&amp;#34;consoleProfile.url&amp;#34;&lt;/span> -o tsv&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
DNS, curl
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
this works, dunno why?&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>dig @192.168.129.7 console-openshift-console.apps.xm7rdz4r.westeurope.aroapp.io&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
use &lt;span style="text-decoration: underline;">curl&lt;/span> to access the internal API and see if it works:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>curl -kv https://192.168.129.4:6443&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-4" class="outline-2">
&lt;h2 id="headline-4">
Additional Resources
&lt;/h2>
&lt;div id="outline-text-headline-4" class="outline-text-2">
&lt;ul>
&lt;li>&lt;a href="https://blog.notnot.ninja/2020/09/19/azure-site-to-site-vpn/">Build an Azure site-to-site VPN for DevTest&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-cli">Create a virtual network with a Site-to-Site VPN connection using CLI&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://libreswan.org/wiki/FAQ#Why_is_it_recommended_to_disable_rp_filter_in_.2Fproc.2Fsys.2Fnet_.3F">Libreswan: Disable rp_filter for IPsec&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://libreswan.org/wiki/FAQ#NAT_.2B_IPsec_is_not_working">Libreswan: NAT and IPsec not working&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://libreswan.org/wiki/Subnet_to_subnet_VPN">Libreswan: Subnet to subnet VPN&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div></description></item><item><title>Stumbling into Azure Part I: Building a site-to-site VPN tunnel for testing</title><link>https://blog.stderr.at/azure/2021-10-17-s2s-vpn/</link><pubDate>Sat, 16 Oct 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/azure/2021-10-17-s2s-vpn/</guid><description>
&lt;p>
So we want to play with ARO (Azure Red Hat OpenShift) private
clusters. A private cluster is &lt;strong>not&lt;/strong> reachable from the internet
(surprise) and is only reachable via a VPN tunnel from other networks.&lt;/p>
&lt;p>
This blog post describes how we created a site-to-site VPN between a
Hetzner dedicated server running multiple VM&amp;#39;s via libvirt and Azure.&lt;/p>
&lt;p>
An upcoming blog post is going to cover the setup of the private ARO
cluster.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Azure Setup
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
The diagram below depicts our planned setup:&lt;/p>
&lt;p>&lt;img src="https://blog.stderr.at/azure/images/azure_network_setup.png" alt="/azure/images/azure_network_setup.png" title="/azure/images/azure_network_setup.png" />&lt;/p>
&lt;p>
On the right hand side can see the resources required for our lab:&lt;/p>
&lt;ul>
&lt;li>a virtual network (vnet 192.168.128.0/19). This vnet will be split
into 3 separate subnets&lt;/li>
&lt;li>a master subnet (192.168.129.0/24) holding the ARO control plane nodes&lt;/li>
&lt;li>a node subnet (192.168.130.0/24) holding ARO worker nodes&lt;/li>
&lt;li>and finally a subnet call &lt;code>GatewaySubnet&lt;/code> where we are going to
deploy our Azure VPN gateway (called a &lt;code>vnet-gateway&lt;/code>)
&lt;div class="admonitionblock warning" >&lt;table>&lt;tbody>&lt;tr>&lt;td class="icon">&lt;i class="fa icon-warning" title="warning">&lt;/i>&lt;/td>&lt;td class="content">&lt;p>
The subnet where the Azure VPN gateway is located needs to have
the name &lt;code>GatewaySubnet&lt;/code>. Otherwise creating the Azure VPN gateway
will fail.&lt;/p>
&lt;/td>&lt;/tr>&lt;/tbody>&lt;/table>&lt;/div>
&lt;/li>
&lt;li>we also need a &lt;code>publicIP&lt;/code> resource that we are going to connect to
our &lt;code>vnet-gateway&lt;/code> (the VPN gateway)&lt;/li>
&lt;li>and finally a &lt;code>local-gateway&lt;/code> resource that tells the
&lt;code>vnet-gateway&lt;/code> which networks are reachable on the left, in our
case the Hetzner server.&lt;/li>
&lt;/ul>
&lt;div id="outline-container-headline-2" class="outline-3">
&lt;h3 id="headline-2">
Creating the required Azure resources
&lt;/h3>
&lt;div id="outline-text-headline-2" class="outline-text-3">
&lt;ol>
&lt;li>
&lt;p>First we are going to set some environment variable. Those
variables are used in the upcoming commands:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>export RESOURCEGROUP&lt;span style="color:#f92672">=&lt;/span>aro-rg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export GATWAY_SUBNET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;192.168.128.0/24&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export MASTER_SUBNET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;192.168.129.0/24&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export WORKER_SUBNET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;192.168.130.0/24&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export HETZNER_VM_NETWORKS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;10.0.0.0/24 192.168.122.0/24 172.16.100.0/24&amp;#34;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Next create a VNET resource holding our sub networks:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vnet create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--address-prefixes 192.168.128.0/18&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create the &lt;code>GatewaySubnet&lt;/code> subnet&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vnet subnet create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet-name aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name GatewaySubnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--address-prefixes $GATEWAY_SUBNET&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create the master subnet&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vnet subnet create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet-name aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name master-subnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--address-prefixes $MASTER_SUBNET &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--service-endpoints Microsoft.ContainerRegistry&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create the worker subnet&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vnet subnet create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet-name aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name worker-subnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--address-prefixes $WORKER_SUBNET &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--service-endpoints Microsoft.ContainerRegistry&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a &lt;code>public IP&lt;/code> resource&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network public-ip create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name GatewayIP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--allocation-method Dynamic&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a &lt;code>local-gateway&lt;/code> resource&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network local-gateway create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name playground &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--local-address-prefixes $HETZNER_VM_NETWORKS &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--gateway-ip-address 95.217.42.98&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a &lt;code>vnet-gateway&lt;/code> resource (takes around 30 minutes)&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vnet-gateway create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name vpn-gateway &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--public-ip-address GatewayIP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet aro-vnet &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--gateway-type Vpn &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vpn-type RouteBased &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--sku Basic &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--no-wait&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Define a &lt;code>vpn-connection&lt;/code>&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>az network vpn-connection create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--name VNet1toSite2 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--resource-group $RESOURCEGROUP &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--vnet-gateway1 vpn-gateway &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--local-gateway2 playground &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--location westeurope &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>--shared-key thepassword&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Required iptables (nf tables) hacks for libvirt
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;div id="outline-container-headline-4" class="outline-3">
&lt;h3 id="headline-4">
Skip NAT rules if the destination network is in Azure and the client network deploy via libvirt
&lt;/h3>
&lt;div id="outline-text-headline-4" class="outline-text-3">
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>iptables -I LIBVIRT_PRT &lt;span style="color:#ae81ff">2&lt;/span> -t nat -d 192.168.129.0/24 -j RETURN
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>iptables -I LIBVIRT_PRT &lt;span style="color:#ae81ff">2&lt;/span> -t nat -d 192.168.130.0/24 -j RETURN&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-3">
&lt;h3 id="headline-5">
Skip NAT rules if the destination network is in Azure and the client is connected via tailscale
&lt;/h3>
&lt;div id="outline-text-headline-5" class="outline-text-3">
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>iptables -I ts-postrouting &lt;span style="color:#ae81ff">1&lt;/span> -t nat -d 192.168.129.0/24 -j RETURN
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>iptables -I ts-postrouting &lt;span style="color:#ae81ff">1&lt;/span> -t nat -d 192.168.130.0/24 -j RETURN&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-6" class="outline-2">
&lt;h2 id="headline-6">
Libreswan setup on CentOS Stream
&lt;/h2>
&lt;div id="outline-text-headline-6" class="outline-text-2">
&lt;ol>
&lt;li>
&lt;p>Install the Libreswan packages&lt;/p>
&lt;div class="src src-h">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-h" data-lang="h">&lt;span style="display:flex;">&lt;span>dnf install libreswan&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a Azure configuration for Libreswan in ~/etc/ipsec.d/azure.conf&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>conn masterSubnet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>also=azureTunnel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>leftsubnet=192.168.129.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rightsubnet=172.16.100.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>auto=start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>conn workerSubnet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>also=azureTunnel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>leftsubnet=192.168.130.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rightsubnet=172.16.100.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>auto=start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>conn azureTunnel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>authby=secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>auto=start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dpdaction=restart
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dpddelay=30
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dpdtimeout=120
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ike=aes256-sha1;modp1024
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ikelifetime=3600s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ikev2=insist
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>keyingtries=3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pfs=yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>phase2alg=aes128-sha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>left=51.137.113.44
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>leftsubnets=192.168.128.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>right=%defaultroute
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rightsubnets=172.16.100.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>salifetime=3600s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type=tunnel
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ipsec-interface=yes&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a Libreswan secrets file for Azure in &lt;code>/etc/ipsec.d/azure.secrets&lt;/code>:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>%any %any : PSK &amp;#34;abc123&amp;#34;&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Enable and start the IPsec service&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>systemctl enable --now ipsec&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>We had to explicitly load the IPsec configuration via&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ipsec addconn --config /etc/ipsec.d/azure.conf azureTunnel&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-7" class="outline-2">
&lt;h2 id="headline-7">
Libreswan IPSEC debugging tips
&lt;/h2>
&lt;div id="outline-text-headline-7" class="outline-text-2">
&lt;ul>
&lt;li>
&lt;p>Check the state of the IPsec systemd service&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>systemctl status ipsec&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Check the full log of the IPsec systemd service&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>journalctl -e -u ipsec&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Check the state of the tunnels with the &lt;code>ipsec&lt;/code> command line tool&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ipsec status&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Check for the following lines&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> Total IPsec connections: loaded 5, active &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> State Information: DDoS cookies not required, Accepting new IKE connections
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> IKE SAs: total&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span>, half-open&lt;span style="color:#f92672">(&lt;/span>0&lt;span style="color:#f92672">)&lt;/span>, open&lt;span style="color:#f92672">(&lt;/span>0&lt;span style="color:#f92672">)&lt;/span>, authenticated&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span>, anonymous&lt;span style="color:#f92672">(&lt;/span>0&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> IPsec SAs: total&lt;span style="color:#f92672">(&lt;/span>2&lt;span style="color:#f92672">)&lt;/span>, authenticated&lt;span style="color:#f92672">(&lt;/span>2&lt;span style="color:#f92672">)&lt;/span>, anonymous&lt;span style="color:#f92672">(&lt;/span>0&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> &lt;span style="color:#75715e">#130: &amp;#34;azureTunnel/1x1&amp;#34;:500 STATE_V2_ESTABLISHED_CHILD_SA (IPsec SA established); EVENT_SA_REKEY in 2003s; newest IPSEC; eroute owner; isakmp#131; idle;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> &lt;span style="color:#75715e">#130: &amp;#34;azureTunnel/1x1&amp;#34; esp.56cf4304@51.137.113.44 esp.6f49e8d3@95.217.42.98 tun.0@51.137.113.44 tun.0@95.217.42.98 Traffic: ESPin=0B ESPout=0B! ESPmax=0B&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> &lt;span style="color:#75715e">#129: &amp;#34;masterSubnet/0x0&amp;#34;:500 STATE_V2_ESTABLISHED_CHILD_SA (IPsec SA established); EVENT_SA_REKEY in 1544s; newest IPSEC; eroute owner; isakmp#131; idle;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> &lt;span style="color:#75715e">#129: &amp;#34;masterSubnet/0x0&amp;#34; esp.6e81e8da@51.137.113.44 esp.6f72bbc8@95.217.42.98 tun.0@51.137.113.44 tun.0@95.217.42.98 Traffic: ESPin=0B ESPout=0B! ESPmax=0B&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">000&lt;/span> &lt;span style="color:#75715e">#131: &amp;#34;masterSubnet/0x0&amp;#34;:500 STATE_V2_ESTABLISHED_IKE_SA (established IKE SA); EVENT_SA_REKEY in 2121s; newest ISAKMP; idle;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
IPsec specifies properties of connections via &lt;a href="https://en.wikipedia.org/wiki/IPsec#Security_association">security
associations (SA)&lt;/a>. The parent SA is describes the IKEv2
connections, the child SA is the ESP (encapsulated security
payload) connection.&lt;/p>
&lt;p>
Check IPsec transformation policies&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>ip xfrm policy&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Check the state of IPsec transformation policies&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>ip xfrm state&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Check for dropped packages on the IPsec interface (ipsec1 in our case)&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>ip -s link show dev ipsec1&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-8" class="outline-2">
&lt;h2 id="headline-8">
Additonal Resources
&lt;/h2>
&lt;div id="outline-text-headline-8" class="outline-text-2">
&lt;ul>
&lt;li>&lt;a href="https://blog.notnot.ninja/2020/09/19/azure-site-to-site-vpn/">Build an Azure site-to-site VPN for DevTest&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-howto-site-to-site-resource-manager-cli">Create a virtual network with a Site-to-Site VPN connection using CLI&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://libreswan.org/wiki/FAQ#Why_is_it_recommended_to_disable_rp_filter_in_.2Fproc.2Fsys.2Fnet_.3F">Libreswan: Disable rp_filter for IPsec&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://libreswan.org/wiki/FAQ#NAT_.2B_IPsec_is_not_working">Libreswan: NAT and IPsec not working&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://libreswan.org/wiki/Subnet_to_subnet_VPN">Libreswan: Subnet to subnet VPN&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div></description></item><item><title>Stumbling into Quay: Upgrading from 3.3 to 3.4 with the quay-operator</title><link>https://blog.stderr.at/quay/2021-09-07-quay-upgrade-3.4/</link><pubDate>Sat, 16 Oct 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/quay/2021-09-07-quay-upgrade-3.4/</guid><description>
&lt;p>
We had the task of answering various questions related to upgrading
Red Hat Quay 3.3 to 3.4 and to 3.5 with the help of the quay-operator.&lt;/p>
&lt;p>
Thankfully (sic!) everything changed in regards to the Quay operator
between Quay 3.3 and Quay 3.4.&lt;/p>
&lt;p>
So this is a brain dump of the things to consider.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Operator changes
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
With Quay 3.4 the operator was completely reworked and it basically
changed from opinionated to &lt;strong>very&lt;/strong> opinionated. The upgrade works
quite well but you have to be aware about the following points:&lt;/p>
&lt;ul>
&lt;li>The name of the custom resource changed from &lt;code>QuayEcosystem&lt;/code> to &lt;code>QuayRegistry&lt;/code>&lt;/li>
&lt;li>The &lt;code>configHostname&lt;/code>, used for providing the quay configuration UI, is no longer configurable&lt;/li>
&lt;li>The password for the configuration UI is &lt;strong>always&lt;/strong> regenerated after a configuration re-deployment&lt;/li>
&lt;li>The volume size of the PostgreSQL PVC will change to 50G&lt;/li>
&lt;/ul>
&lt;div class="admonitionblock warning" >&lt;table>&lt;tbody>&lt;tr>&lt;td class="icon">&lt;i class="fa icon-warning" title="warning">&lt;/i>&lt;/td>&lt;td class="content">&lt;p>
In my test cluster I was using a 10G Ceph block device and the
StorageClass did not support volume expansion. So my upgrade stopped
at this point and I had to allow volume expansion in the storage
class.&lt;/p>
&lt;/td>&lt;/tr>&lt;/tbody>&lt;/table>&lt;/div>
&lt;ul>
&lt;li>A horizontal pod autoscaler is also deploy during the upgrade. The
default is to scale automatically to 20 pods, you might reconsider this…&lt;/li>
&lt;li>
&lt;p>With the Quay operator version 3.5 the operator is monitoring all
namespaces for custom resources and needs to be installed in the
openshift-operators namespace, this is how we upgraded Quay to 3.5
including the operator:&lt;/p>
&lt;ul>
&lt;li>change the quay operator channel to 3.5&lt;/li>
&lt;li>trigger an upgrade&lt;/li>
&lt;li>now Quay gets upgraded to version 3.5&lt;/li>
&lt;li>
&lt;p>after the Quay upgrade you need to reinstall the operator:&lt;/p>
&lt;ul>
&lt;li>deinstall the quay operator, Quay is &lt;strong>not&lt;/strong> affected by this&lt;/li>
&lt;li>reinstall the Quay operator (3.5) in all-namespaces&lt;/li>
&lt;li>the re-installation of the operator triggers a quay deployment,
all Quay pods are restarted!&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>You have to manually cleanup old&lt;/p>
&lt;ul>
&lt;li>postgres-config-secrets and&lt;/li>
&lt;li>quay-config-bundle&amp;#39;s&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-2" class="outline-2">
&lt;h2 id="headline-2">
Backup and restore considerations
&lt;/h2>
&lt;div id="outline-text-headline-2" class="outline-text-2">
&lt;p>
Red Hat is working on providing documentation on how to backup and
restore Quay in various scenarios. There&amp;#39;s an open task for this
that provides more information
&lt;a href="https://issues.redhat.com/browse/PROJQUAY-2242">https://issues.redhat.com/browse/PROJQUAY-2242&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>Ansible Tower and downloading collections</title><link>https://blog.stderr.at/ansible/2021/07/ansible-tower-and-downloading-collections/</link><pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/ansible/2021/07/ansible-tower-and-downloading-collections/</guid><description>&lt;div class="paragraph">
&lt;p>Every wondered why Ansible Tower does not start downloading required
collections when you synchronize a project? Here are the stumbling
blocks we discovered so far:&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_wrong_name_for_requirements_yml">Wrong name for requirements.yml&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>When downloading collections Ansible Tower searches for a file
&lt;code>requirements.yml&lt;/code> in the collections directory.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Be careful with the file extension: &lt;code>requirements.yml&lt;/code> has to end with
the extension &lt;code>.yml&lt;/code> and &lt;strong>not&lt;/strong> &lt;code>.yaml&lt;/code>.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_collections_download_is_disabled_in_ansible_tower">Collections download is disabled in Ansible Tower&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Within Ansible Tower there is a setting called &lt;code>ENABLE COLLECTION(S)
DOWNLOAD&lt;/code> under &lt;code>Settings&lt;/code>/&lt;code>Jobs&lt;/code>. This has to be set to true, which
is also the default.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_no_ansible_galaxy_credential_defined_for_the_organization">No Ansible Galaxy credential defined for the organization&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Last but not least an Ansible Galaxy credential needs to be defined
for the organization where the project is defined. With the default
installation of Ansible Tower, when the sample playbooks are installed
there is a credential called &lt;code>Ansible Galaxy&lt;/code> defined. You need to assign
this credential to the organization.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you skip installing the sample playbooks, &lt;strong>no&lt;/strong> &lt;code>Ansible Galaxy&lt;/code>
credential will be defined for you and you have to create it manually.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_how_does_this_actually_work">How does this actually work?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Ansible Tower uses a Python virtual environment for running
Ansible. The default environment is installed in
&lt;code>/var/lib/awx/venv/awx&lt;/code>. You can also create custom environments, see
&lt;a href="https://docs.ansible.com/ansible-tower/latest/html/upgrade-migration-guide/virtualenv.html">Using virtualenv with Ansible Tower&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In the default setup the following files define how collections are downloaded:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;code>lib/python3.6/site-packages/awx/main/tasks.py&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>lib/python3.6/site-packages/awx/playbooks/project_update.yml&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_task_py">task.py&lt;/h3>
&lt;div class="paragraph">
&lt;p>&lt;code>task.py&lt;/code> defines various internal tasks Tower has to run on various
occasions. For example in line number 1930 (Ansible Tower 3.8.3) the
task &lt;code>RunProjectUpdate&lt;/code> gets defined. This is the task Tower
has to run whenever a project update is required.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our case the function &lt;code>build_extra_vars_file&lt;/code> (line 2083 with
Ansible Tower 3.8.3) defines the variable &lt;code>galaxy_creds_are_defined&lt;/code>
only if the organization has a galaxy credential defined (line 2099
Ansible Tower 3.8.3).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Line 2120 (Ansible Tower 3.8.3) finally defines the Ansible extra
variable &lt;code>collections_enabled&lt;/code> depending on
&lt;code>galaxy_creds_are_defined&lt;/code>.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_project_update_yml">project_update.yml&lt;/h3>
&lt;div class="paragraph">
&lt;p>So &lt;code>task.py&lt;/code> defines the extra variable &lt;code>collections_enabled&lt;/code> (see
above). Finally the playbook &lt;code>project_update.yml&lt;/code> consumes this extra
variable and only downloads collections if &lt;code>collections_enabled&lt;/code> is
set to &lt;code>true&lt;/code>, see the block string at line 192 (Ansible Tower 3.8.3)
in `project_update.yml.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So long and thanks for all the fish!&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Understanding RWO block device handling in OpenShift</title><link>https://blog.stderr.at/openshift/2021/02/understanding-rwo-block-device-handling-in-openshift/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021/02/understanding-rwo-block-device-handling-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>In this blog post we would like to explore OpenShift / Kubernetes
block device handling. We try to answer the following questions:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>What happens if multiple pods try to access the same block device?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What happens if we scale a deployment using block devices to more than one replica?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And finally we want to give a short, high level overview about how the
container storage interface (CSI) actually works.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
A block device provides Read-Write-Once (RWO) storage. This
basically means a local file system mounted by a single node. Do not
confuse this with a cluster (CephFS, GlusterFS) or network file system
(NFS). These file systems provide Read-Write-Many (RWX) storage
mountable on more than one node.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_test_setup">Test setup&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>For running our tests we need the following resources&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A new namespace/project for running our tests&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A persistent volume claim (PVC) to be mounted in our test pods&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Two pods definitions for mounting the PVC&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_step_1_creating_a_new_namespaceproject">Step 1: Creating a new namespace/project&lt;/h3>
&lt;div class="paragraph">
&lt;p>To run our test cases we created a new project with OpenShift&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc new-project blockdevices&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_step_2_defining_a_block_pvc">Step 2: Defining a block PVC&lt;/h3>
&lt;div class="paragraph">
&lt;p>Our cluster is running the rook operator (&lt;a href="https://rook.io" class="bare">https://rook.io&lt;/a>) and provides a ceph-block
storage class for creating block devices:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get sc
NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE
ceph-block rook-ceph.rbd.csi.ceph.com Delete Immediate false 4d14h&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s take a look a the details of the storage class:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">$ oc get sc -o yaml ceph-block
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
name: ceph-block
parameters:
clusterID: rook-ceph
csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
csi.storage.k8s.io/fstype: ext4 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
imageFeatures: layering
imageFormat: &amp;#34;2&amp;#34;
pool: blockpool
provisioner: rook-ceph.rbd.csi.ceph.com
reclaimPolicy: Delete
volumeBindingMode: Immediate&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>So whenever we create a PVC using this storage class the Ceph
provisioner will also create an EXT4 file system on the block device.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To test block device handling we create the following persistent volume claim (PVC):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: block-claim
spec:
accessModes:
- ReadWriteOnce &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
resources:
requests:
storage: 1Gi
storageClassName: ceph-block&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The access mode is set to ReadWriteOnce (RWO), as block devices&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc create -f pvc.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get pvc
NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE
block-claim Bound pvc-bd68be5d-c312-4c31-86a8-63a0c22de844 1Gi RWO ceph-block 91s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To test our shiny new block device we are going to use the following three pod definitions:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="title">block-pod-a&lt;/div>
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
labels:
run: block-pod-a
name: block-pod-a
spec:
containers:
- image: registry.redhat.io/ubi8/ubi:8.3
name: block-pod-a
command:
- sh
- -c
- &amp;#39;df -h /block &amp;amp;&amp;amp; findmnt /block &amp;amp;&amp;amp; sleep infinity&amp;#39;
volumeMounts:
- name: blockdevice
mountPath: /block
volumes:
- name: blockdevice
persistentVolumeClaim:
claimName: block-claim&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="title">block-pod-b&lt;/div>
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
labels:
run: block-pod-b
name: block-pod-b
spec:
affinity:
podAntiAffinity: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
requiredDuringSchedulingIgnoredDuringExecution:
- labelSelector:
matchExpressions:
- key: run
operator: In
values:
- block-pod-a
topologyKey: kubernetes.io/hostname
containers:
- image: registry.redhat.io/ubi8/ubi:8.3
name: block-pod-b
command:
- sh
- -c
- &amp;#39;df -h /block &amp;amp;&amp;amp; findmnt /block &amp;amp;&amp;amp; sleep infinity&amp;#39;
volumeMounts:
- name: blockdevice
mountPath: /block
volumes:
- name: blockdevice
persistentVolumeClaim:
claimName: block-claim&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We use an &lt;em>AntiAffinity&lt;/em> rule for making sure that &lt;em>block-pod-b&lt;/em> runs
on a &lt;strong>different&lt;/strong> node than &lt;em>block-pod-a&lt;/em>.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="title">block-pod-c&lt;/div>
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
labels:
run: block-pod-c
name: block-pod-c
spec:
affinity:
podAffinity: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
preferredDuringSchedulingIgnoredDuringExecution:
- weight: 100
podAffinityTerm:
labelSelector:
matchExpressions:
- key: run
operator: In
values:
- block-pod-a
topologyKey: kubernetes.io/hostname
containers:
- image: registry.redhat.io/ubi8/ubi:8.3
name: block-pod-c
command:
- sh
- -c
- &amp;#39;df -h /block &amp;amp;&amp;amp; findmnt /block &amp;amp;&amp;amp; sleep infinity&amp;#39;
volumeMounts:
- name: blockdevice
mountPath: /block
volumes:
- name: blockdevice
persistentVolumeClaim:
claimName: block-claim&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We use an &lt;em>Affinity&lt;/em> rule for making sure that &lt;em>block-pod-c&lt;/em> runs
on the &lt;strong>same&lt;/strong> node as &lt;em>block-pod-a&lt;/em>.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our first test we want to make sure that both pods are running on
separate cluster nodes. So we create &lt;em>block-pod-a&lt;/em> and &lt;em>block-pod-b&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc create -f block-pod-a.yml
$ oc create -f block-pod-b.yml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After a few seconds we can check the state of our pods:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get pods -o wide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
block-pod-a 1/1 Running 0 46s 10.130.6.4 infra02.lan.stderr.at &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
block-pod-b 0/1 ContainerCreating 0 16s &amp;lt;none&amp;gt; infra01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Hm, block-pod-b is in the state &lt;em>ContainerCreating&lt;/em>, let’s check the
events. Also note that it is running on another node (infra01) then
&lt;em>block-pod-a&lt;/em> (infra02).&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">10s Warning FailedAttachVolume pod/block-pod-b Multi-Attach error for volume &amp;#34;pvc-bd68be5d-c312-4c31-86a8-63a0c22de844&amp;#34; Volume is already used by pod(s) block-pod-a&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Ah, so because of our block device with RWO access mode and
&lt;em>block-pod-b&lt;/em> running on separate cluster node, OpenShift or K8s can’t
attach the volume to our &lt;em>block-pod-b&lt;/em>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>But let’s try another test and let’s create a third pod &lt;em>block-pod-c&lt;/em>
that should run on the same node as &lt;em>block-pod-a&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc create -f block-pod-c.yml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now let’s check the status of &lt;em>block-pod-c&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get pods -o wide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
block-pod-a 1/1 Running 0 6m49s 10.130.6.4 infra02.lan.stderr.at &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
block-pod-b 0/1 ContainerCreating 0 6m19s &amp;lt;none&amp;gt; infra01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
block-pod-c 1/1 Running 0 14s 10.130.6.5 infra02.lan.stderr.at &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Oh, &lt;em>block-pod-c&lt;/em> is running on node &lt;em>infra02&lt;/em> and mounted the RWO volume. Let’s check the events for &lt;em>block-pod-c&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">3m6s Normal Scheduled pod/block-pod-c Successfully assigned blockdevices/block-pod-c to infra02.lan.stderr.at
2m54s Normal AddedInterface pod/block-pod-c Add eth0 [10.130.6.5/23]
2m54s Normal Pulled pod/block-pod-c Container image &amp;#34;registry.redhat.io/ubi8/ubi:8.3&amp;#34; already present on machine
2m54s Normal Created pod/block-pod-c Created container block-pod-c
2m54s Normal Started pod/block-pod-c Started container block-pod-c&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we compare this with the events for &lt;em>block-pod-a&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">9m41s Normal Scheduled pod/block-pod-a Successfully assigned blockdevices/block-pod-a to infra02.lan.stderr.at
9m41s Normal SuccessfulAttachVolume pod/block-pod-a AttachVolume.Attach succeeded for volume &amp;#34;pvc-bd68be5d-c312-4c31-86a8-63a0c22de844&amp;#34;
9m34s Normal AddedInterface pod/block-pod-a Add eth0 [10.130.6.4/23]
9m34s Normal Pulled pod/block-pod-a Container image &amp;#34;registry.access.redhat.com/ubi8/ubi:8.3&amp;#34; already present on machine
9m34s Normal Created pod/block-pod-a Created container block-pod-a
9m34s Normal Started pod/block-pod-a Started container block-pod-a&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So the &lt;em>AttachVolume.Attach&lt;/em> message is missing in the events for
&lt;em>block-pod-c&lt;/em>. Because the volume is already attached to the node,
interesting.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Even with RWO block device volumes it is possible to use the
same volume in multiple pods &lt;strong>if&lt;/strong> the pods a running on the &lt;strong>same&lt;/strong> node.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I was not aware of this possibility and always had the believe with an
RWO block device only one pod can access the volume. That’s the
problem with believing :-)&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Thanks or reading this far.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Basic usage of git</title><link>https://blog.stderr.at/general/2020/05/basic-usage-of-git/</link><pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/general/2020/05/basic-usage-of-git/</guid><description>&lt;div class="paragraph">
&lt;p>This is a very short and hopefully simple introduction on how to use
&lt;a href="https://git-scm.com/">Git&lt;/a> when you would like to contribute to
projects hosted on &lt;a href="http://github.com">github.com&lt;/a>. The same workflow should also work for
projects on &lt;a href="http://gitlab.com">gitlab.com&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_introduction">Introduction&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>There is this fancy mega application hosted on github called
&lt;a href="https://github.com/rhatservices/megaapp">megaapp&lt;/a> that you would like
to contribute to. It’s perfect but there’s just this little feature
missing to make it even more perfect.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is how we would tackle this.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
rocket science ahead
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_glossary">Glossary&lt;/h2>
&lt;div class="sectionbody">
&lt;table class="tableblock frame-all grid-all stretch">
&lt;colgroup>
&lt;col style="width: 27.2727%;"/>
&lt;col style="width: 72.7273%;"/>
&lt;/colgroup>
&lt;thead>
&lt;tr>
&lt;th class="tableblock halign-left valign-top">Term&lt;/th>
&lt;th class="tableblock halign-left valign-top">Definition&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">fork&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">A (personal) copy of a repository you created on github or gitlab.&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">upstream&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">When creating forks of repositories on github or gitlab, the original repository hosting the project&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">index&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">The staging area git uses before you can commit to a repository&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">remote repository&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">A repository hosted on a server shared by developers&lt;/p>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">local repository&lt;/p>&lt;/td>
&lt;td class="tableblock halign-left valign-top">&lt;p class="tableblock">A local copy of a repository stored on you machine.&lt;/p>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_1_fork_the_repository_on_github_com">Step 1: Fork the repository on github.com&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Login to you Github account and navigate to the project you would like
to fork, &lt;a href="https://github.com/rhatservices/megaapp">megaapp&lt;/a> in our
example.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Click on the the fork button, as depicted in the image below:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/general/images/fork.png" alt="fork"/>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you are a member of several projects on github.com, github is going
to ask you into which project you would like to clone this repository.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After selecting the project or your personal account, github is going
to clone the repository into the project you selected. For this
example I’m going to use my personal github account &amp;#34;tosmi&amp;#34;.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_2_clone_the_repository_to_you_workstation">Step 2: Clone the repository to you workstation&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Next we are going to clone our fork from &lt;a href="#_step_1_fork_the_repository_on_github_com">Step 1: Fork the repository on github.com&lt;/a> to our workstation and start working on the new
feature.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After forking the upstream project you are redirect to your personal
copy of the project. Click on the &amp;#34;Clone or download&amp;#34; button and
select the link. You can choose between SSH and HTTPS protocols for
downloading the project. We are going to use SSH.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/general/images/clone.png" alt="clone"/>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Copy the link into a terminal and execute the &lt;em>git clone&lt;/em> command:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git clone git@github.com:tosmi/megaapp.git&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_3_create_a_feature_branch_for_your_new_fancy_feature">Step 3: Create a feature branch for your new fancy feature&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Change into the directory of the project you downloaded in &lt;a href="#_step_2_clone_the_repository_to_you_workstation">Step 2: Clone the repository to you workstation&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">cd megaapp&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now we create a feature branch with a short name that describes our new feature:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">git checkout -b tosmi/addoption&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Because we would like to add a new option to &lt;em>megaapp&lt;/em> we call this feature branch &lt;em>addoption&lt;/em>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We are also prefixing the feature branch with our github username so that
it is clear for the upstream project maintainer(s) who is contributing this.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>How you name you branches is opinionated, so we would search for
upstream project guidelines and if there are none maybe look at some
existing pull request how other people are naming there branches. If we
find no clue upstream we sticking with &lt;em>&amp;lt;github username&amp;gt;/&amp;lt;branch
name&amp;gt;&lt;/em>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We can now start adding our mega feature to the project.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_4_add_you_changes_to_the_git_index">Step 4: Add you changes to the Git index&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before we can commit our changes, we have to place the changes made in
the so called &lt;em>index&lt;/em> or staging area:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git add &amp;lt;path to file you have changed&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If we would like to place all of our changes onto the index we could execute&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git add -A&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_5_commit_your_changes">Step 5: Commit your changes&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>After adding our changes to the Git index we can commit with&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git commit&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will open our favorite editor and we can type a commit
message. The first line should be a short description of our change,
probably not longer than 70 to 80 characters. After two newlines we
can enter a detailed explanation of your changes.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is an example commit message&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Added a `version` option to output the current version of megaapp
This change introduces a `version` option to megaapp. The purpose is
to output the current version of megaapp for users. This might be
helpful when users open a bug report so we can see what version is
affected.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After saving the message and we have successfully created a commit.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Remember this is now only stored in the local copy of the
repository! We still have to push our changes to github.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There is also the option to add the commit comment directly on the command line&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git commit -m &amp;#39;Added a `version` option to output the current version of megaapp
This change introduces a `version` option to megaapp. The purpose is
to output the current version of megaapp for users. This might be
helpful when users open a bug report so we can see what version is
affected.&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_6_pushing_our_local_changes_to_our_forked_repo_on_github_com">Step 6: Pushing our local changes to our forked repo on github.com&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>We execute&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git push&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>to push our local changes to the forked repository hosted on github.com.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_step_7_creating_a_pull_request_on_github_com">Step 7: Creating a pull request on github.com&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>We navigate to our personal project page of the forked repository on
github. For the fork we are using in this example this is
&lt;a href="http://github.com/tosmi/megaapp" class="bare">http://github.com/tosmi/megaapp&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Github is going to show us a button &amp;#34;Compare &amp;amp; pull request&amp;#34;:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/general/images/pull_request.png" alt="pull request"/>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After clicking on that button we are able to review the changes we
would like to include in this pull request.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If we are happy with our changes we click on &amp;#34;Create pull
request&amp;#34;. The upstream owner of the repository will get notified and
we can see our open pull request on the upstream project page under
&amp;#34;Pull requests&amp;#34;.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If there are CI test configured for that project they will start to
run and we can see if our pull request is going to pass all test
configured.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_rebasing_to_current_upstream_if_required">Rebasing to current upstream if required&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Sometimes a upstream project maintainer asks you to rebase your work
on the current upstream master branch. The following steps explain the
basic workflow.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First we are going to create a new remote location of our repository
called &lt;em>upstream&lt;/em>. &lt;em>Upstream&lt;/em> points to the upstream project
repository. We will not push to this location, in most cases this is
not possible because you do not have write access to a remote upstream
repository. It is just used for pulling upstream changes in our forked
repository.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Execute the following commands to add the upstream repository as a new
remote location and display all remote locations currently defined.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git remote add upstream https://github.com/rhatservices/megaapp.git
$ git remote -v origin
git@github.com:tosmi/megaapp.git (fetch) origin
git@github.com:tosmi/megaapp.git (push) upstream
https://github.com/rhatservices/megaapp.git (fetch) upstream
https://github.com/rhatservices/megaapp.git (push)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As we hopefully implemented our new feature in feature branch, we can
pull changes from the upstream master branch into our local copy of
the master branch. Remember we are using a feature branch and master
should be kept clean from local changes.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git checkout master
Switched to branch &amp;#39;master&amp;#39;
Your branch is up to date with &amp;#39;origin/master&amp;#39;.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So now we have this older copy of the upstream master branch checked
out and we would like to update it to the latest and greatest from the
upstream master branch.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git pull upstream master
remote: Enumerating objects: 10, done.
remote: Counting objects: 100% (10/10), done.
remote: Compressing objects: 100% (3/3), done.
remote: Total 6 (delta 2), reused 6 (delta 2), pack-reused 0
Unpacking objects: 100% (6/6), 630 bytes | 157.00 KiB/s, done.
From https://github.com/rhatservices/megaapp
* branch master -&amp;gt; FETCH_HEAD
* [new branch] master -&amp;gt; upstream/master
Updating 4d8584e..ddfd077
Fast-forward
cmd/megaapp/main.go | 2 ++
cmd/megaapp/rule.go | 20 ++++++++++++++++++++
2 files changed, 22 insertions(+)
create mode 100644 cmd/megaapp/rule.go&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the pull command above you pulled all changes from the upstream
master branch into you local copy of master. Just to be sure let’s
display all available branches, local and remote ones.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Branches with a name &lt;em>remote/&amp;lt;remote name&amp;gt;/&amp;lt;branch name&amp;gt;&lt;/em> are remote
branches that git knows about. &lt;em>Origin&lt;/em> points to our forked
repository and is also the default location for push operations.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git branch -a
master
* tosmi/megafeature
remotes/origin/HEAD -&amp;gt; origin/master
remotes/origin/master
remotes/origin/tosmi/megafeature
remotes/upstream/master&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So finally to &lt;strong>rebase&lt;/strong> our feature branch to the upstream master
branch we first need to checkout our feature branch via&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git checkout tosmi/megafeature&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now we are able to rebase our changes to upstream master. Git
basically pulls in all changes from the master branch and re-applies
the changes we did in our feature branch.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">git rebase upstream/master
Successfully rebased and updated refs/heads/tosmi/megafeature.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There might be merge conflicts when git tries to apply you changes
from your feature branch. You have to fix those changes, &lt;em>git add&lt;/em> the
fixed files and execute &lt;em>git rebase continue&lt;/em>. Luckily this is not the
case for your megafeature.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As we have successfully rebased our feature branch to upstream master
we can now try to push changes made to our forked github repository.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git push
To github.com:tosmi/megaapp.git
! [rejected] tosmi/megafeature -&amp;gt; tosmi/megafeature (non-fast-forward)
error: failed to push some refs to &amp;#39;git@github.com:tosmi/megaapp.git&amp;#39;
hint: Updates were rejected because the tip of your current branch is behind
hint: its remote counterpart. Integrate the remote changes (e.g.
hint: &amp;#39;git pull ...&amp;#39;) before pushing again.
hint: See the &amp;#39;Note about fast-forwards&amp;#39; in &amp;#39;git push --help&amp;#39; for details.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Oh, this fails of course! The reason is that our local feature branch
and the remote feature branch have a different commit history. The
remote feature branch is missing the commits from master that we
applied when rebasing on the current master branch.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s try again, this time using the &lt;em>--force-with-lease&lt;/em>
option. You could also use &lt;em>-f&lt;/em> or &lt;em>--force&lt;/em> but &lt;em>--force-with-lease&lt;/em>
will stop you if someone else (our you) has modified the remote feature
branch meanwhile. If you push with &lt;em>-f&lt;/em> or &lt;em>--force&lt;/em> anyways you might loose changes.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git push --force-with-lease
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 8 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 295 bytes | 295.00 KiB/s, done.
Total 3 (delta 2), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (2/2), completed with 2 local objects.
To github.com:tosmi/megaapp.git
+ acf66a3...39357b2 tosmi/megafeature -&amp;gt; tosmi/megafeature (forced update)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>But as no one modified the remote feature branch while we did our
rebase the force push goes through.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Our merge request (if we opened one already) is now updated to the
latest upstream master branch and merging our feature should be a
breeze. You might notify the upstream project maintainer that you
feature branch is up to date and ready for merging&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_using_gits_interactive_rebase_to_change_you_commit_history">Using git’s interactive rebase to change you commit history&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>When working with upstream projects it might be that a project
maintainer requests that you rework your git history before he is
willing to merge your changes. For example this could be that case if
you have plenty of commits with very small changes (e.g. fixed typos).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The general rule is that one commit should implement one change. This
is not a hard rule, but usually works.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s look at an example. For the implementation of our new feature
that we would like to bring upstream we have the following commit history&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git log --oneline
0a5221d (HEAD -&amp;gt; tosmi/megafeature) fixed typo
0e60d12 update README
bf2ef3c update&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We have updated README.md in the repository but there a three commits
for this little change. Before bringing this upstream in our pull
request, we would like to convert those three commits into a single
one and also make the commit message a little more meaningful.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We execute the following command to start reworking our commit history&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git rebase -i&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Git will drop us into our beloved editor (vi in this case), under
Linux you could change the editor git uses by modifying the $EDITOR
environment variable. We are going to see the following output:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">pick bf2ef3c update
pick 0e60d12 update README
pick 0a5221d fixed typo
# Rebase 39357b2..0a5221d onto 39357b2 (3 commands)
#
# Commands:
# p, pick &amp;lt;commit&amp;gt; = use commit
# r, reword &amp;lt;commit&amp;gt; = use commit, but edit the commit message
# e, edit &amp;lt;commit&amp;gt; = use commit, but stop for amending
# s, squash &amp;lt;commit&amp;gt; = use commit, but meld into previous commit
# f, fixup &amp;lt;commit&amp;gt; = like &amp;#34;squash&amp;#34;, but discard this commit&amp;#39;s log message
# x, exec &amp;lt;command&amp;gt; = run command (the rest of the line) using shell
# b, break = stop here (continue rebase later with &amp;#39;git rebase --continue&amp;#39;)
# d, drop &amp;lt;commit&amp;gt; = remove commit
# l, label &amp;lt;label&amp;gt; = label current HEAD with a name
# t, reset &amp;lt;label&amp;gt; = reset HEAD to a label
# m, merge [-C &amp;lt;commit&amp;gt; | -c &amp;lt;commit&amp;gt;] &amp;lt;label&amp;gt; [# &amp;lt;oneline&amp;gt;]
# . create a merge commit using the original merge commit&amp;#39;s
# . message (or the oneline, if no original merge commit was
# . specified). Use -c &amp;lt;commit&amp;gt; to reword the commit message.
#
# These lines can be re-ordered; they are executed from top to bottom.
#
# If you remove a line here THAT COMMIT WILL BE LOST.
#
# However, if you remove everything, the rebase will be aborted.
#&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Git automatically selected commit id bf2ef3c as the basis for our
rebase. We could also have specified the commit id where we would like
to start our rebase operation e.g.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">git rebase -i bf2ef3c&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our editor of choice we can now tell git what it should do with the selected commits.
Please go ahead and read the helpfull explanation text in comments (prefixed with &amp;#39;#&amp;#39;)
to get a better understanding of the operations supported.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our case we would like to &lt;em>squash&lt;/em> the last commits. So we change the lines with &lt;em>pick&lt;/em> to
&lt;em>squash&lt;/em> until it looks like the following:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">pick bf2ef3c update
squash 0e60d12 update README
squash 0a5221d fixed typo&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We would like to squash commits 0a5221d and 0e60d12 onto commit
bf2ef3c. Keep in mind that git actually reverses the order of
commits. So 0a5221d is the last commit we added.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If we save the file and quit our editor (I’m using vi here), git drops us into
another buffer where we can finally modify the commits&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"> This is a combination of 3 commits.
# This is the 1st commit message:
update
# This is the commit message #2:
update README
# This is the commit message #3:
fixed typo
# Please enter the commit message for your changes. Lines starting
# with &amp;#39;#&amp;#39; will be ignored, and an empty message aborts the commit.
#
# Date: Mon May 18 15:46:37 2020 +0200
#
# interactive rebase in progress; onto 39357b2
# Last commands done (3 commands done):
# squash 0e60d12 update README
# squash 0a5221d fixed typo
# No commands remaining.
# You are currently rebasing branch &amp;#39;tosmi/megafeature&amp;#39; on &amp;#39;39357b2&amp;#39;.
#
# Changes to be committed:
# modified: README.md
#&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We can see all three commit message and we are going to modify those messages until we are happy&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># This is a combination of 3 commits.
# This is the 1st commit message:
updated README.md to megafeature
as we added megafeature, it makes sense to include a short note about it also in README.md
# Please enter the commit message for your changes. Lines starting
# with &amp;#39;#&amp;#39; will be ignored, and an empty message aborts the commit.
#
# Date: Mon May 18 15:46:37 2020 +0200
#
# interactive rebase in progress; onto 39357b2
# Last commands done (3 commands done):
# squash 0e60d12 update README
# squash 0a5221d fixed typo
# No commands remaining.
# You are currently rebasing branch &amp;#39;tosmi/megafeature&amp;#39; on &amp;#39;39357b2&amp;#39;.
#
# Changes to be committed:
# modified: README.md
#&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we are happy with new commit message we just save and quit our
editor. Git will now rewirte the history and when we take look at the
commit history again we will see our changes:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ git log --oneline
91d1ae2 (HEAD -&amp;gt; tosmi/megafeature) updated README.md to megafeature
39357b2 (origin/tosmi/megafeature) added a mega feature
ddfd077 (upstream/master, master) added rule command
4d8584e (origin/master, origin/HEAD) Update README.md
eb6ccbc Create README.md
60fcabc start using cobra for argument parsing
5140ed0 import .gitignore
d2b55d1 import a simple Makefile
2ecb412 initial import&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We only have commit 91d1ae2 now , which includes all three changes from
the commits before.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
Rewriting the history of a repository is a dangerous
operation. Especially when you are working in a team. It is not
advised to change the history of commits that got already pushed to a
remote location. Otherwise your teammates will get confused next time
they try to push or pull from the shared repository.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So it’s OK to change the commit history of a feature branch that only
you are using, but be careful when working on branches more than one
developer is using.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Red Hat Satellite Cheat Sheet</title><link>https://blog.stderr.at/general/2020/04/red-hat-satellite-cheat-sheet/</link><pubDate>Wed, 15 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/general/2020/04/red-hat-satellite-cheat-sheet/</guid><description>&lt;div class="paragraph">
&lt;p>Cheat sheet for various Red Hat Satellite tasks from a newbie to a newbie.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_requirements">Requirements&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>up to Satellite 6.7 RHEL 7.X&lt;/p>
&lt;/li>
&lt;li>
&lt;p>4 CPU Cores&lt;/p>
&lt;/li>
&lt;li>
&lt;p>20 GB of RAM&lt;/p>
&lt;/li>
&lt;li>
&lt;p>300 GB disk space&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>for more info see the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_satellite/6.6/html/installing_satellite_server_from_a_connected_network/preparing_your_environment_for_installation#storage_requirements">prerequistes guide&lt;/a>&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installation">Installation&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Satellite up to version 6.7 uses puppet for installation. You can use&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">puppet filebucket&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>to restore files modified by puppet.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Satellite requires the &lt;em>Red Hat Satellite Infrastructure Subscription&lt;/em>, check if it’s available with&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">subscription-manager list --all --available --matches &amp;#39;Red Hat Satellite Infrastructure Subscription&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If not attach it with&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">subscription-manager attach --pool=pool_id&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next disable all repos and enable only supported repostories via&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">subscription-manager repos --disable &amp;#34;*&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>and enable required repositories&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">subscription-manager repos --enable=rhel-7-server-rpms \
--enable=rhel-7-server-satellite-6.6-rpms \
--enable=rhel-7-server-satellite-maintenance-6-rpms \
--enable=rhel-server-rhscl-7-rpms \
--enable=rhel-7-server-ansible-2.8-rpms&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>then clean cached all repo data via&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"> yum clean all&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>and install satellite packages via&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">yum install satellite&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Install satellite with&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-installer --scenario satellite \
--foreman-initial-organization &amp;#34;initial_organization_name&amp;#34; \
--foreman-initial-location &amp;#34;initial_location_name&amp;#34; \
--foreman-initial-admin-username admin_user_name \
--foreman-initial-admin-password admin_password&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_backup_restore_cloning">Backup / Restore / Cloning&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Use &lt;code>satellite-maintain&lt;/code> for doing offline and online backups&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-maintain backup offline /backup/&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>when using the &lt;em>online&lt;/em> option make sure that no new content view or
content view versions should be created while the backup is
running. basically satellite should be idle.&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_cloning_satellite">Cloning Satellite&lt;/h3>
&lt;div class="paragraph">
&lt;p>The online/offline options also backup &lt;em>/var/lib/pulp&lt;/em>, which contains
all downloaded packages. This could be &lt;strong>huge&lt;/strong>. There’s an option to skip this so&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-maintain backup offline --skip-pulp-tar /backup/&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
For a restore you always need the content of &lt;em>/var/lib/pulp&lt;/em>.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is mainly usefull for cloning satellite. You backup everything
except &lt;em>/var/lib/pulp&lt;/em>, copy the backup to a second system and rsync
&lt;em>/var/lib/pulp&lt;/em> to the new system. Then restore the backup and
satellite should work as normal on the clone.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_snaphot_backups">Snaphot backups&lt;/h3>
&lt;div class="paragraph">
&lt;p>Satellite also supports backups via LVM snapshots. For more information see &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_satellite/6.6/html/administering_red_hat_satellite/chap-red_hat_satellite-administering_red_hat_satellite-backup_and_disaster_recovery#snapshot-backup_assembly">Snapshot backup&lt;/a>&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_upgrades">Upgrades&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Read the Satellite release notes&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Do a offline backup see &lt;a href="#Backup / Restore">[Backup / Restore]&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You could clone satellite to a other system&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If there are local changes to dhcpd or dns configurations use&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-installer --foreman-proxy-dns-managed=false --foreman-proxy-dhcp-managed=false&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>to stop satellite-install from overwriting those files.&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>install the latest version of satellite-maintain via&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">yum install rubygem-foreman_maintain&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>check for available satellite versions with&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-maintain upgrade list-versions&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>test the possible upgrade with&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-maintain upgrade check --target-version 6.7&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>and finally run the upgrade and PRAY!&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-maintain upgrade run --target-version 6.7&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_various_tips_and_tricks">Various tips and tricks&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="sect2">
&lt;h3 id="_installing_packages_via_yum">Installing packages via yum&lt;/h3>
&lt;div class="paragraph">
&lt;p>Satellite installs a yum plugin called &lt;code>foreman-protector&lt;/code>. If you try
to install a package via yum you get the following message&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code>WARNING: Excluding 12190 packages due to foreman-protector.
Use foreman-maintain packages install/update &amp;lt;package&amp;gt;
to safely install packages without restrictions.
Use foreman-maintain upgrade run for full upgrade.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>so use&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">satellite-maintain install &amp;lt;package name&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_os_package_upgrade">OS package upgrade&lt;/h3>
&lt;div class="paragraph">
&lt;p>This should be done via satellite-maintain because all packages are locked by default (see &lt;a href="#_installing_packages_via_yum">Installing packages via yum&lt;/a>).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This basically comes down to running&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oreman-maintain upgrade run --target-version 6.6.z&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>for upgrading OS packages if you have satellite 6.6 installed.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Helpful oc / kubectl commands</title><link>https://blog.stderr.at/openshift/2020/04/helpful-oc-/-kubectl-commands/</link><pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2020/04/helpful-oc-/-kubectl-commands/</guid><description>&lt;div class="paragraph">
&lt;p>This is a list of useful oc and/or kubectl commands so they won’t be forgotton. No this is not a joke…​&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_list_all_pods_in_state_running">List all pods in state &lt;em>Running&lt;/em>&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get pods --field-selector=status.phase=Running&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_list_all_pods_in_state_running_and_show_there_resource_usage">List all pods in state &lt;em>Running&lt;/em> and show there resource usage&lt;/h3>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get pods --field-selector=status.phase=Running -o json|jq &amp;#34;.items[] | {name: .metada
ta.name, res: .spec.containers[].resources}&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_list_events_sort_by_time_created">List events sort by time created&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"> oc get events --sort-by=&amp;#39;.lastTimestamp&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_explain_objects_while_specifing_the_api_version">Explain objects while specifing the api version&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Sometimes when you run &lt;code>oc explain&lt;/code> you get a message in DESCRIPTION that this particular version is deprecated, e.g. you are running &lt;code>oc explain deployment&lt;/code> and get&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">DESCRIPTION:
DEPRECATED - This group version of Deployment is deprecated by
apps/v1/Deployment. See the release notes for more information. Deployment
enables declarative updates for Pods and ReplicaSets.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Note the DEPRECTATED message above
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>if you want to see the documentation for the object that has not been deprecated you can use&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc explain deployment --api-version=apps/v1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_magic_with_oc_set">Magic with oc set&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;code>oc set&lt;/code> is actually a very versatile command. Studying &lt;code>oc set -h&lt;/code> is a good idea, here are some examples&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_set_route_weights_when_alternatebackends_in_a_route_are_defined">Set route weights when alternateBackends in a route are defined&lt;/h3>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc set route-backends bluegreen blue=1 green=9&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_set_resources_on_the_command_line">Set resources on the command line&lt;/h3>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc set resources dc cakephp-mysql-example --limits=memory=1Gi,cpu=200m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item></channel></rss>