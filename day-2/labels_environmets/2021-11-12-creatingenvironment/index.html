<!doctype html><html lang=en class="js csstransforms3d"><head><meta name=google-site-verification content="yq2Ib3doJVHVlEW2wtHap5WY54JhS2CCvI40y30F0FI"><meta charset=utf-8><meta name=color-scheme content="dark light"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.101.0"><meta name=description content="Create separate environments on one OpenShift cluster"><meta name=author content="Toni Schmidbauer & Thomas Jungbauer"><link rel=icon href=/images/favicon.ico type=image/png><link rel=apple-touch-icon sizes=152x152 href=/images/apple-touch-icon-152x152.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon-180x180.png><link rel=apple-touch-icon sizes=128x128 href=/images/apple-touch-icon-128x128.png><link rel=apple-touch-icon sizes=144x144 href=/images/apple-touch-icon-144x144.png><link rel=apple-touch-icon sizes=114x114 href=/images/apple-touch-icon-114x114.png><link rel=apple-touch-icon sizes=72x72 href=/images/apple-touch-icon-72x72.png><link rel=apple-touch-icon href=/images/apple-touch-icon-57x57.png><link rel="shortcut icon" href=/images/favicon.ico><link rel=apple-touch-icon sizes=57x57 href=/images/apple-icon-57x57.png><link rel=apple-touch-icon sizes=60x60 href=/images/apple-icon-60x60.png><link rel=apple-touch-icon sizes=76x76 href=/images/apple-icon-76x76.png><link rel=apple-touch-icon sizes=120x120 href=/images/apple-icon-120x120.png><link rel=icon type=image/png sizes=192x192 href=/images/android-icon-192x192.png><link rel=icon type=image/png sizes=32x32 href=/images/favicon-32x32.png><link rel=icon type=image/png sizes=96x96 href=/images/favicon-96x96.png><link rel=icon type=image/png sizes=16x16 href=/images/favicon-16x16.png><title>Working with Environments :: TechBlog about OpenShift/Ansible/Satellite and much more</title><link rel=manifest href=/manifest.json><meta name=theme-color content="#317EFB"><link href=/css/nucleus.min.css?1661575540 rel=stylesheet><link href=/css/fontawesome-all.min.css?1661575540 rel=stylesheet><link href=/css/font-awesome-animation.min.css?1661575540 rel=stylesheet><link href=/css/hybrid.css?1661575540 rel=stylesheet><link href=/css/featherlight.min.css?1661575540 rel=stylesheet><link href=/css/perfect-scrollbar.min.css?1661575540 rel=stylesheet><link href=/css/auto-complete.css?1661575540 rel=stylesheet><link href=/css/atom-one-dark-reasonable.css?1661575540 rel=stylesheet><link href=/css/theme.min.css?1661575540 rel=stylesheet><link href=/css/hugo-theme.css?1661575540 rel=stylesheet><link href=/css/theme-yaub.css?1661575540 rel=stylesheet><script src=/js/jquery-3.6.0.min.js?1661575540></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=/day-2/labels_environmets/2021-11-12-creatingenvironment/><button onclick=scrollTopAnimated() id=myBtn class="top-btn button fa fa-arrow-up" title="Go to top"></button><nav id=sidebar><div id=header-wrapper><div id=header><a id=logo href=/><p class="fa fa-cloud-upload-alt faa-float animated"></p><span class=text>YAUB</span><p class=logoarea><span class="text small">Yet another Useless Blog</span></p></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=/js/lunr.min.js?1661575540></script>
<script type=text/javascript src=/js/auto-complete.js?1661575540></script>
<script type=text/javascript>var baseurl="https://blog.stderr.at/"</script><script type=text/javascript src=/js/search.js?1661575540></script></div><div class=togglemode><button id=dark-mode-toggle class="btn-toggle btn-default btn">Toggle Dark-Mode</button></div><section id=homelinks><ul><li><a class=padding href=/><i class='fas fa-home'></i> Home</a></li></ul></section><div class=highlightable><ul class=topics><li data-nav-id=/openshift/ title=OpenShift class=dd-item><a href=/openshift/>OpenShift</a><ul><li data-nav-id=/openshift/2022-08-16-hashicorp-vault/ title="Secrets Management - Vault on OpenShift" class=dd-item><a href=/openshift/2022-08-16-hashicorp-vault/>Secrets Management - Vault on OpenShift</a></li><li data-nav-id=/openshift/2022-04-22-multi-cloud-gateway/ title="Overview of Red Hat's Multi Cloud Gateway (Noobaa)" class=dd-item><a href=/openshift/2022-04-22-multi-cloud-gateway/>Overview of Red Hat's Multi Cloud Gateway (Noobaa)</a></li><li data-nav-id=/openshift/2021-09-25-sealed_secrets/ title="Secure your secrets with Sealed Secrets" class=dd-item><a href=/openshift/2021-09-25-sealed_secrets/>Secure your secrets with Sealed Secrets</a></li><li data-nav-id=/openshift/2021-02-27-understanding-block-devices/ title="Understanding RWO block device handling in OpenShift" class=dd-item><a href=/openshift/2021-02-27-understanding-block-devices/>Understanding RWO block device handling in OpenShift</a></li><li data-nav-id=/openshift/2021-01-27-writingoperatoransible/ title="Writing Operator using Ansible" class=dd-item><a href=/openshift/2021-01-27-writingoperatoransible/>Writing Operator using Ansible</a></li><li data-nav-id=/openshift/2020-12-10-thanos-vs-thanos/ title="Thanos Querier vs Thanos Querier" class=dd-item><a href=/openshift/2020-12-10-thanos-vs-thanos/>Thanos Querier vs Thanos Querier</a></li><li data-nav-id=/openshift/2020-08-06-argocd/ title="GitOps - Argo CD" class=dd-item><a href=/openshift/2020-08-06-argocd/>GitOps - Argo CD</a></li><li data-nav-id=/openshift/2020-04-16-tekton/ title="OpenShift Pipelines - Tekton Introduction" class=dd-item><a href=/openshift/2020-04-16-tekton/>OpenShift Pipelines - Tekton Introduction</a></li><li data-nav-id=/openshift/2020-04-01-oc-commands/ title="Helpful oc / kubectl commands" class=dd-item><a href=/openshift/2020-04-01-oc-commands/>Helpful oc / kubectl commands</a></li></ul></li><li data-nav-id=/day-2/ title="OpenShift Day-2" class="dd-item
parent"><a href=/day-2/>OpenShift Day-2</a><ul><li data-nav-id=/day-2/etcd/ title=etcd class=dd-item><a href=/day-2/etcd/>etcd</a><ul><li data-nav-id=/day-2/etcd/2021-11-29-automatedetcdbackup/ title="Automated ETCD Backup" class=dd-item><a href=/day-2/etcd/2021-11-29-automatedetcdbackup/>Automated ETCD Backup</a></li></ul></li><li data-nav-id=/day-2/gitops/ title=Gitops class=dd-item><a href=/day-2/gitops/>Gitops</a><ul><li data-nav-id=/day-2/gitops/2022-08-16-hashicorp-vault/ title="Secrets Management - Vault on OpenShift" class=dd-item><a href=/day-2/gitops/2022-08-16-hashicorp-vault/>Secrets Management - Vault on OpenShift</a></li></ul></li><li data-nav-id=/day-2/labels_environmets/ title="Labels & Environments" class="dd-item
parent"><a href=/day-2/labels_environmets/>Labels & Environments</a><ul><li data-nav-id=/day-2/labels_environmets/2021-11-12-creatingenvironment/ title="Working with Environments" class="dd-item active"><a href=/day-2/labels_environmets/2021-11-12-creatingenvironment/>Working with Environments</a></li></ul></li><li data-nav-id=/day-2/pod-placement/ title="Pod Placement" class=dd-item><a href=/day-2/pod-placement/>Pod Placement</a><ul><li data-nav-id=/day-2/pod-placement/2021-08-26-podplacement-intro/ title=Introduction class=dd-item><a href=/day-2/pod-placement/2021-08-26-podplacement-intro/>Introduction</a></li><li data-nav-id=/day-2/pod-placement/2021-08-29-node-affinity/ title="Node Affinity" class=dd-item><a href=/day-2/pod-placement/2021-08-29-node-affinity/>Node Affinity</a></li><li data-nav-id=/day-2/pod-placement/2021-08-27-podplacement/ title=NodeSelector class=dd-item><a href=/day-2/pod-placement/2021-08-27-podplacement/>NodeSelector</a></li><li data-nav-id=/day-2/pod-placement/2021-08-28-affinity/ title="Pod Affinity/Anti-Affinity" class=dd-item><a href=/day-2/pod-placement/2021-08-28-affinity/>Pod Affinity/Anti-Affinity</a></li><li data-nav-id=/day-2/pod-placement/2021-08-30-taints/ title="Taints and Tolerations" class=dd-item><a href=/day-2/pod-placement/2021-08-30-taints/>Taints and Tolerations</a></li><li data-nav-id=/day-2/pod-placement/2021-08-31-topologyspreadcontraints/ title="Topology Spread Constraints" class=dd-item><a href=/day-2/pod-placement/2021-08-31-topologyspreadcontraints/>Topology Spread Constraints</a></li><li data-nav-id=/day-2/pod-placement/2021-09-01-descheduler/ title="Using Descheduler" class=dd-item><a href=/day-2/pod-placement/2021-09-01-descheduler/>Using Descheduler</a></li></ul></li></ul></li><li data-nav-id=/compliance/ title=Compliance class=dd-item><a href=/compliance/>Compliance</a><ul><li data-nav-id=/compliance/2021/07/oc-compliance-command-line-plugin/ title="oc compliance command line plugin" class=dd-item><a href=/compliance/2021/07/oc-compliance-command-line-plugin/>oc compliance command line plugin</a></li><li data-nav-id=/compliance/2021/07/compliance-operator/ title="Compliance Operator" class=dd-item><a href=/compliance/2021/07/compliance-operator/>Compliance Operator</a></li></ul></li><li data-nav-id=/service-mesh/ title="Service Mesh" class=dd-item><a href=/service-mesh/>Service Mesh</a><ul><li data-nav-id=/service-mesh/2020/05/enable-automatic-route-creation/ title="Enable Automatic Route Creation" class=dd-item><a href=/service-mesh/2020/05/enable-automatic-route-creation/>Enable Automatic Route Creation</a></li><li data-nav-id=/service-mesh/2020/05/authorization-rbac/ title="Authorization (RBAC)" class=dd-item><a href=/service-mesh/2020/05/authorization-rbac/>Authorization (RBAC)</a></li><li data-nav-id=/service-mesh/2020/04/deploy-example-bookinfo-application/ title="Deploy Example Bookinfo Application" class=dd-item><a href=/service-mesh/2020/04/deploy-example-bookinfo-application/>Deploy Example Bookinfo Application</a></li><li data-nav-id=/service-mesh/2020/04/service-mesh-1.1-released/ title="Service Mesh 1.1 released" class=dd-item><a href=/service-mesh/2020/04/service-mesh-1.1-released/>Service Mesh 1.1 released</a></li><li data-nav-id=/service-mesh/2020/04/authentication-jwt/ title="Authentication JWT" class=dd-item><a href=/service-mesh/2020/04/authentication-jwt/>Authentication JWT</a></li><li data-nav-id=/service-mesh/2020/04/mutual-tls-authentication/ title="Mutual TLS Authentication" class=dd-item><a href=/service-mesh/2020/04/mutual-tls-authentication/>Mutual TLS Authentication</a></li><li data-nav-id=/service-mesh/2020/04/fault-injection/ title="Fault Injection" class=dd-item><a href=/service-mesh/2020/04/fault-injection/>Fault Injection</a></li><li data-nav-id=/service-mesh/2020/04/limit-egress/external-traffic/ title="Limit Egress/External Traffic" class=dd-item><a href=/service-mesh/2020/04/limit-egress/external-traffic/>Limit Egress/External Traffic</a></li><li data-nav-id=/service-mesh/2020/04/advanced-routing-example/ title="Advanced Routing Example" class=dd-item><a href=/service-mesh/2020/04/advanced-routing-example/>Advanced Routing Example</a></li><li data-nav-id=/service-mesh/2020/04/routing-example/ title="Routing Example" class=dd-item><a href=/service-mesh/2020/04/routing-example/>Routing Example</a></li><li data-nav-id=/service-mesh/2020/03/ingress-with-custom-domain/ title="Ingress with custom domain" class=dd-item><a href=/service-mesh/2020/03/ingress-with-custom-domain/>Ingress with custom domain</a></li><li data-nav-id=/service-mesh/2020/03/ingress-traffic/ title="Ingress Traffic" class=dd-item><a href=/service-mesh/2020/03/ingress-traffic/>Ingress Traffic</a></li><li data-nav-id=/service-mesh/2020/03/deploy-microservices/ title="Deploy Microservices" class=dd-item><a href=/service-mesh/2020/03/deploy-microservices/>Deploy Microservices</a></li><li data-nav-id=/service-mesh/2020/03/installation/ title=Installation class=dd-item><a href=/service-mesh/2020/03/installation/>Installation</a></li></ul></li><li data-nav-id=/general/ title=General class=dd-item><a href=/general/>General</a><ul><li data-nav-id=/general/2020/05/basic-usage-of-git/ title="Basic usage of git" class=dd-item><a href=/general/2020/05/basic-usage-of-git/>Basic usage of git</a></li><li data-nav-id=/general/2020/04/red-hat-satellite-cheat-sheet/ title="Red Hat Satellite Cheat Sheet" class=dd-item><a href=/general/2020/04/red-hat-satellite-cheat-sheet/>Red Hat Satellite Cheat Sheet</a></li></ul></li><li data-nav-id=/ansible/ title=Ansible class=dd-item><a href=/ansible/>Ansible</a><ul><li data-nav-id=/ansible/2021/11/ansible-style-guide/ title="Ansible Style Guide" class=dd-item><a href=/ansible/2021/11/ansible-style-guide/>Ansible Style Guide</a></li><li data-nav-id=/ansible/2021/10/automation-controller-and-ldap-authentication/ title="Automation Controller and LDAP Authentication" class=dd-item><a href=/ansible/2021/10/automation-controller-and-ldap-authentication/>Automation Controller and LDAP Authentication</a></li><li data-nav-id=/ansible/2021/07/ansible-tower-and-downloading-collections/ title="Ansible Tower and downloading collections" class=dd-item><a href=/ansible/2021/07/ansible-tower-and-downloading-collections/>Ansible Tower and downloading collections</a></li><li data-nav-id=/ansible/2020/04/ansible-azure-resource-manager-example/ title="Ansible - Azure Resource Manager Example" class=dd-item><a href=/ansible/2020/04/ansible-azure-resource-manager-example/>Ansible - Azure Resource Manager Example</a></li><li data-nav-id=/ansible/2020/04/do410-ansible-and-ansible-tower-training-notes/ title="DO410 Ansible and Ansible Tower training notes" class=dd-item><a href=/ansible/2020/04/do410-ansible-and-ansible-tower-training-notes/>DO410 Ansible and Ansible Tower training notes</a></li></ul></li><li data-nav-id=/acs/ title="Advanced Cluster Security" class=dd-item><a href=/acs/>Advanced Cluster Security</a><ul><li data-nav-id=/acs/2021-12-11-acsauth/ title="Advanced Cluster Security - Authentication" class=dd-item><a href=/acs/2021-12-11-acsauth/>Advanced Cluster Security - Authentication</a></li></ul></li><li data-nav-id=/azure/ title=Azure class=dd-item><a href=/azure/>Azure</a><ul><li data-nav-id=/azure/2021-10-29-private-aro/ title="Stumbling into Azure Part II: Setting up a private ARO cluster" class=dd-item><a href=/azure/2021-10-29-private-aro/>Stumbling into Azure Part II: Setting up a private ARO cluster</a></li><li data-nav-id=/azure/2021-10-17-s2s-vpn/ title="Stumbling into Azure Part I: Building a site-to-site VPN tunnel for testing" class=dd-item><a href=/azure/2021-10-17-s2s-vpn/>Stumbling into Azure Part I: Building a site-to-site VPN tunnel for testing</a></li></ul></li><li data-nav-id=/java/ title=Java class=dd-item><a href=/java/>Java</a><ul><li data-nav-id=/java/2022-02-25-jpa-disconnected-entity/ title="Adventures in Java Land: JPA disconnected entities" class=dd-item><a href=/java/2022-02-25-jpa-disconnected-entity/>Adventures in Java Land: JPA disconnected entities</a></li></ul></li><li data-nav-id=/quay/ title=Quay class=dd-item><a href=/quay/>Quay</a><ul><li data-nav-id=/quay/2021-09-07-quay-upgrade-3.4/ title="Stumbling into Quay: Upgrading from 3.3 to 3.4 with the quay-operator" class=dd-item><a href=/quay/2021-09-07-quay-upgrade-3.4/>Stumbling into Quay: Upgrading from 3.3 to 3.4 with the quay-operator</a></li><li data-nav-id=/quay/2020-05-13-quay-tutorial1/ title="Red Hat Quay Registry - Overview and Installation" class=dd-item><a href=/quay/2020-05-13-quay-tutorial1/>Red Hat Quay Registry - Overview and Installation</a></li></ul></li><li data-nav-id=/archive/ title=Archive class=dd-item><a href=/archive/>Archive</a></li><li data-nav-id=/legaldisclosure/ title="Legal Disclosure" class=dd-item><a href=/legaldisclosure/>Legal Disclosure</a></li><li data-nav-id=/rss/ title="RSS Feeds" class=dd-item><a href=/rss/>RSS Feeds</a></li></ul><section id=shortcuts><h3 class=shortcut-title>More</h3><ul><li><a class=padding href=https://blog.stderr.at/tags><i class='fas fa-tags'></i> Tags</a></li><li><a class=padding href=https://blog.stderr.at/categories><i class='far fa-bookmark'></i> Catagories</a></li><li><a class=padding href=https://charts.stderr.at/><i class='fas fa-book'></i> Helm Charts</a></li><li><a class=padding href=https://www.redhat.com><i class='fab fa-redhat'></i> Red Hat</a></li></ul></section><section id=footer></section></div></nav><section id=body><div id=overlay></div><aside id=toc-field class="hidden lg:block tableOfContentContainer"><header id=TableOfContentsHeader>What's on this Page</header><nav id=TableOfContents><ul><li><a href=#_prerequisites>Prerequisites</a></li><li><a href=#_create_nodes_labels_and_machineconfigpools>Create Nodes Labels and MachineConfigPools</a></li><li><a href=#_create_custom_configuration>Create Custom Configuration</a></li><li><a href=#_bind_an_application_to_a_specific_environment>Bind an Application to a Specific Environment</a></li><li><a href=#_create_dedicated_ingresscontroller>Create Dedicated IngressController</a></li><li><a href=#_verify_ingress_configuration>Verify Ingress Configuration</a></li><li><a href=#_appendix>Appendix</a><ul><li><a href=#_internal_registry>Internal Registry</a></li><li><a href=#_openshift_monitoring_workload>OpenShift Monitoring Workload</a></li></ul></li></ul></nav><div id=navigation><a class=nav-prev href=/day-2/labels_environmets/ title="Labels & Environments"><i class="fa fa-chevron-left"></i></a>
<a class=nav-next href=/day-2/pod-placement/ title="Pod Placement" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></aside><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://schema.org/BreadcrumbList><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i></a></span>
<span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><span itemscope itemprop=itemListElement itemtype=http://schema.org/ListItem><a itemprop=item href=/><span itemprop=name>YAUB Yet Another Useless Blog</span><meta itemprop=position content="1"></a></span>> <span itemscope itemprop=itemListElement itemtype=http://schema.org/ListItem><a itemprop=item href=/day-2/><span itemprop=name>OpenShift Day-2</span><meta itemprop=position content="2"></a></span>> <span itemscope itemprop=itemListElement itemtype=http://schema.org/ListItem><a itemprop=item href=/day-2/labels_environmets/><span itemprop=name>Labels & Environments</span><meta itemprop=position content="3"></a></span>> Working with Environments</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#_prerequisites>Prerequisites</a></li><li><a href=#_create_nodes_labels_and_machineconfigpools>Create Nodes Labels and MachineConfigPools</a></li><li><a href=#_create_custom_configuration>Create Custom Configuration</a></li><li><a href=#_bind_an_application_to_a_specific_environment>Bind an Application to a Specific Environment</a></li><li><a href=#_create_dedicated_ingresscontroller>Create Dedicated IngressController</a></li><li><a href=#_verify_ingress_configuration>Verify Ingress Configuration</a></li><li><a href=#_appendix>Appendix</a><ul><li><a href=#_internal_registry>Internal Registry</a></li><li><a href=#_openshift_monitoring_workload>OpenShift Monitoring Workload</a></li></ul></li></ul></nav></div></div></div></div><div id=head-tags><div class=tags><a class=tag-link href=/tags/ocp>OCP</a>
<a class=tag-link href=/tags/day-2>Day-2</a>
<a class=tag-link href=/tags/openshift>OpenShift</a>
<a class=tag-link href=/tags/pod-placement>Pod Placement</a>
<a class=tag-link href=/tags/nodeselector>NodeSelector</a>
<a class=tag-link href=/tags/environments>Environments</a>
<a class=tag-link href=/tags/ingress>Ingress</a>
<a class=tag-link href=/tags/ingresscontroller>IngressController</a>
<a class=tag-link href=/tags/labels>Labels</a>
<a class=tag-link href=/tags/annotations>Annotations</a></div></div><div id=body-inner><h1>Working with Environments</h1><p class=tracked><time class="f6 mv4 dib tracked" datetime=2021-11-12T00:00:00Z><strong>November 12, 2021</strong></time>
- By:
Thomas Jungbauer
( Lastmod: 2021-12-15 )</p><div class=paragraph><p>Imagine you have one OpenShift cluster and you would like to create 2 or more environments inside this cluster, but also separate them and force the environments to specific nodes, or use specific inbound routers. All this can be achieved using labels, IngressControllers and so on. The following article will guide you to set up dedicated compute nodes for infrastructure, development and test environments as well as the creation of IngressController which are bound to the appropriate nodes.</p></div><div class=sect1><h2 id=_prerequisites>Prerequisites</h2><div class=sectionbody><div class=paragraph><p>Before we start we need an OpenShift cluster of course. In this example we have a cluster with typical 3 control plane nodes (labelled as master) and 7 compute nodes (labelled as worker)</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc get nodes

NAME                                         STATUS   ROLES    AGE   VERSION
ip-10-0-138-104.us-east-2.compute.internal   Ready    master   13h   v1.21.1+6438632
ip-10-0-149-168.us-east-2.compute.internal   Ready    worker   13h   v1.21.1+6438632 # &lt;-- will become infra
ip-10-0-154-244.us-east-2.compute.internal   Ready    worker   16m   v1.21.1+6438632 # &lt;-- will become infra
ip-10-0-158-44.us-east-2.compute.internal    Ready    worker   15m   v1.21.1+6438632 # &lt;-- will become infra
ip-10-0-160-91.us-east-2.compute.internal    Ready    master   13h   v1.21.1+6438632
ip-10-0-188-198.us-east-2.compute.internal   Ready    worker   13h   v1.21.1+6438632 # &lt;-- will become worker-test
ip-10-0-191-9.us-east-2.compute.internal     Ready    worker   16m   v1.21.1+6438632 # &lt;-- will become worker-test
ip-10-0-192-174.us-east-2.compute.internal   Ready    master   13h   v1.21.1+6438632
ip-10-0-195-201.us-east-2.compute.internal   Ready    worker   16m   v1.21.1+6438632 # &lt;-- will become worker-dev
ip-10-0-199-235.us-east-2.compute.internal   Ready    worker   16m   v1.21.1+6438632 # &lt;-- will become worker-dev</code></pre></div></div><div class=paragraph><p>We will use the 7 nodes to create the environments for:</p></div><div class=ulist><ul><li><p>Infrastructure Services (3 nodes) - will be labelled as <code>infra</code></p></li><li><p>Development Environment (2 nodes) - will be labelled as <code>worker-dev</code></p></li><li><p>Test Environment (2 nodes) - will be labelled as <code>worker-test</code></p></li></ul></div><div class=paragraph><p>To do this, we will label the nodes and create dedicated roles for them.</p></div></div></div><div class=sect1><h2 id=_create_nodes_labels_and_machineconfigpools>Create Nodes Labels and MachineConfigPools</h2><div class=sectionbody><div class=paragraph><p>Let’s create a maschine config pool for the different environments.</p></div><div class=paragraph><p>The pool inherits the configuration from <code>worker</code> nodes by default, which means that any new update on the worker configuration will also update custom labeled nodes.
Or in other words: it is possible to remove the worker label from the custom pools.</p></div><div class=paragraph><p>Create the following objects:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-yaml data-lang=yaml># Infrastructure
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  name: infra
spec:
  machineConfigSelector:
    matchExpressions:
      - {key: machineconfiguration.openshift.io/role, operator: In, values: [worker,infra]} <i class=conum data-value=1></i><b>(1)</b>
  maxUnavailable: 1 <i class=conum data-value=2></i><b>(2)</b>
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/infra: &#34;&#34; <i class=conum data-value=3></i><b>(3)</b>
  paused: false
---
# Worker-DEV
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  name: worker-dev
spec:
  machineConfigSelector:
    matchExpressions:
      - {key: machineconfiguration.openshift.io/role, operator: In, values: [worker,worker-dev]}
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/worker-dev: &#34;&#34;
---
# Worker-TEST
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
  name: worker-test
spec:
  machineConfigSelector:
    matchExpressions:
      - {key: machineconfiguration.openshift.io/role, operator: In, values: [worker,worker-test]}
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/worker-test: &#34;&#34;</code></pre></div></div><div class="colist arabic"><table><tbody><tr><td><i class=conum data-value=1></i><b>1</b></td><td>User worker and infra so that the default worker configuration gets applied during upgrades</td></tr><tr><td><i class=conum data-value=2></i><b>2</b></td><td>Whenever an update happens, do only 1 at a time</td></tr><tr><td><i class=conum data-value=3></i><b>3</b></td><td>This pool is valid for nodes which are labelled as <code>infra</code></td></tr></tbody></table></div><div class=paragraph><p>Now let’s label our nodes.
First add the new, additional label:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash># Add the label &#34;infra&#34;
oc label node ip-10-0-149-168.us-east-2.compute.internal ip-10-0-154-244.us-east-2.compute.internal ip-10-0-158-44.us-east-2.compute.internal node-role.kubernetes.io/infra=

# Add the label &#34;worker-dev&#34;
oc label node ip-10-0-195-201.us-east-2.compute.internal ip-10-0-199-235.us-east-2.compute.internal node-role.kubernetes.io/worker-dev=

# Add the label &#34;worker-test&#34;
oc label node ip-10-0-188-198.us-east-2.compute.internal ip-10-0-191-9.us-east-2.compute.internal node-role.kubernetes.io/worker-test=</code></pre></div></div><div class=paragraph><p>This will result in:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>NAME                                         STATUS   ROLES                AGE   VERSION
ip-10-0-138-104.us-east-2.compute.internal   Ready    master               13h   v1.21.1+6438632
ip-10-0-149-168.us-east-2.compute.internal   Ready    infra,worker         13h   v1.21.1+6438632
ip-10-0-154-244.us-east-2.compute.internal   Ready    infra,worker         20m   v1.21.1+6438632
ip-10-0-158-44.us-east-2.compute.internal    Ready    infra,worker         19m   v1.21.1+6438632
ip-10-0-160-91.us-east-2.compute.internal    Ready    master               13h   v1.21.1+6438632
ip-10-0-188-198.us-east-2.compute.internal   Ready    worker,worker-test   13h   v1.21.1+6438632
ip-10-0-191-9.us-east-2.compute.internal     Ready    worker,worker-test   20m   v1.21.1+6438632
ip-10-0-192-174.us-east-2.compute.internal   Ready    master               13h   v1.21.1+6438632
ip-10-0-195-201.us-east-2.compute.internal   Ready    worker,worker-dev    20m   v1.21.1+6438632
ip-10-0-199-235.us-east-2.compute.internal   Ready    worker,worker-dev    20m   v1.21.1+6438632</code></pre></div></div><div class=paragraph><p>We can remove the worker label from the worker-dev and worker-test nodes now.</p></div><div class="admonitionblock warning"><table><tbody><tr><td class=icon><i class="fa icon-warning" title=Warning></i></td><td class=content>Keep the label "worker" for the infra nodes as this is the default worker label which is used when no nodeselector is in use. You can use any other node, just keep in mind that per default new applications will be started on nodes with the labels "worker". As an alternative, you can also define a cluster-wide default node selector.</td></tr></tbody></table></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc label node ip-10-0-195-201.us-east-2.compute.internal ip-10-0-199-235.us-east-2.compute.internal node-role.kubernetes.io/worker-
oc label node ip-10-0-188-198.us-east-2.compute.internal ip-10-0-191-9.us-east-2.compute.internal node-role.kubernetes.io/worker-</code></pre></div></div><div class=paragraph><p>The final node labels will look like the following:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>NAME                                         STATUS   ROLES         AGE   VERSION
ip-10-0-138-104.us-east-2.compute.internal   Ready    master        13h   v1.21.1+6438632
ip-10-0-149-168.us-east-2.compute.internal   Ready    infra,worker  13h   v1.21.1+6438632
ip-10-0-154-244.us-east-2.compute.internal   Ready    infra,worker  22m   v1.21.1+6438632
ip-10-0-158-44.us-east-2.compute.internal    Ready    infra,worker  21m   v1.21.1+6438632
ip-10-0-160-91.us-east-2.compute.internal    Ready    master        13h   v1.21.1+6438632
ip-10-0-188-198.us-east-2.compute.internal   Ready    worker-test   13h   v1.21.1+6438632
ip-10-0-191-9.us-east-2.compute.internal     Ready    worker-test   21m   v1.21.1+6438632
ip-10-0-192-174.us-east-2.compute.internal   Ready    master        13h   v1.21.1+6438632
ip-10-0-195-201.us-east-2.compute.internal   Ready    worker-dev    21m   v1.21.1+6438632
ip-10-0-199-235.us-east-2.compute.internal   Ready    worker-dev    22m   v1.21.1+6438632</code></pre></div></div><div class="admonitionblock note"><table><tbody><tr><td class=icon><i class="fa icon-note" title=Note></i></td><td class=content>Since the custom pools (infra, worker-test and worker-dev) inherit their configuration from the default worker pool, no changes on the files on the nodes themselves are triggered at this point.</td></tr></tbody></table></div></div></div><div class=sect1><h2 id=_create_custom_configuration>Create Custom Configuration</h2><div class=sectionbody><div class=paragraph><p>Let’s test our setup by deploying a configuration on specific nodes. The following MaschineConfig objects will create a file at <strong>/etc/myfile</strong> on the nodes labelled either <em>infra</em>, <em>worker-dev</em> or <em>worker_test</em>.
Dependent on the node role the content of the file will vary.</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-yaml data-lang=yaml>apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: infra <i class=conum data-value=1></i><b>(1)</b>
  name: 55-infra
spec:
  config:
    ignition:
      version: 2.2.0
    storage:
      files:
      - contents:
          source: data:,infra <i class=conum data-value=2></i><b>(2)</b>
        filesystem: root
        mode: 0644
        path: /etc/myfile <i class=conum data-value=3></i><b>(3)</b>
---
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker-dev
  name: 55-worker-dev
spec:
  config:
    ignition:
      version: 2.2.0
    storage:
      files:
      - contents:
          source: data:,worker-dev
        filesystem: root
        mode: 0644
        path: /etc/myfile
---
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker-test
  name: 55-worker-test
spec:
  config:
    ignition:
      version: 2.2.0
    storage:
      files:
      - contents:
          source: data:,worker-test
        filesystem: root
        mode: 0644
        path: /etc/myfile</code></pre></div></div><div class="colist arabic"><table><tbody><tr><td><i class=conum data-value=1></i><b>1</b></td><td>Valid for node with the role xyz</td></tr><tr><td><i class=conum data-value=2></i><b>2</b></td><td>Content of the file</td></tr><tr><td><i class=conum data-value=3></i><b>3</b></td><td>File to be created</td></tr></tbody></table></div><div class=paragraph><p>Since this is a new configuration, all nodes will get reconfigured.</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>NAME                                         STATUS                        ROLES         AGE   VERSION
ip-10-0-138-104.us-east-2.compute.internal   Ready                         master        13h   v1.21.1+6438632
ip-10-0-149-168.us-east-2.compute.internal   Ready,SchedulingDisabled      infra,worker  13h   v1.21.1+6438632
ip-10-0-154-244.us-east-2.compute.internal   Ready                         infra,worker  28m   v1.21.1+6438632
ip-10-0-158-44.us-east-2.compute.internal    Ready                         infra,worker  27m   v1.21.1+6438632
ip-10-0-160-91.us-east-2.compute.internal    Ready                         master        13h   v1.21.1+6438632
ip-10-0-188-198.us-east-2.compute.internal   Ready                         worker-test   13h   v1.21.1+6438632
ip-10-0-191-9.us-east-2.compute.internal     NotReady,SchedulingDisabled   worker-test   27m   v1.21.1+6438632
ip-10-0-192-174.us-east-2.compute.internal   Ready                         master        13h   v1.21.1+6438632
ip-10-0-195-201.us-east-2.compute.internal   Ready                         worker-dev    27m   v1.21.1+6438632
ip-10-0-199-235.us-east-2.compute.internal   NotReady,SchedulingDisabled   worker-dev    28m   v1.21.1+6438632</code></pre></div></div><div class=paragraph><p>Wait until all nodes are ready and test the configuration by verifying the content of <em>/etc/myfile</em>:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>###
# infra nodes:
###
oc get pods -n openshift-machine-config-operator -l k8s-app=machine-config-daemon --field-selector &#34;spec.nodeName=ip-10-0-149-168.us-east-2.compute.internal&#34;
NAME                          READY   STATUS    RESTARTS   AGE
machine-config-daemon-f85kd   2/2     Running   6          16h

# Get file content
oc rsh -n openshift-machine-config-operator machine-config-daemon-f85kd chroot /rootfs cat /etc/myfile
Defaulted container &#34;machine-config-daemon&#34; out of: machine-config-daemon, oauth-proxy
infra

###
#worker-dev:
###
oc get pods -n openshift-machine-config-operator -l k8s-app=machine-config-daemon --field-selector &#34;spec.nodeName=ip-10-0-195-201.us-east-2.compute.internal&#34;
NAME                          READY   STATUS    RESTARTS   AGE
machine-config-daemon-s6rr5   2/2     Running   4          3h5m

# Get file content
oc rsh -n openshift-machine-config-operator machine-config-daemon-s6rr5 chroot /rootfs cat /etc/myfile
Defaulted container &#34;machine-config-daemon&#34; out of: machine-config-daemon, oauth-proxy
worker-dev

###
# worker-test:
###
oc get pods -n openshift-machine-config-operator -l k8s-app=machine-config-daemon --field-selector &#34;spec.nodeName=ip-10-0-188-198.us-east-2.compute.internal&#34;
NAME                          READY   STATUS    RESTARTS   AGE
machine-config-daemon-m22rf   2/2     Running   6          16h

# Get file content
oc rsh -n openshift-machine-config-operator machine-config-daemon-m22rf chroot /rootfs cat /etc/myfile
Defaulted container &#34;machine-config-daemon&#34; out of: machine-config-daemon, oauth-proxy
worker-test</code></pre></div></div><div class=paragraph><p>The file /etc/myfile exists on all nodes and depending on their role the files have a different content.</p></div></div></div><div class=sect1><h2 id=_bind_an_application_to_a_specific_environment>Bind an Application to a Specific Environment</h2><div class=sectionbody><div class=paragraph><p>The following will label the nodes with a specific environment and will deploy an example application, which should only be executed on the appropriate nodes.</p></div><div class="olist arabic"><ol class=arabic><li><p>Let’s label the nodes with <strong>environment=worker-dev</strong> and <strong>environment=worker-test</strong>:</p><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc label node ip-10-0-195-201.us-east-2.compute.internal ip-10-0-199-235.us-east-2.compute.internal environment=worker-dev
oc label node ip-10-0-188-198.us-east-2.compute.internal ip-10-0-191-9.us-east-2.compute.internal environment=worker-test</code></pre></div></div></li><li><p>Create a namespace for the example application</p><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc new-project bookinfo</code></pre></div></div></li><li><p>Create an annotation and a label for the namespace. The annotation will make sure that the application will only be started on nodes with the same label. The label will be later used for the IngressController setup.</p><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc annotate namespace bookinfo environment=worker-dev
oc annotate namespace bookinfo openshift.io/node-selector: environment=worker-test

oc label namespace bookinfo environment=worker-dev</code></pre></div></div></li><li><p>Deploy the example application. In this article the sample application of Istio was used:</p><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc apply -f https://raw.githubusercontent.com/istio/istio/release-1.11/samples/bookinfo/platform/kube/bookinfo.yaml</code></pre></div></div></li></ol></div><div class=paragraph><p>This will start the application on <code>worker-dev`</code> nodes only, because the annotation in the namespace was created accordingly.</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc get pods -n bookinfo -o wide

NAME                             READY   STATUS    RESTARTS   AGE     IP            NODE                                         NOMINATED NODE   READINESS GATES
details-v1-86dfdc4b95-v8zfv      1/1     Running   0          9m19s   10.130.2.17   ip-10-0-199-235.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
productpage-v1-658849bb5-8gcl7   1/1     Running   0          7m17s   10.128.4.21   ip-10-0-195-201.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
ratings-v1-76b8c9cbf9-cc4js      1/1     Running   0          9m19s   10.130.2.19   ip-10-0-199-235.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
reviews-v1-58b8568645-mbgth      1/1     Running   0          7m44s   10.128.4.20   ip-10-0-195-201.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
reviews-v2-5d8f8b6775-qkdmz      1/1     Running   0          9m19s   10.130.2.21   ip-10-0-199-235.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
reviews-v3-666b89cfdf-8zv8w      1/1     Running   0          9m18s   10.130.2.22   ip-10-0-199-235.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;</code></pre></div></div></div></div><div class=sect1><h2 id=_create_dedicated_ingresscontroller>Create Dedicated IngressController</h2><div class=sectionbody><div class=paragraph><p>IngressController are responsible to bring the traffic into the cluster. OpenShift comes with one default controller, but it is possible to create more in order to use different domains and separate the incoming traffic to different nodes.</p></div><div class=paragraph><p>Bind the default ingress controller to the infra labeled nodes, so we can be sure that the default router pods are executed only on these nodes:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc patch ingresscontroller default -n openshift-ingress-operator --type=merge --patch=&#39;{&#34;spec&#34;:{&#34;nodePlacement&#34;:{&#34;nodeSelector&#34;: {&#34;matchLabels&#34;:{&#34;node-role.kubernetes.io/infra&#34;:&#34;&#34;}}}}}&#39;</code></pre></div></div><div class=paragraph><p>The pods will get restarted, to be sure they are running on infra:</p></div><div class=listingblock><div class=content><pre>oc get pods -n openshift-ingress -o wide
NAME                              READY   STATUS              RESTARTS   AGE   IP           NODE                                         NOMINATED NODE   READINESS GATES
router-default-78f8dd6f69-dbtbv   0/1     ContainerCreating   0          2s    &lt;none&gt;       ip-10-0-149-168.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
router-default-78f8dd6f69-wwpgb   0/1     ContainerCreating   0          2s    &lt;none&gt;       ip-10-0-158-44.us-east-2.compute.internal    &lt;none&gt;           &lt;none&gt;
router-default-7bbbc8f9bd-vfh84   1/1     Running             0          22m   10.129.4.6   ip-10-0-158-44.us-east-2.compute.internal    &lt;none&gt;           &lt;none&gt;
router-default-7bbbc8f9bd-wggrx   1/1     Terminating         0          19m   10.128.2.8   ip-10-0-149-168.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;</pre></div></div><div class=paragraph><p>Create the following IngressController objects for <strong>worker-dev</strong> and <strong>worker-test</strong>. Replace with the domain of your choice</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-yaml data-lang=yaml>apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  name: ingress-worker-dev
  namespace: openshift-ingress-operator
spec:
  domain: worker-dev.&lt;yourdomain&gt; <i class=conum data-value=1></i><b>(1)</b>
  endpointPublishingStrategy:
    type: HostNetwork
  httpErrorCodePages:
    name: &#39;&#39;
  namespaceSelector:
    matchLabels:
      environment: worker-dev <i class=conum data-value=2></i><b>(2)</b>
  nodePlacement:
    nodeSelector:
      matchLabels:
        node-role.kubernetes.io/worker-dev: &#39;&#39; <i class=conum data-value=3></i><b>(3)</b>
  replicas: 3
  tuningOptions: {}
  unsupportedConfigOverrides: null
---
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
  name: ingress-worker-test
  namespace: openshift-ingress-operator
spec:
  domain: worker-test.&lt;yourdomain&gt;
  endpointPublishingStrategy:
    type: HostNetwork
  httpErrorCodePages:
    name: &#39;&#39;
  namespaceSelector:
    matchLabels:
      environment: worker-test
  nodePlacement:
    nodeSelector:
      matchLabels:
        node-role.kubernetes.io/worker-test: &#39;&#39;
  replicas: 3
  tuningOptions: {}
  unsupportedConfigOverrides: null</code></pre></div></div><div class="colist arabic"><table><tbody><tr><td><i class=conum data-value=1></i><b>1</b></td><td>Domainname which is used by this Controller</td></tr><tr><td><i class=conum data-value=2></i><b>2</b></td><td>Namespace selector …​ namespaces with such label will be handled by this IngressController</td></tr><tr><td><i class=conum data-value=3></i><b>3</b></td><td>Node Placement …​ This Controller should run on nodes with this label/role</td></tr></tbody></table></div><div class=paragraph><p>This will spin up additional router pods on the collect labelled nodes:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc get pods -n openshift-ingress -o wide

NAME                                         READY   STATUS    RESTARTS   AGE    IP            NODE                                         NOMINATED NODE   READINESS GATES
router-default-78f8dd6f69-dbtbv              1/1     Running   0          8m7s   10.128.2.11   ip-10-0-149-168.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
router-default-78f8dd6f69-wwpgb              1/1     Running   0          8m7s   10.129.4.10   ip-10-0-158-44.us-east-2.compute.internal    &lt;none&gt;           &lt;none&gt;
router-ingress-worker-dev-76b65cf558-mspvb   1/1     Running   0          113s   10.130.2.13   ip-10-0-199-235.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
router-ingress-worker-dev-76b65cf558-p2jpg   1/1     Running   0          113s   10.128.4.12   ip-10-0-195-201.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;
router-ingress-worker-test-6bbf9967f-4whfs   1/1     Running   0          113s   10.131.2.13   ip-10-0-191-9.us-east-2.compute.internal     &lt;none&gt;           &lt;none&gt;
router-ingress-worker-test-6bbf9967f-jht4w   1/1     Running   0          113s   10.131.0.8    ip-10-0-188-198.us-east-2.compute.internal   &lt;none&gt;           &lt;none&gt;</code></pre></div></div></div></div><div class=sect1><h2 id=_verify_ingress_configuration>Verify Ingress Configuration</h2><div class=sectionbody><div class=paragraph><p>To test our new ingress router lets create a route object for our example application:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-yaml data-lang=yaml>kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: productpage
  namespace: bookinfo
spec:
  host: productpage-bookinfo.worker-dev.&lt;yourdomain&gt;
  to:
    kind: Service
    name: productpage
    weight: 100
  port:
    targetPort: http
  wildcardPolicy: None
---
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: productpage-worker-test
  namespace: bookinfo
spec:
  host: productpage-bookinfo.worker-test.&lt;yourdomain&gt;
  to:
    kind: Service
    name: productpage
    weight: 100
  port:
    targetPort: http
  wildcardPolicy: None</code></pre></div></div><div class="admonitionblock warning"><table><tbody><tr><td class=icon><i class="fa icon-warning" title=Warning></i></td><td class=content>Be sure that the name is resolvable and a load balancer is configured accordingly</td></tr></tbody></table></div><div class=paragraph><p>Verify that the router pod has the correct configuration in the file <strong>haproxy.config</strong> :</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc get pods -n openshift-ingress
NAME                                         READY   STATUS    RESTARTS   AGE
router-default-78f8dd6f69-dbtbv              1/1     Running   0          95m
router-default-78f8dd6f69-wwpgb              1/1     Running   0          95m
router-ingress-worker-dev-76b65cf558-mspvb   1/1     Running   0          88m
router-ingress-worker-dev-76b65cf558-p2jpg   1/1     Running   0          88m
router-ingress-worker-test-6bbf9967f-4whfs   1/1     Running   0          88m
router-ingress-worker-test-6bbf9967f-jht4w   1/1     Running   0          88m</code></pre></div></div><div class=paragraph><p>Verify the content of the haproxy configuration for one of the <code>worker-dev</code> router</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc rsh -n openshift-ingress router-ingress-worker-dev-76b65cf558-mspvb cat haproxy.config | grep productpage

backend be_http:bookinfo:productpage
  server pod:productpage-v1-658849bb5-8gcl7:productpage:http:10.128.4.21:9080 10.128.4.21:9080 cookie 3758caf21badd7e4f729209173eece08 weight 256</code></pre></div></div><div class=paragraph><p>Compare with <code>worker-test</code> router</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc rsh -n openshift-ingress router-ingress-worker-test-6bbf9967f-jht4w cat haproxy.config | grep productpage

--&gt; Empty result, this router is not configured with that route.</code></pre></div></div><div class=paragraph><p>Compare with <code>default</code> router:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>backend be_http:bookinfo:productpage
  server pod:productpage-v1-658849bb5-8gcl7:productpage:http:10.128.4.21:9080 10.128.4.21:9080 cookie 3758caf21badd7e4f729209173eece08 weight 256</code></pre></div></div><div class=paragraph><p>Why does this happen? Why are the default router and the router for worker-dev configured?
This happens because it is the default router and we must explicitly tell it to ignore certain labels.</p></div><div class=paragraph><p>Modify the default IngressController</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc edit ingresscontroller.operator default -n openshift-ingress-operator</code></pre></div></div><div class=paragraph><p>Add the following</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-yaml data-lang=yaml>  namespaceSelector:
    matchExpressions:
      - key: environment
        operator: NotIn
        values:
          - worker-dev
          - worker-test</code></pre></div></div><div class=paragraph><p>This will tell the default IngressController to ignore selectors on <code>worker-dev</code> and <code>worker-test</code></p></div><div class=paragraph><p>Wait a few seconds until the route pods have been restarted:</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc get pods -n openshift-ingress
NAME                                         READY   STATUS    RESTARTS   AGE
router-default-744998df46-8lh4t              1/1     Running   0          2m32s
router-default-744998df46-hztgf              1/1     Running   0          2m31s
router-ingress-worker-dev-76b65cf558-mspvb   1/1     Running   0          96m
router-ingress-worker-dev-76b65cf558-p2jpg   1/1     Running   0          96m
router-ingress-worker-test-6bbf9967f-4whfs   1/1     Running   0          96m
router-ingress-worker-test-6bbf9967f-jht4w   1/1     Running   0          96m</code></pre></div></div><div class=paragraph><p>And test again</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc rsh -n openshift-ingress router-default-744998df46-8lh4t cat haproxy.config | grep productpage
--&gt; empty result</code></pre></div></div><div class="admonitionblock caution"><table><tbody><tr><td class=icon><i class="fa icon-caution" title=Caution></i></td><td class=content>At this point the new router feels responsible. Be sure to have a load balancer configured correctly.</td></tr></tbody></table></div></div></div><div class=sect1><h2 id=_appendix>Appendix</h2><div class=sectionbody><div class=paragraph><p>Bind other infra-workload to infrastructure nodes:</p></div><div class=sect2><h3 id=_internal_registry>Internal Registry</h3><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc patch configs.imageregistry.operator.openshift.io/cluster -n openshift-image-registry --type=merge --patch &#39;{&#34;spec&#34;:{&#34;nodeSelector&#34;:{&#34;node-role.kubernetes.io/infra&#34;:&#34;&#34;}}}&#39;</code></pre></div></div></div><div class=sect2><h3 id=_openshift_monitoring_workload>OpenShift Monitoring Workload</h3><div class=paragraph><p>Create the following file and apply it.</p></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>cat &lt;&lt;&#39;EOF&#39; &gt; cluster-monitoring-config-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |+
    alertmanagerMain:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
    prometheusK8s:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
    prometheusOperator:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
    grafana:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
    k8sPrometheusAdapter:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
    kubeStateMetrics:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
    telemeterClient:
      nodeSelector:
        node-role.kubernetes.io/infra: &#34;&#34;
EOF</code></pre></div></div><div class=listingblock><div class=content><pre class=highlight><code class=language-bash data-lang=bash>oc create -f cluster-monitoring-config-cm.yaml</code></pre></div></div></div></div></div><footer class=footline></footer></div></div><div id=navigation-bottom><a class="nav-prev btn btn-default" href=/day-2/labels_environmets/ title="Labels & Environments"><i class="fa fa-chevron-left btn-bottom-prev"></i><span class=btn-bottom-text>Previous:</span> Labels & Environments</a>
<a class="nav-next btn btn-default" href=/day-2/pod-placement/ title="Pod Placement" style=margin-right:0><i class="fa fa-chevron-right btn-bottom-next"></i><span class=btn-bottom-text>Next:</span> Pod Placement</a></div><div class=copyright><p>Copyright &copy; 2020 - 2022 Toni Schmidbauer & Thomas Jungbauer</p><p>Built with <a href=https://github.com/matcornic/hugo-theme-learn target=_blank rel="noopener noreferrer">Hugo Learn Theme</i></a> and <a href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a></p></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=/js/clipboard.min.js?1661575544></script>
<script src=/js/perfect-scrollbar.min.js?1661575544></script>
<script src=/js/perfect-scrollbar.jquery.min.js?1661575544></script>
<script src=/js/jquery.sticky.js?1661575544></script>
<script src=/js/featherlight.min.js?1661575544></script>
<script src=/js/highlight.pack.js?1661575544></script>
<script>hljs.initHighlightingOnLoad()</script><script src=/js/modernizr.custom-3.6.0.js?1661575544></script>
<script src=/js/learn.js?1661575544></script>
<script src=/js/hugo-learn.js?1661575544></script>
<script src=/js/yaub.js?1661575544></script>
<script>window.addEventListener("DOMContentLoaded",()=>{const e=new IntersectionObserver(e=>{e.forEach(e=>{const t=e.target.getAttribute("id");e.intersectionRatio>0&&(clearActiveStatesInTableOfContents(),document.querySelector(`aside nav li a[href="#${t}"]`).parentElement.classList.add("active"))})});document.querySelectorAll("h1[id],h2[id],h3[id],h4[id]").forEach(t=>{e.observe(t)})});function clearActiveStatesInTableOfContents(){document.querySelectorAll("aside nav li").forEach(e=>{e.classList.remove("active")})}</script><script type=text/javascript>function scrollTopAnimated(){$("html, body").animate({scrollTop:"0"},500)}</script><script>function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}$(".summary-box").click(function(){return window.location=$(this).find("a").attr("href"),!1})</script><script>const btn=document.querySelector(".btn-toggle"),prefersDarkScheme=window.matchMedia("(prefers-color-scheme: dark)"),currentTheme=localStorage.getItem("theme");currentTheme=="dark"?document.body.classList.toggle("dark-theme"):currentTheme=="light"&&document.body.classList.toggle("light-theme"),btn.addEventListener("click",function(){if(prefersDarkScheme.matches){document.body.classList.toggle("light-theme");var e=document.body.classList.contains("light-theme")?"light":"dark"}else document.body.classList.toggle("dark-theme"),e=document.body.classList.contains("dark-theme")?"dark":"light";localStorage.setItem("theme",e)})</script></body></html>