<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>YAUB Yet Another Useless Blog on TechBlog about OpenShift/Ansible/Satellite and much more</title><link>https://blog.stderr.at/</link><description>Recent content in YAUB Yet Another Useless Blog on TechBlog about OpenShift/Ansible/Satellite and much more</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Toni Schmidbauer &amp; Thomas Jungbauer</copyright><atom:link href="https://blog.stderr.at/index.xml" rel="self" type="application/rss+xml"/><item><title>Ansible Tower and downloading collections</title><link>https://blog.stderr.at/ansible/2021/07/ansible-tower-and-downloading-collections/</link><pubDate>Sat, 31 Jul 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/ansible/2021/07/ansible-tower-and-downloading-collections/</guid><description>Every wondered why Ansible Tower does not start downloading required collections when you synchronize a project? Here are the stumbling blocks we discovered so far:
Wrong name for requirements.yml When downloading collections Ansible Tower searches for a file requirements.yml in the collections directory.
Be careful with the file extension: requirements.yml has to end with the extension .yml and not .yaml.
Collections download is disabled in Ansible Tower Within Ansible Tower there is a setting called ENABLE COLLECTION(S) DOWNLOAD under Settings/Jobs.</description></item><item><title>oc compliance command line plugin</title><link>https://blog.stderr.at/compliance/2021/07/oc-compliance-command-line-plugin/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/compliance/2021/07/oc-compliance-command-line-plugin/</guid><description>&lt;div class="paragraph">
&lt;p>As described at &lt;a href="https://blog.stderr.at/compliance/2021/07/compliance-operator/">Compliance Operator&lt;/a> the Compliance Operator can be used to scan the OpenShift cluster environment against security benchmark, like CIS.
Fetching the actual results might be a bit tricky tough.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With OpenShift 4.8 plugins to the &lt;code>oc&lt;/code> command are allowed. One of these plugin os &lt;code>oc compliance&lt;/code>, which allows you to easily fetch scan results, re-run scans and so on.
Let’s install and try it out.&lt;/p>
&lt;/div></description></item><item><title>Compliance Operator</title><link>https://blog.stderr.at/compliance/2021/07/compliance-operator/</link><pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/compliance/2021/07/compliance-operator/</guid><description>&lt;div class="paragraph">
&lt;p>OpenShift comes out of the box with a highly secure operating system, called Red Hat CoreOS. This OS is immutable, which means that no direct changes are done inside the OS, instead any configuration is managed by OpenShift itself using MachineConfig objects. Nevertheless, hardening certain settings must still be considered. Red Hat released a hardening guide (CIS Benchmark) which can be downloaded at &lt;a href="https://www.cisecurity.org/" class="bare">https://www.cisecurity.org/&lt;/a>.&lt;/p>
&lt;/div></description></item><item><title>Understanding RWO block device handling in OpenShift</title><link>https://blog.stderr.at/openshift/2021-02-27-understanding-block-devices/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021-02-27-understanding-block-devices/</guid><description>&lt;div class="paragraph">
&lt;p>In this blog post we would like to explore OpenShift / Kubernetes
block device handling. We try to answer the following questions:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>What happens if multiple pods try to access the same block device?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What happens if we scale a deployment using block devices to more than one replica?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div></description></item><item><title>Writing Operator using Ansible</title><link>https://blog.stderr.at/openshift/2021-01-27-writingoperatoransible/</link><pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021-01-27-writingoperatoransible/</guid><description>&lt;div class="paragraph">
&lt;p>This quick post shall explain, without any fancy details, how to write an Operator based on Ansible. It is assumed that you know what purpose an Operator has.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a short summary: Operators are a way to create custom controllers in OpenShift or Kubernetes. It watches for custom resource objects and creates the application based on the parameters in such custom resource object.
Often written in &lt;strong>Go&lt;/strong>, the SDK supports &lt;strong>Ansible&lt;/strong>, &lt;strong>Helm&lt;/strong> and (new) &lt;strong>Java&lt;/strong> as well.&lt;/p>
&lt;/div></description></item><item><title>Thanos Querier vs Thanos Querier</title><link>https://blog.stderr.at/openshift/2020-12-10-thanos-vs-thanos/</link><pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2020-12-10-thanos-vs-thanos/</guid><description>&lt;div class="paragraph">
&lt;p>OpenShift comes per default with a static Grafana dashboard, which will present cluster metrics to cluster administrators. It is not possible to customize this Grafana instance.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>However, many customers would like to create their own dashboards, their own monitoring and their own alerting while leveraging the possibilities of OpenShift at the same time and without installing a completely separated monitoring stack.&lt;/p>
&lt;/div></description></item><item><title>GitOps - Argo CD</title><link>https://blog.stderr.at/openshift/2020-08-06-argocd/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2020-08-06-argocd/</guid><description>&lt;div class="paragraph">
&lt;p>&lt;a href="https://argoproj.github.io/argo-cd/">Argo CD&lt;/a> &lt;em>is a declarative, GitOps continuous delivery tool for Kubernetes. GitOps itself uses Git pull request to manager infrastructure and application configuration.&lt;/em>&lt;/p>
&lt;/div></description></item><item><title>Enable Automatic Route Creation</title><link>https://blog.stderr.at/service-mesh/2020/05/enable-automatic-route-creation/</link><pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/05/enable-automatic-route-creation/</guid><description>&lt;div class="paragraph">
&lt;p>Red Hat Service Mesh 1.1 allows you to enable a &amp;#34;&lt;strong>Automatic Route Creation&lt;/strong>&amp;#34; which will take care about the routes for a specific Gateway. Instead of defining * for hosts, a list of domains can be defined. The Istio OpenShift Routing (ior) synchronizes the routes and creates them inside the Istio namespace. If a Gateway is deleted, the routes will also be removed again.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This new features makes the manual creation of the route obsolete, as it was explained here: &lt;a href="https://blog.stderr.at/service-mesh/2020/03/ingress-with-custom-domain/">Openshift 4 and Service Mesh 4 - Ingress with custom domain&lt;/a>&lt;/p>
&lt;/div></description></item><item><title>Red Hat Quay Registry - Overview and Installation</title><link>https://blog.stderr.at/openshift/2020-05-13-quay-tutorial1/</link><pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2020-05-13-quay-tutorial1/</guid><description>&lt;div class="paragraph">
&lt;p>Red Hat Quay is an enterprise-quality container registry, which is responsible to build, scan, store and deploy containers.
The main features of Quay include:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>High Availability&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Security Scanning (with Clair)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Registry mirroring&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Docker v2&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Continuous integration&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>and much more.&lt;/p>
&lt;/div></description></item><item><title>Authorization (RBAC)</title><link>https://blog.stderr.at/service-mesh/2020/05/authorization-rbac/</link><pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/05/authorization-rbac/</guid><description>&lt;div class="paragraph">
&lt;p>Per default all requests inside a Service Mesh are allowed, which can be a problem security-wise.
To solve this, authorization, which verifies if the user is allowed to perform a certain action, is required.
Istio’s authorization provides access control on mesh-level, namespace-level and workload-level.&lt;/p>
&lt;/div></description></item><item><title>Basic usage of git</title><link>https://blog.stderr.at/general/2020/05/basic-usage-of-git/</link><pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/general/2020/05/basic-usage-of-git/</guid><description>&lt;div class="paragraph">
&lt;p>This is a very short and hopefully simple introduction on how to use
&lt;a href="https://git-scm.com/">Git&lt;/a> when you would like to contribute to
projects hosted on &lt;a href="http://github.com">github.com&lt;/a>. The same workflow should also work for
projects on &lt;a href="http://gitlab.com">gitlab.com&lt;/a>.&lt;/p>
&lt;/div></description></item><item><title>Deploy Example Bookinfo Application</title><link>https://blog.stderr.at/service-mesh/2020/04/deploy-example-bookinfo-application/</link><pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/04/deploy-example-bookinfo-application/</guid><description>&lt;div class="paragraph">
&lt;p>To test a second application, a bookinfo application shall be deployed as an example.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following section finds it’s origin at:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://istio.io/docs/examples/bookinfo/" target="_blank" rel="noopener">Istio - Bookinfo Application&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://docs.openshift.com/container-platform/4.3/service_mesh/service_mesh_day_two/ossm-example-bookinfo.html" target="_blank" rel="noopener">OpenShift 4 - Example Application&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div></description></item><item><title>Ansible - Azure Resource Manager Example</title><link>https://blog.stderr.at/ansible/2020/04/ansible-azure-resource-manager-example/</link><pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/ansible/2020/04/ansible-azure-resource-manager-example/</guid><description>&lt;div class="paragraph">
&lt;p>Using Ansible Resource Manager with an ARM template and a simple Ansible playbook to deploy a Virtual Machine with Disk, virtual network, public IP and so on.&lt;/p>
&lt;/div></description></item><item><title>OpenShift Pipelines - Tekton Introduction</title><link>https://blog.stderr.at/openshift/2020-04-16-tekton/</link><pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2020-04-16-tekton/</guid><description>&lt;div class="paragraph">
&lt;p>&lt;em>OpenShift Pipelines is a cloud-native, continuous integration and delivery (CI/CD) solution for building pipelines using Tekton. Tekton is a flexible, Kubernetes-native, open-source CI/CD framework that enables automating deployments across multiple platforms (Kubernetes, serverless, VMs, etc) by abstracting away the underlying details.&lt;/em> [&lt;a href="#source_1">1&lt;/a>]&lt;/p>
&lt;/div></description></item><item><title>Red Hat Satellite Cheat Sheet</title><link>https://blog.stderr.at/general/2020/04/red-hat-satellite-cheat-sheet/</link><pubDate>Wed, 15 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/general/2020/04/red-hat-satellite-cheat-sheet/</guid><description>&lt;div class="paragraph">
&lt;p>Cheat sheet for various Red Hat Satellite tasks from a newbie to a newbie.&lt;/p>
&lt;/div></description></item><item><title>Service Mesh 1.1 released</title><link>https://blog.stderr.at/service-mesh/2020/04/service-mesh-1.1-released/</link><pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/04/service-mesh-1.1-released/</guid><description>&lt;div class="paragraph">
&lt;p>April 10th 2020 Red Hat released Service Mesh version 1.1 which supports the following versions:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Istio - 1.4.6&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kiali - 1.12.7&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Jaeger - 1.17.1&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div></description></item><item><title>Authentication JWT</title><link>https://blog.stderr.at/service-mesh/2020/04/authentication-jwt/</link><pubDate>Thu, 09 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/04/authentication-jwt/</guid><description>&lt;div class="paragraph">
&lt;p>Welcome to tutorial 10 of &lt;strong>OpenShift 4 and Service Mesh&lt;/strong>, where we will discuss authentication with JWT.
JSON Web Token (JWT) is an open standard that allows to transmit information between two parties securely as a JSON object. It is an authentication token, which is verified and signed and therefore trusted. The signing can be achieved by using a secret or a public/private key pair.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Service Mesh can be used to configure a policy which enables JWT for your services.&lt;/p>
&lt;/div></description></item><item><title>Mutual TLS Authentication</title><link>https://blog.stderr.at/service-mesh/2020/04/mutual-tls-authentication/</link><pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/04/mutual-tls-authentication/</guid><description>&lt;div class="paragraph">
&lt;p>When more and more microservices are involved in an application, more and more traffic is sent on the network. It should be considered to secure this traffic, to prevent the possibility to inject malicious packets. Mutual TLS/mTLS authentication or two-way authentication offers a way to encrypt service traffic with certificates.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With Red Hat OpenShift Service Mesh, Mutual TLS can be used without the microservice knowing that it is happening. The TLS is managed completely by the Service Mesh Operator between two Envoy proxies using a defined mTLS policy.&lt;/p>
&lt;/div></description></item><item><title>Fault Injection</title><link>https://blog.stderr.at/service-mesh/2020/04/fault-injection/</link><pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/service-mesh/2020/04/fault-injection/</guid><description>&lt;div class="paragraph">
&lt;p>Tutorial 8 of &lt;strong>OpenShift 4 and Service Mesh&lt;/strong> tries to cover Fault Injection by using Chaos testing method to verify if your application is running. This is done by adding the property HTTPFaultInjection to the VirtualService. The settings for this property can be for example: delay, to delay the access or abort, to completely abort the connection.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&amp;#34;&lt;em>Adopting microservices often means more dependencies, and more services you might not control. It also means more requests on the network, increasing the possibility for errors. For these reasons, it’s important to test your services’ behavior when upstream dependencies fail.&amp;#34;&lt;/em> [&lt;a href="#source_1">1&lt;/a>]&lt;/p>
&lt;/div></description></item><item><title>DO410 Ansible and Ansible Tower training notes</title><link>https://blog.stderr.at/ansible/2020/04/do410-ansible-and-ansible-tower-training-notes/</link><pubDate>Mon, 06 Apr 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/ansible/2020/04/do410-ansible-and-ansible-tower-training-notes/</guid><description>&lt;div class="paragraph">
&lt;p>Notes taken during Red Hat course D410 Ansible and Ansible Tower.&lt;/p>
&lt;/div></description></item></channel></rss>