<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>OpenShift on TechBlog about OpenShift/Ansible/Satellite and much more</title><link>https://blog.stderr.at/openshift/</link><description>TechBlog about OpenShift/Ansible/Satellite and much more</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Toni Schmidbauer &amp; Thomas Jungbauer</copyright><atom:link href="https://blog.stderr.at/openshift/index.xml" rel="self" type="application/rss+xml"/><item><title>A second look into the Kubernetes Gateway API on OpenShift</title><link>https://blog.stderr.at/openshift/2025/08/a-second-look-into-the-kubernetes-gateway-api-on-openshift/</link><pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/08/a-second-look-into-the-kubernetes-gateway-api-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>This is our second look into the Kubernetes Gateway API an it’s
integration into OpenShift. This post covers TLS configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Kubernetes Gateway API is new implementation of the ingress, load
balancing and service mesh API’s. See
&lt;a href="https://gateway-api.sigs.k8s.io/" target="_blank" rel="noopener">upstream&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-overview_ingress-gateway-api" target="_blank" rel="noopener">OpenShift documentation&lt;/a> provides an overview of the Gateway API and it’s integration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We demonstrate how to add TLS to our Nginx deployment, how to
implement a shared Gateway and finally how to implement HTTP to HTTPS
redirection with the Gateway API. Furthermore we cover how &lt;em>HTTPRoute&lt;/em>
objects attach to Gateways and dive into ordering of &lt;em>HTTPRoute&lt;/em>
objects.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_references">References&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;a href="https://blog.stderr.at/openshift/2025/08/gateway-api/">A first look into the Kubernetes Gateway API on OpenShift&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adding_tls_to_our_nginx_deployment">Adding TLS to our Nginx deployment&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In our fist post we simply exposed a Nginx web server via the
Gateway API. We only enabled HTTP, so let’s try to do the same with
HTTPS now.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Remember we use a DNS wildcard domain &lt;code>*.gtw.ocp.lan.stderr.at&lt;/code> which
points to our Gateway. The gateway is exposed via a &lt;em>Service&lt;/em> of type
&lt;em>LoadBalancer&lt;/em>. We use
&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/networking_operators/metallb-operator">MetalLB&lt;/a>
for this.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The first step is setting up a wildcard TLS certificate for our custom
domain &lt;em>*.gtw.ocp.lan.stderr.at&lt;/em>. We are using
&lt;a href="https://github.com/OpenVPN/easy-rsa">EasyRSA&lt;/a> here, but use whatever tool you like.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Just for reference this is how we created a wildcard cert with EasyRSA:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ EASYRSA_CERT_EXPIRE=3650 EASYRSA_EXTRA_EXTS=&amp;#34;subjectAltName=DNS:*.gtw.ocp.lan.stderr.at&amp;#34; ./easyrsa gen-req gtw.ocp.lan.stderr.at
$ EASYRSA_CERT_EXPIRE=3650 ./easyrsa sign-req serverClient gtw.ocp.lan.stderr.at&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>EasyRSA stores the public key under &lt;em>pki/issued&lt;/em> and the private key
under &lt;em>pki/private&lt;/em>. We copied the certificate and the private key to
a temporary directory.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we need to remove the private key passphrase and create a
Kubernetes secret from the private and pubic key:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ openssl rsa -in gtw.ocp.lan.stderr.at.key -out gtw.ocp.lan.stderr.at-insecure.key
$ oc create secret -n openshift-ingress tls gateway-api --cert=gtw.ocp.lan.stderr.at.crt --key=gtw.ocp.lan.stderr.at-insecure.key&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now it’s time to add a TLS listener to our &lt;em>Gateway&lt;/em> resource in the
&lt;em>openshift-ingress&lt;/em> namespace. Remember for the OpenShift Gateway API implementation, &lt;em>Gateways&lt;/em> have
to be deployed in the &lt;em>openshift-ingress&lt;/em> namespace.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
- name: https
protocol: HTTPS &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
port: 443 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
tls:
mode: Terminate &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
certificateRefs:
- name: gateway-api &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
allowedRoutes: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
namespaces:
from: All&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We want to support HTTPS&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>We use the default HTTPS port 443&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The URLs we support with this listener are the same as for HTTP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>We use edge termination for now, this means HTTP traffic will only be encrypted up to the gateway. From the gateway to our pod we speak plain HTTP.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>This is the name of the TLS secret we created above&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>We accept routes from all namespaces&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Also remember from our first post that we created a
&lt;em>ReferenceGrant&lt;/em> in the namespace where Nginx is running. Otherwise
HTTP routes will not be accepted.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally lets try to access our Nginx pod via HTTPS:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -v https://nginx.gtw.ocp.lan.stderr.at
* Host nginx.gtw.ocp.lan.stderr.at:443 was resolved.
* IPv6: (none)
* IPv4: 10.0.0.150
* Trying 10.0.0.150:443...
* ALPN: curl offers h2,http/1.1
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* CAfile: /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem
* CApath: none
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):
* TLSv1.3 (IN), TLS handshake, Certificate (11):
* TLSv1.3 (IN), TLS handshake, CERT verify (15):
* TLSv1.3 (IN), TLS handshake, Finished (20):
* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.3 (OUT), TLS handshake, Finished (20):
* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 / x25519 / RSASSA-PSS
* ALPN: server accepted h2
* Server certificate:
* subject: CN=gtw.ocp.lan.stderr.at
* start date: Aug 30 10:01:33 2025 GMT
* expire date: Aug 28 10:01:33 2035 GMT
* subjectAltName: host &amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34; matched cert&amp;#39;s &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
* issuer: CN=tntinfra CA
* SSL certificate verify ok.
* Certificate level 0: Public key type RSA (2048/112 Bits/secBits), signed using sha256WithRSAEncryption
* Certificate level 1: Public key type RSA (2048/112 Bits/secBits), signed using sha256WithRSAEncryption
* Connected to nginx.gtw.ocp.lan.stderr.at (10.0.0.150) port 443
* using HTTP/2
* [HTTP/2] [1] OPENED stream for https://nginx.gtw.ocp.lan.stderr.at/
* [HTTP/2] [1] [:method: GET]
* [HTTP/2] [1] [:scheme: https]
* [HTTP/2] [1] [:authority: nginx.gtw.ocp.lan.stderr.at]
* [HTTP/2] [1] [:path: /]
* [HTTP/2] [1] [user-agent: curl/8.11.1]
* [HTTP/2] [1] [accept: */*]
&amp;gt; GET / HTTP/2
&amp;gt; Host: nginx.gtw.ocp.lan.stderr.at
&amp;gt; User-Agent: curl/8.11.1
&amp;gt; Accept: */*
&amp;gt;
* Request completely sent off
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
&amp;lt; HTTP/2 200
&amp;lt; server: nginx/1.29.1
&amp;lt; date: Sat, 30 Aug 2025 14:30:20 GMT
&amp;lt; content-type: text/html
&amp;lt; content-length: 615
&amp;lt; last-modified: Wed, 13 Aug 2025 14:33:41 GMT
&amp;lt; etag: &amp;#34;689ca245-267&amp;#34;
&amp;lt; accept-ranges: bytes
(output omitted)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Yes, we can reach our Nginx via HTTPS, and the gateway presents the TLS certificate we created.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be aware that we are still using the same &lt;em>HTTPRoute&lt;/em> for Nginx from our previous blog post.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Just for completeness here is the &lt;em>HTTPRoute&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Also Remember that we are using a dedicated &lt;em>Gateway&lt;/em> and all
&lt;em>HTTPRoutes&lt;/em> must be in the namespace &lt;em>openshift-ingress&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_moving_to_a_shared_gateway">Moving to a shared gateway&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Up until now we had to create all &lt;em>HTTPRoute&lt;/em> objects in the
&lt;em>openshift-ingress&lt;/em> namespace. The Gateway API support two modes of
operations:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Dedicated gateway: all &lt;em>HTTPRoute&lt;/em> object need to be in the same namespace as the gateway&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Shared gateway: The gateway runs in the &lt;em>openshift-ingress&lt;/em>
namespace and we allow &lt;em>HTTPRoute&lt;/em> objects from all or specific namespaces.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The first step in creating a shared gateway is to modify the gateway resource:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
allowedRoutes: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespaces:
from: All&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We now allow &lt;em>HTTPRoute&lt;/em> objects from all namespaces in the cluster&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we delete the existing &lt;em>HTTPRoute&lt;/em> for Nginx in the
&lt;em>openshift-ingress&lt;/em> namespaces, and verify that we can’t reach Nginx:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc delete httproutes.gateway.networking.k8s.io -n openshift-ingress nginx-route
httproute.gateway.networking.k8s.io &amp;#34;nginx-route&amp;#34; deleted
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 404 Not Found &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
date: Sat, 30 Aug 2025 15:02:23 GMT
transfer-encoding: chunked&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Our Nginx route stopped working&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we apply our modified &lt;em>Gateway&lt;/em> resource in the
&lt;em>openshift-ingress&lt;/em> namespace and the &lt;em>HTTPRoute&lt;/em> object in the
&lt;em>gateway-api-test&lt;/em> namespace.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -n openshift-ingress -f gateway--selector.yaml
gateway.gateway.networking.k8s.io/http-gateway configured
$ oc apply -n gateway-api-test -f httproute.yaml &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
httproute.gateway.networking.k8s.io/nginx-route created
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
server: nginx/1.29.1
date: Sat, 30 Aug 2025 15:04:34 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We create the &lt;em>HTTPRoute&lt;/em> in the gateway-api-test namespace&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>We can reach our Nginx pod again&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So our shared gateway seems to be working. But what if we want to
restrict which namespaces are allowed to create route objects?&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Gateway API allows the following settings under &lt;em>spec.listeners[].allowedRoutes.namespaces.from&lt;/em> field&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>All&lt;/strong>: Allow from all namespaces&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Selector&lt;/strong>: Specify a selector&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Same&lt;/strong>: Only allow &lt;em>HTTPRoutes&lt;/em> in the same namespaces&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>None&lt;/strong>: Do not allow any routes to attach&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>See the API specification &lt;a href="https://gateway-api.sigs.k8s.io/reference/spec/#fromnamespaces">FromNamespaces&lt;/a> for details.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try to use a more specific selector for our gateway:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
allowedRoutes:
namespaces:
from: Selector &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
selector:
matchLabels:
kubernetes.io/metadata.name: gateway-api-test &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Now we are using the Selector option&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Because we do not have a specific label on the namespace we would like to use, let’s use the &lt;em>metadata.name&lt;/em> label Kubernetes created for us&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We create a new yaml file &lt;em>gateway-selector.yaml&lt;/em> and appy the new configuration:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -n openshift-ingress -f gateway-selector.yaml
gateway.gateway.networking.k8s.io/http-gateway configured
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK
server: nginx/1.29.1
date: Sat, 30 Aug 2025 15:17:17 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>All good, still working.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Just for testing we modified the namespace name in the Gateway definition to &lt;strong>NOT&lt;/strong> match the namespace of our Nginx deployment and confirmed that we receive a &lt;em>404&lt;/em> not found response.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_implementing_http_to_https_redirect">Implementing HTTP to HTTPS redirect&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As a last test for this post let’s try to implement HTTP to HTTPS redirects.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We deployed the following &lt;em>Gateway&lt;/em> configuration:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
allowedRoutes:
namespaces:
from: Selector
selector:
matchLabels:
kubernetes.io/metadata.name: gateway-api-test2
- name: https &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
protocol: HTTPS
port: 443
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34;
tls:
mode: Terminate
certificateRefs:
- name: gateway-api
allowedRoutes:
namespaces:
from: All&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Always deploy the gateway to the &lt;em>openshift-ingress&lt;/em> namespace for the OpenShift Gateway API implementation&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>We added the HTTPS configuration back&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;a href="https://gateway-api.sigs.k8s.io/guides/http-redirect-rewrite/">upstream&lt;/a> documentation contains an example on how to implements HTTP to HTTPS redirects. We created the following additional &lt;em>HTTPRoute&lt;/em> object in the &lt;em>gateway-api-test&lt;/em> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: http-https-redirect
spec:
parentRefs:
- name: http-gateway &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: openshift-ingress
sectionName: http &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
hostnames:
- nginx.gtw.ocp.lan.stderr.at
rules:
- filters:
- type: RequestRedirect
requestRedirect:
scheme: https
statusCode: 301&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Match our &lt;em>Gateway&lt;/em> &lt;em>http-gateway&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Match the &lt;em>http&lt;/em> section in our gateway&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Just for reference this is the &lt;em>HTTPRoute&lt;/em> object to expose Nginx:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First we re-applied our &lt;em>Gateway&lt;/em> configuration&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f gateway-https-selector.yaml
gateway.gateway.networking.k8s.io/http-gateway configured&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try and verify if our redirect is working, we need to apply both routes:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f httproute.yaml
httproute.gateway.networking.k8s.io/nginx-route created
$ oc apply -f http-https-redirect-route.yaml
httproute.gateway.networking.k8s.io/http-https-redirect created&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And test with curl:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
server: nginx/1.29.1
date: Sat, 30 Aug 2025 15:37:20 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Hm, strange we still get 200 OK and &lt;strong>NOT&lt;/strong> a redirect to HTTPS&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_understanding_httproute_ordering">Understanding HTTPRoute ordering&lt;/h3>
&lt;div class="paragraph">
&lt;p>After a longer search through the documentation we found some hints on why this is happening.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s take a more detailed look at our http-to-https route again, as a
&lt;em>HTTPRoute&lt;/em> &lt;strong>attaches&lt;/strong> to a &lt;em>Gateway&lt;/em>, we focus on the &lt;em>parentRefs&lt;/em> in
the &lt;em>HTTPRoute&lt;/em> object. In our current understanding &lt;em>parentRefs&lt;/em> select a &lt;em>Gateway&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: http-https-redirect
spec:
parentRefs: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- name: http-gateway &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
namespace: openshift-ingress &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
sectionName: http &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
hostnames:
- nginx.gtw.ocp.lan.stderr.at
rules:
- filters:
- type: RequestRedirect
requestRedirect:
scheme: https
statusCode: 301&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Ok, this is the &lt;em>parentRefs&lt;/em> section we are looking for&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>&lt;em>name&lt;/em> selects the name of the &lt;em>Gateway&lt;/em> we want to attach to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>&lt;em>namespace&lt;/em> specifies the namespace where we can find the &lt;em>Gateway&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>&lt;em>sectionName&lt;/em> selects the section in the &lt;em>Gateway&lt;/em> where we want to attach to.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So this &lt;em>HTTPRoute&lt;/em> explicitly attaches to a &lt;em>Gateway&lt;/em> in a
&lt;em>Namespace&lt;/em> that has a &lt;em>Section&lt;/em> http defined.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you look at the Gateway configuration above you will see that we
have a section for HTTP traffic and one for HTTPS traffic.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s compare this with our Nginx &lt;em>HTTPRoute&lt;/em> definition:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- name: http-gateway &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
namespace: openshift-ingress &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The &lt;em>parentRefs&lt;/em> section&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The &lt;em>Gateway&lt;/em> we would like to attach to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The &lt;em>namespace&lt;/em> where the &lt;em>Gateway&lt;/em> is deploy&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Note that &lt;em>Section&lt;/em> is missing in this configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So this &lt;em>HTTPRoute&lt;/em> actually attaches to &lt;strong>both&lt;/strong> sections in our
&lt;em>Gateway&lt;/em> definition, HTTP and HTTPS. Which is not what we want.&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>When a client hits the HTTP endpoint we want to redirect the traffic to HTTPS&lt;/p>
&lt;/li>
&lt;li>
&lt;p>When a client hits the HTTPS endpoint we want the traffic to be forward to our Nginx deployment&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We found the following statement
&lt;a href="https://gateway-api.sigs.k8s.io/reference/spec/#httprouterule">statement&lt;/a>
how ordering works in the Gateway API:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre>If ties still exist across multiple Routes, matching precedence MUST be
determined in order of the following criteria, continuing on ties:
The oldest Route based on creation timestamp.&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we look at the timestamps of our &lt;em>HTTPRoutes&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">oc get httproute -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.creationTimestamp}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
http-https-redirect 2025-08-31T09:17:46Z &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
nginx-route 2025-08-31T09:17:40Z &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the redirect route&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the nginx route&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Nginx &lt;em>HTTPRoute&lt;/em> is &lt;strong>older&lt;/strong> than the HTTP-to-HTTP &lt;em>HTTPRoute&lt;/em>. So
this matches first and a 200 OK is returned.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s try to revers how we applied our &lt;em>HTTPRoutes&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc delete httproutes.gateway.networking.k8s.io --all
httproute.gateway.networking.k8s.io &amp;#34;http-https-redirect&amp;#34; deleted
httproute.gateway.networking.k8s.io &amp;#34;nginx-route&amp;#34; deleted
$ oc apply -f http-to-https-httproute.yaml
httproute.gateway.networking.k8s.io/http-https-redirect created
$ oc apply -f nginx-httproute.yaml
httproute.gateway.networking.k8s.io/nginx-route created
$ oc get httproute -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.creationTimestamp}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
http-https-redirect 2025-08-31T10:34:55Z &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
nginx-route 2025-08-31T10:35:11Z &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the HTTP-to-HTTPS route&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Creation timestamp of the nginx route&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now the HTTP-to-HTTPS route is the oldest route. Let’s try again calling Nginx with curl:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 301 Moved Permanently &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
location: https://nginx.gtw.ocp.lan.stderr.at/
date: Sun, 31 Aug 2025 10:37:13 GMT
transfer-encoding: chunked
$ curl -I https://nginx.gtw.ocp.lan.stderr.at
HTTP/2 200 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
server: nginx/1.29.1
date: Sun, 31 Aug 2025 10:37:17 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The HTTP endpoint returns a redirect&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>the HTTPS endpoint returns 200 OK from Nginx&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So now we have the expected behavior: HTTP is redirect to HTTPS!&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As depending on the time when an object is created is definitely &lt;strong>NOT&lt;/strong>
a good idea, let’s be more specific in our Nginx &lt;em>HTTPRoute&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
sectionName: https &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We explicitly select the &lt;strong>HTTPS&lt;/strong> section in our &lt;em>Gateway&lt;/em> configuration&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next we delete our &lt;em>HTTPRoutes&lt;/em> again, and re-apply them in the order that didn’t work the first time (Nginx is the oldest route):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc delete httproutes.gateway.networking.k8s.io --all
httproute.gateway.networking.k8s.io &amp;#34;http-https-redirect&amp;#34; deleted
httproute.gateway.networking.k8s.io &amp;#34;nginx-route&amp;#34; deleted
$ oc apply -f http-to-https-httproute.yaml
httproute.gateway.networking.k8s.io/http-https-redirect created
$ oc get httproute -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.creationTimestamp}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
http-https-redirect 2025-08-31T10:45:01Z
nginx-route 2025-08-31T10:44:57Z &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 301 Moved Permanently &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
location: https://nginx.gtw.ocp.lan.stderr.at/
date: Sun, 31 Aug 2025 10:46:22 GMT
transfer-encoding: chunked
$ curl -I https://nginx.gtw.ocp.lan.stderr.at
HTTP/2 200 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
server: nginx/1.29.1
date: Sun, 31 Aug 2025 10:46:30 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The Nginx route is the oldest route&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The HTTP endpoint returns a redirect to HTTPS&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The response from our Nginx deployment&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally everything works as expected!&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
A &lt;em>HTTPRoute&lt;/em> attaches to a &lt;em>Gateway&lt;/em>. Always be as specific as
possible which &lt;em>Gateway&lt;/em> to match and which &lt;em>section&lt;/em> in the
&lt;em>Gateway&lt;/em>.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this blog post we demonstrated to implement TLS with the
Gateway API. We also implemented a shared &lt;em>Gateway&lt;/em> with &lt;em>HTTPRoute&lt;/em>
objects in different namespaces.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Furthermore we configured HTTP to HTTPS redirects and dove into
&lt;em>HTTPRoute&lt;/em> ordering if a route matches multiple listeners in a
&lt;em>Gateway&lt;/em> definition.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>A first look into the Kubernetes Gateway API on OpenShift</title><link>https://blog.stderr.at/openshift/2025/08/a-first-look-into-the-kubernetes-gateway-api-on-openshift/</link><pubDate>Fri, 29 Aug 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/08/a-first-look-into-the-kubernetes-gateway-api-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>This blog post summarizes our first look into the Kubernetes Gateway
API and how it is integrated in OpenShift.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Kubernetes Gateway API is new implementation of the ingress, load
balancing and service mesh API’s. See
&lt;a href="https://gateway-api.sigs.k8s.io/" target="_blank" rel="noopener">upstream&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also the &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-overview_ingress-gateway-api" target="_blank" rel="noopener">OpenShift documentation&lt;/a> provides an overview of the Gateway API and it’s integration.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_things_to_consider_when_using_gateway_api_with_openshift">Things to consider when using Gateway API with OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Currently UDN (User Defined Networks) with Gateway API are not supported.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Only TLS termination on the edge is supported (no pass-through or re-encrypt), this needs to be confirmed. We can’t find the original source of this statement&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The standard OpenShift ingress controller manages Gateway API Resources&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Gateway API provides a standard on how to get client traffic into a
Kubernetes cluster. Vendors provide an implementation of the API. So
OpenShift provides &lt;strong>ONE&lt;/strong> possible implementation, but there could
be more than one in a cluster.&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>We found the following sentence in the OpenShift documentation
interesting:&lt;/p>
&lt;div class="literalblock">
&lt;div class="content">
&lt;pre>Because OpenShift Container Platform uses a specific
version of Gateway API CRDs, any use of third-party implementations
of Gateway API must conform to the OpenShift Container Platform
implementation to ensure that all fields work as expected&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_setting_up_gateway_api_on_openshift">Setting up Gateway API on OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before you begin, ensure you have the following:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.19 or higher with cluster-admin access&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First you need to create a &lt;code>GatewayClass&lt;/code> object.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be aware that the &lt;code>GatewayClass&lt;/code> object is &lt;strong>NOT&lt;/strong> namespaced.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: gateway.networking.k8s.io/v1
kind: GatewayClass
metadata:
name: openshift-default
spec:
controllerName: openshift.io/gateway-controller/v1 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The controller name needs to be exactly as shown. Otherwise the
ingress controller will &lt;strong>NOT&lt;/strong> manage the gateway and associated
resources.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This creates a new pod in the openshift-ingress namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po -n openshift-ingress
NAME READY STATUS RESTARTS AGE
istiod-openshift-gateway-7b567bc8b4-4lrt2 1/1 Running 0 12m &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
router-default-6db958cbd-dlbwz 1/1 Running 12 14d&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>this pod got create after applying the gateway class resource&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;code>router-default&lt;/code> is the default openshift ingress pod. The first
difference seems to be the SCC (security context constraint) the pods
are using.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po -n openshift-ingress -o jsonpath=&amp;#39;{range .items[*]}{.metadata.name}{&amp;#34;\t&amp;#34;}{.metadata.annotations.openshift\.io/scc}{&amp;#34;\n&amp;#34;}{end}&amp;#39;
istiod-openshift-gateway-7b567bc8b4-4lrt2 restricted-v2
router-default-6db958cbd-dlbwz hostnetwork&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The standard router used host networking for listing on port 80 and 443
on the node where it is running. Our &lt;code>GatewayClass&lt;/code> currently only
provides a pod running Istiod awaiting further configuration. To
actually listen for client request additional configuration is
required.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A &lt;code>Gateway&lt;/code> is required to listen for client requests. We create the
following gateway:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.apps.ocp.lan.stderr.at&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We create this gateway in the same namespace as the istio
deployment. This is required for OpenShift.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This creates an additional pod in the &lt;code>openshift-ingress&lt;/code> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po
NAME READY STATUS RESTARTS AGE
http-gateway-openshift-default-d476664f5-h87mp 1/1 Running 0 36s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We also got a new service for the our http-gateway&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">➜ oc get svc
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
http-gateway-openshift-default LoadBalancer 172.30.183.48 10.0.0.150 15021:30251/TCP,80:30437/TCP 4m52s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The interesting thing is the &lt;code>TYPE&lt;/code> of the service. It’s of type
&lt;code>LoadBalancer&lt;/code>. We have
&lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/networking_operators/metallb-operator">MetalLB&lt;/a>
deployed in our cluster, this might be the reason for this. We will
try to configure a gateway without MetalLB in in upcoming post.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Lets take a look at the gateway resource&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get gtw
NAME CLASS ADDRESS PROGRAMMED AGE
http-gateway openshift-default 10.0.0.150 True 3m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So this seems to be working. But know we have a problem: the &lt;code>*.apps&lt;/code>
domain that we used for our gateway points already to the default
OpenShift Ingress. We could either&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>redeploy the gateway with a different wildcard domain (e.g. *.gtw…​)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>create a more specific DNS record that points to our new load balancer&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try to confirm this with &lt;em>curl&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://bla.apps.ocp.lan.stderr.at
HTTP/1.0 503 Service Unavailable
pragma: no-cache
cache-control: private, max-age=0, no-cache, no-store
content-type: text/html&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;code>503&lt;/code> is the response of default OpenShift Ingress.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://10.0.0.150
HTTP/1.1 404 Not Found
date: Fri, 29 Aug 2025 14:31:31 GMT
transfer-encoding: chunked&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Our new gateway returns a &lt;code>404&lt;/code> not found response. We choose the
first option and create another wildcard DNS entry for
&lt;code>*.gtw.ocp.lan.stderr.at&lt;/code>. We re-deployed our gateway with the new hostname:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
name: http-gateway
namespace: openshift-ingress
spec:
gatewayClassName: openshift-default
listeners:
- name: http
protocol: HTTP
port: 80
hostname: &amp;#34;*.gtw.ocp.lan.stderr.at&amp;#34; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>New hostname for resources exposed via our gateway&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f gateway.yaml
gateway.gateway.networking.k8s.io/http-gateway created&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This also creates a DNSRecord resource:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc describe dnsrecords.ingress.operator.openshift.io -n openshift-ingress http-gateway-c8d7bfc67-wildcard
Name: http-gateway-c8d7bfc67-wildcard
Namespace: openshift-ingress
Labels: gateway.istio.io/managed=openshift.io-gateway-controller-v1
gateway.networking.k8s.io/gateway-name=http-gateway
istio.io/rev=openshift-gateway
Annotations: &amp;lt;none&amp;gt;
API Version: ingress.operator.openshift.io/v1
Kind: DNSRecord
Metadata:
Creation Timestamp: 2025-08-29T14:49:45Z
Finalizers:
operator.openshift.io/ingress-dns
Generation: 1
Owner References:
API Version: v1
Kind: Service
Name: http-gateway-openshift-default
UID: a023de5d-c428-4249-a190-de3cbfeb6964
Resource Version: 141150968
UID: 7a61a867-216e-40b7-88f3-e3934493c477
Spec:
Dns Management Policy: Managed
Dns Name: *.gtw.ocp.lan.stderr.at.
Record TTL: 30
Record Type: A
Targets:
10.0.0.150
Events: &amp;lt;none&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This resource is only internally used by the OpenShift ingress
operator (see &lt;code>oc explain dnsrecord&lt;/code> for details).&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_httproutes_for_exposing_our_service">Creating HTTPRoutes for exposing our service.&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>To actually expose a HTTP pod via our new gateway we need:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A &lt;em>Namespace&lt;/em> to deploy an example pod. We will use a Nginx for this&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A &lt;em>Service&lt;/em> that exposes our Nginx pod&lt;/p>
&lt;/li>
&lt;li>
&lt;p>and finally a &lt;em>HTTPRoute&lt;/em> resource&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For the nginx deployment we used the following manifest:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: v1
kind: Namespace
metadata:
name: gateway-api-test
spec:
finalizers:
- kubernetes
---
apiVersion: apps/v1
kind: Deployment
metadata:
name: nginx-deployment
namespace: gateway-api-test
labels:
app: nginx
spec:
replicas: 1
selector:
matchLabels:
app: nginx
template:
metadata:
labels:
app: nginx
spec:
containers:
- name: nginx
image: quay.io/nginx/nginx-unprivileged:1.29.1
ports:
- containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
name: nginx
namespace: gateway-api-test
spec:
selector:
app: nginx
ports:
- protocol: TCP
port: 8080
targetPort: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s see if our nginx pod got deployed successfully:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc get po,svc -n gateway-api-test
NAME READY STATUS RESTARTS AGE
pod/nginx-deployment-796cdf7474-b7bqz 1/1 Running 0 20s
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/nginx ClusterIP 172.30.42.36 &amp;lt;none&amp;gt; 8080/TCP 21s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And finally confirm our &lt;code>Service&lt;/code> is working:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc port-forward -n gateway-api-test svc/nginx 8080 &amp;amp;
Forwarding from 127.0.0.1:8080 -&amp;gt; 8080
Forwarding from [::1]:8080 -&amp;gt; 8080
$ curl -I localhost:8080
Handling connection for 8080
HTTP/1.1 200 OK
Server: nginx/1.29.1
Date: Fri, 29 Aug 2025 15:45:12 GMT
Content-Type: text/html
Content-Length: 615
Last-Modified: Wed, 13 Aug 2025 14:33:41 GMT
Connection: keep-alive
ETag: &amp;#34;689ca245-267&amp;#34;
Accept-Ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We received a response from our nginx pod, hurray!&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So next let’s try to create a &lt;code>HTTPRoute&lt;/code> to expose our nginx service to external clients:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
name: nginx-route
spec:
parentRefs:
- name: http-gateway
namespace: openshift-ingress
hostnames: [&amp;#34;nginx.gtw.ocp.lan.stderr.at&amp;#34;]
rules:
- backendRefs:
- name: nginx
namespace: gateway-api-test
port: 8080&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>One important point here, the &lt;code>Gateway&lt;/code> actually come in two flavors&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>dedicated gateways, only accepting HTTP routes in the same namespace (&lt;code>openshift-ingress&lt;/code>) in our case.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>shared gateways, which also accept HTTP route objects from other namespaces&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>see &lt;a href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/ingress_and_load_balancing/configuring-ingress-cluster-traffic#nw-ingress-gateway-api-deployment_ingress-gateway-api">Gateway API deployment topologies&lt;/a> in the OpenShift documentation for more information.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As this post is already rather long, we focus on the dedicated gateway topology for now.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The HTTP route must be deployed in the same namespace as the
gateway if the dedicated topology is used.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s deploy our &lt;code>HTTPRoute&lt;/code>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc apply -f httproute.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Verify we can reach our nginx pod:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 500 Internal Server Error
date: Fri, 29 Aug 2025 15:57:34 GMT
transfer-encoding: chunked&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This return a &lt;em>500&lt;/em> error, something seems to be wrong with our route,
let’s take a look at the status of the &lt;code>HTTPRoute&lt;/code>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ oc describe gtw http-gateway
.
. (output omitted)
.
Status:
Parents:
Conditions:
Last Transition Time: 2025-08-29T15:54:43Z
Message: Route was valid
Observed Generation: 1
Reason: Accepted
Status: True
Type: Accepted
Last Transition Time: 2025-08-29T15:54:43Z
Message: backendRef nginx/gateway-api-test not accessible to a HTTPRoute in namespace &amp;#34;openshift-ingress&amp;#34; (missing a ReferenceGrant?) &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
Observed Generation: 1
Reason: RefNotPermitted
Status: False &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Type: ResolvedRefs
Controller Name: openshift.io/gateway-controller/v1
Parent Ref:
Group: gateway.networking.k8s.io
Kind: Gateway
Name: http-gateway
Namespace: openshift-ingress&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Something seems to be wrong as the status is &lt;em>False&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Seems we are missing a ReferenceGrant&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Looking at the
&lt;a href="https://gateway-api.sigs.k8s.io/api-types/referencegrant/" target="_blank" rel="noopener">upstream&lt;/a>
documentation reveals a security feature of the Gateway API. Before a
&lt;code>HTTPRoute&lt;/code> can reach a service in a &lt;em>different&lt;/em> namespace we must
create a &lt;code>ReferenceGrant&lt;/code> in the namespace providing the service.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So let’s try to deploy following &lt;code>ReferenceGrant&lt;/code> in the &lt;em>gateway-api-test&lt;/em> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: gateway.networking.k8s.io/v1beta1
kind: ReferenceGrant
metadata:
name: nginx
namespace: gateway-api-test
spec:
from:
- group: gateway.networking.k8s.io
kind: HTTPRoute
namespace: openshift-ingress
to:
- group: &amp;#34;&amp;#34;
kind: Service&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Checking the status field of our &lt;code>HTTPRoute&lt;/code> again:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">(output omitted)
Status:
Addresses:
Type: IPAddress
Value: 10.0.0.150
Conditions:
Last Transition Time: 2025-08-29T15:47:07Z
Message: Resource accepted
Observed Generation: 1
Reason: Accepted
Status: True
Type: Accepted
Last Transition Time: 2025-08-29T15:47:08Z
Message: Resource programmed, assigned to service(s) http-gateway-openshift-default.openshift-ingress.svc.cluster.local:80
Observed Generation: 1
Reason: Programmed
Status: True &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Type: Programmed&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>&lt;em>Status&lt;/em> is now &lt;em>True&lt;/em>&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>and finally calling the nginx pod again via our gateway:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">$ curl -I http://nginx.gtw.ocp.lan.stderr.at
HTTP/1.1 200 OK
server: nginx/1.29.1
date: Fri, 29 Aug 2025 16:01:33 GMT
content-type: text/html
content-length: 615
last-modified: Wed, 13 Aug 2025 14:33:41 GMT
etag: &amp;#34;689ca245-267&amp;#34;
accept-ranges: bytes&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally everything seems to be in place and working.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this blog post we took a first look at the Kubernetes Gateway API
and it’s integration into OpenShift. We enabled the Gateway API via a
&lt;code>GatewayClass&lt;/code> resource, created a simple HTTP Gateway via a
&lt;code>Gateway&lt;/code>, deploy a Nginx pod and a Service and exposed the service
via a &lt;code>HTTPRoute&lt;/code> and a &lt;code>ReferenceGrant&lt;/code>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Hopefully an upcoming blog post will cover how to&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>How to deploy a Gateway without MetalLB&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Deploy a TLS secured service&lt;/p>
&lt;/li>
&lt;li>
&lt;p>implement HTTP redirects&lt;/p>
&lt;/li>
&lt;li>
&lt;p>rewriting URL’s (if possible)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>and other possibilities of the Gateway API&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Cert-Manager Policy Approver in OpenShift</title><link>https://blog.stderr.at/openshift/2025/06/cert-manager-policy-approver-in-openshift/</link><pubDate>Tue, 03 Jun 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/06/cert-manager-policy-approver-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>One of the most commonly deployed operators in OpenShift environments is the &lt;strong>Cert-Manager Operator&lt;/strong>. It automates the management of TLS certificates for applications running within the cluster, including their issuance and renewal.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The tool supports a variety of certificate issuers by default, including ACME, Vault, and self-signed certificates. Whenever a certificate is needed, Cert-Manager will automatically create a CertificateRequest resource that contains the details of the certificate. This resource is then processed by the appropriate issuer to generate the actual TLS certificate. The approval process in this case is usually fully automated, meaning that the certificate is issued without any manual intervention.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>But what if you want to have more control? What if certificate issuance must follow strict organizational policies, such as requiring a specifc country code or organization name?
This is where the &lt;strong>CertificateRequestPolicy&lt;/strong> resource, a resource provided by the Approver Policy, comes into play.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article walks through configuring the &lt;strong>Cert-Manager Approver Policy&lt;/strong> in OpenShift to enforce granular policies on certificate requests.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before you begin, ensure you have the following:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.16 or higher with cluster-admin access&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cert-Manager Operator installed&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The installation of Cert-Manager itself is discussed in the article: &lt;a href="https://blog.stderr.at/gitopscollection/2024-07-04-managing-certificates-with-gitops/">Managing Certificates using GitOps approach&lt;/a>.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The Cert-Manager Operator does not currently support the Approver Policy by default. You need to install the Approver Policy manually using a Helm Chart. There is a feature request to include the Approver Policy in the Cert-Manager Operator in the future.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adding_approver_policy_chart_as_a_dependency">Adding Approver Policy Chart as a dependency&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Source: &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/cert-manager" target="_blank" rel="noopener">Cert-Manager Deployment&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The above Chart contains the necessary resources to deploy the Cert-Manager itself and Cert-Manager Approver Policy in OpenShift.
To deploy the Approver Policy alongside Cert-Manager, add it as a dependency in your &lt;strong>Chart.yaml&lt;/strong>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">[...]
- name: cert-manager-approver-policy
version: v0.19.0
repository: https://charts.jetstack.io
[...]&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is the official Helm Chart for the Cert-Manager Approver Policy tool provided by Jetstack. The version used in this example is v0.19.0, but you can use a newer version if available.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuration_of_the_helm_chart">Configuration of the Helm Chart&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The initial &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/cert-manager/values.yaml" target="_blank" rel="noopener">values.yaml&lt;/a> file was extended to:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>include the configuration for the Approver Policy Chart&lt;/p>
&lt;/li>
&lt;li>
&lt;p>the configuration for a &lt;strong>CertificateRequestPolicy&lt;/strong> object&lt;/p>
&lt;/li>
&lt;li>
&lt;p>with some specific modifications to the CertManager resource itself&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_disabling_cert_managers_auto_approver">Disabling Cert-Manager’s Auto-Approver&lt;/h3>
&lt;div class="paragraph">
&lt;p>The first step we need to do is to disable the auto-approver of the Cert-Manager. If this is not done, there will be a race condition between the auto-approver and the Approver Policy, which will lead to unexpected results.
These changes are done by:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">cert-manager:
certManager:
enable_patch: true &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
unsupportedConfigOverrides:
controller:
args:
- &amp;#39;--controllers=*,-certificaterequests-approver&amp;#39; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>This enables the patching of the CertManager resource, which tells the chart to overwrite (patch) the automatically generated CertManager resource with the custom configuration.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>This disables the auto-approver Controller of the Cert-Manager.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
As the name suggests, this is currently an unsupported configuration, but it is necessary to disable the auto-approver for the Cert-Manager. In the future versions of the Cert-Manager, this might change, and the auto-approver might be supported out of the box.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In my case, the full CertManager resource looks like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: operator.openshift.io/v1alpha1
kind: CertManager
metadata:
annotations:
name: cluster
spec:
controllerConfig:
overrideArgs: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- &amp;#39;--dns01-recursive-nameservers-only&amp;#39;
- &amp;#39;--dns01-recursive-nameservers=ns-362.awsdns-45.com:53,ns-930.awsdns-52.net:53&amp;#39;
logLevel: Normal
managementState: Managed
operatorLogLevel: Normal
unsupportedConfigOverrides: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
controller:
args:
- &amp;#39;--controllers=*,-certificaterequests-approver&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Settings to support AWS Nameservers for DNS01 challenges.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>This disables the auto-approver Controller of the Cert-Manager.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configuration_of_the_approver_policy">Configuration of the Approver Policy&lt;/h3>
&lt;div class="paragraph">
&lt;p>The second step is to configure the Approver Policy chart. This chart will deploy the necessary resources, most importantly a Deployment that will start the Pods which will process the CertificateRequestPolicy resources later on.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>My configuration for that chart looks like this (some default values are omitted for brevity):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">cert-manager-approver-policy:
crds: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
# This option decides if the CRDs should be installed
# as part of the Helm installation.
enabled: true
# This option makes it so that the &amp;#34;helm.sh/resource-policy&amp;#34;: keep
# annotation is added to the CRD. This will prevent Helm from uninstalling
# the CRD when the Helm release is uninstalled.
# WARNING: when the CRDs are removed, all cert-manager-approver-policy custom resources
# (CertificateRequestPolicy) will be removed too by the garbage collector.
keep: true
# Number of replicas of approver-policy to run.
replicaCount: 1 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
image: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
# Target image repository.
repository: quay.io/jetstack/cert-manager-approver-policy
# Kubernetes imagePullPolicy on Deployment.
pullPolicy: IfNotPresent
tag: v0.19.0
app:
# List of signer names that approver-policy will be given permission to
# approve and deny. CertificateRequests referencing these signer names can be
# processed by approver-policy. Defaults to an empty array, allowing approval
# for all signers.
approveSignerNames: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- &amp;#39;issuers.cert-manager.io/*&amp;#39;
- &amp;#39;clusterissuers.cert-manager.io/*&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>This enables the installation of the CRDs that are required for the Approver Policy.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The number of replicas of the Approver Policy Deployment. In most cases, one replica is enough.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The image configuration for the Approver Policy. The image is pulled from the Jetstack Quay.io repository.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The list of signer names that the Approver Policy will be allowed to approve. In this case, it is configured to allow all issuers and clusterissuers.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The approveSignerNames are, if configured, an important setting, especially if you want to add custom (cluster)issuers. In such a case, you need to add the name of the custom issuer to this list. Otherwise the Approver Policy will not be able to approve the CertificateRequests for that issuer.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_a_certificaterequestpolicy_and_rolebinding">Creating a CertificateRequestPolicy and Role(Binding)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The final step in our configuration is to define a &lt;strong>CertificateRequestPolicy&lt;/strong> resource that will define the policy for the certificate requests. This resource will be processed by the Approver Policy and will determine if a certificate request is approved or denied based on the defined criteria.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following example shows a CertificateRequestPolicy that will:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Allow certificate requests with any common name, DNS names, IP addresses, URIs, and email addresses.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Require DNS names to be set.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Require the subject to contain a specific organization (MyOrganization) and country code (AT).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Allow usages for server auth and client auth.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set constraints for the certificate duration (1h-24h) and private key algorithm (RSA) and size (2048-4096).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Allow all issuers by using an empty selector.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">role: cert-manager-policy:global-approver &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
serviceAccount: cert-manager &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
cert_manager_Namespace: cert-manager &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
policies:
- name: my-approver-policy
enabled: true
allowed:
commonName:
required: false
value: &amp;#34;*&amp;#34;
validations: []
dnsNames: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
required: true
values:
- &amp;#34;*&amp;#34;
validations: []
ipAddresses:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
uris:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
emailAddresses:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
# isCA: false
subject:
organizations: &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
required: true
values:
- &amp;#34;MyOrganization&amp;#34;
validations:
- rule: self.matches(&amp;#34;MyOrganization&amp;#34;)
message: Organization must be MyOrganization
countries:
required: true
values:
- AT
validations:
- rule: self.matches(&amp;#34;AT&amp;#34;)
message: Country code must be AT
usages:
- &amp;#34;server auth&amp;#34;
- &amp;#34;client auth&amp;#34;
constraints: &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
minDuration: 1h
maxDuration: 24h
privateKey:
algorithm: RSA
minSize: 2048
maxSize: 4096
selector:
issuerRef: {} &lt;i class="conum" data-value="7">&lt;/i>&lt;b>(7)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The role that is used to approve the certificate requests. This role must be created in the OpenShift cluster and must have the necessary permissions to approve certificate requests.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The service account that is used by the Approver Policy to process the certificate requests. This service account must have the necessary permissions to access the CertificateRequest resources.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The namespace where the Cert-Manager is deployed. This is usually the &lt;code>cert-manager&lt;/code> namespace, but you can change it if you have a different namespace.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The DNS names are required to be set for the certificate request.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The subject must contain the organization MyOrganization and the country code AT.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>The constraints for the certificate request, such as the minimum and maximum duration, private key algorithm, and size.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="7">&lt;/i>&lt;b>7&lt;/b>&lt;/td>
&lt;td>The selector is empty, which means that the policy applies to all issuers. If you want to limit the policy to specific issuers, you can specify the issuerRef here.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_rendered_certificaterequestpolicy_and_rolebinding">Rendered CertificateRequestPolicy and Role(Binding)&lt;/h3>
&lt;div class="paragraph">
&lt;p>The above configuration will create a CertificateRequestPolicy resource that looks like this:
&lt;div class="expand">
&lt;div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
&lt;i style="font-size:x-small;" class="fas fa-chevron-right">&lt;/i>
&lt;span>
&lt;a>Expand me...&lt;/a>
&lt;/span>
&lt;/div>
&lt;div class="expand-content" style="display: none;">
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
# Source: cert-manager/templates/ClusterRole-Approver-Policy-approving.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: &amp;#34;cert-manager-policy:global-approver&amp;#34;
labels:
helm.sh/chart: cert-manager-2.0.0
app.kubernetes.io/name: cert-manager
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
rules:
- verbs:
- use
apiGroups:
- policy.cert-manager.io
resources:
- certificaterequestpolicies
resourceNames:
- my-approver-policy
---
# Source: cert-manager/charts/cert-manager-approver-policy/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
labels:
app.kubernetes.io/name: cert-manager-approver-policy
helm.sh/chart: cert-manager-approver-policy-v0.19.0
app.kubernetes.io/instance: release-name
app.kubernetes.io/version: &amp;#34;v0.19.0&amp;#34;
app.kubernetes.io/managed-by: Helm
name: cert-manager-approver-policy
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: cert-manager-approver-policy
subjects:
- kind: ServiceAccount
name: cert-manager-approver-policy
namespace: default
---
# Source: cert-manager/templates/CertificateRequestPolicy.yaml
apiVersion: policy.cert-manager.io/v1alpha1
kind: CertificateRequestPolicy
metadata:
name: my-approver-policy
annotations:
argocd.argoproj.io/sync-wave: &amp;#34;10&amp;#34;
labels:
helm.sh/chart: cert-manager-2.0.0
app.kubernetes.io/name: cert-manager
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
spec:
allowed:
commonName:
required: false
value: &amp;#34;*&amp;#34;
validations: []
dnsNames:
required: true
values:
- &amp;#34;*&amp;#34;
validations: []
emailAddresses:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
ipAddresses:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
uris:
required: false
values:
- &amp;#34;*&amp;#34;
validations: []
isCA: false
subject:
organizations:
required: true
values:
- &amp;#34;MyOrganization&amp;#34;
validations:
- rule: &amp;#34;self.matches(\&amp;#34;MyOrganization\&amp;#34;)&amp;#34;
message: &amp;#34;Organization must be MyOrganization&amp;#34;
countries:
required: true
values:
- &amp;#34;AT&amp;#34;
validations:
- rule: &amp;#34;self.matches(\&amp;#34;AT\&amp;#34;)&amp;#34;
message: &amp;#34;Country code must be AT&amp;#34;
organizationalUnits:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
localities:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
provinces:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
streetAddresses:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
postalCodes:
required: false
values: [&amp;#34;*&amp;#34;]
validations: []
serialNumber:
required: false
value: &amp;#34;*&amp;#34;
validations: []
usages:
- &amp;#34;server auth&amp;#34;
- &amp;#34;client auth&amp;#34;
constraints:
minDuration: 1h
maxDuration: 24h
privateKey:
algorithm: RSA
minSize: 2048
maxSize: 4096
selector:
issuerRef: {}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>One important note is about the ClusterRole and ClusterRoleBinding that are created by the Helm Chart. The role looks like the following and is required to allow the Approver Policy to approve certificate requests. This small bit, puzzled me for a while:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">rules:
- verbs:
- use
apiGroups:
- policy.cert-manager.io
resources:
- certificaterequestpolicies
resourceNames:
- my-approver-policy&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the above configuration we are good to go. The Helm Chart can be deployed to the OpenShift cluster (for example, using Argo CD), and the CertificateRequestPolicy will be created automatically.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A new Pod is running in the &lt;strong>cert-manager&lt;/strong> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">❯ oc get pods -n cert-manager | grep approver
NAME READY STATUS RESTARTS AGE
cert-manager-approver-policy-xxxxx 1/1 Running 0 XXm &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The Pod &lt;code>cert-manager-approver-policy-xxxxx&lt;/code> is the Pod that is responsible for processing the CertificateRequestPolicy resources.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_testing_the_policy">Testing the Policy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="sect2">
&lt;h3 id="_test_1_valid_certificate_request">Test 1 - Valid Certificate Request&lt;/h3>
&lt;div class="paragraph">
&lt;p>Now it is time to test the policy. We need to create a Certificate and monitor the output of our approval pod.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a reminder, the policy we created requires the following:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>The subject must contain the organization MyOrganization&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The subject must contain the country code AT.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The keysize must be at least 2048 bits. (max 4096 bits)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The duration must be between 1 hour and 24 hours.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The usage must be server auth or client auth.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s create this example Certificate in the &lt;code>myproject&lt;/code> namespace:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: test-certificate1
namespace: myproject
spec:
dnsNames:
- test1.apps.ocp.aws.ispworld.at
duration: 24h
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod
privateKey:
algorithm: RSA
encoding: PKCS1
rotationPolicy: Always
secretName: test1
subject:
organizations:
- MyOrganization
countries:
- AT
usages:
- server auth&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In the log of the Approver Policy Pod, we should see the following output:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">time=2025-06-03T16:07:58.656Z level=DEBUG+3 msg=&amp;#34;Approved by CertificateRequestPolicy: \&amp;#34;my-approver-policy\&amp;#34;&amp;#34; logger=controller-manager/events type=Normal object=&amp;#34;{Kind:CertificateRequest Namespace:myproject Name:test-certificate1-1 [...]}&amp;#34; reason=Approved&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This indicates that the CertificateRequest was approved by the Approver Policy. The policy was able to validate the subject, keysize, duration, and usage of the certificate request and approved it accordingly.
The certificate has been created successfully in the &lt;strong>myproject&lt;/strong> namespace, and the secret &lt;strong>test1&lt;/strong> contains the TLS certificate and private key.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">❯ oc get secret test1 -n myproject -o yaml
apiVersion: v1
data:
tls.crt: ...
tls.key: ...
kind: Secret
metadata:
labels:
controller.cert-manager.io/fao: &amp;#34;true&amp;#34;
name: test1
namespace: myproject
type: kubernetes.io/tls&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_test_2_invalid_certificate_request">Test 2 - Invalid Certificate Request&lt;/h3>
&lt;div class="paragraph">
&lt;p>That was easy, but what happens if we create a CertificateRequest that does not meet the policy requirements? Let’s try to create a Certificate without the required organization or a wrong country code:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: test-certificate2
namespace: myproject
spec:
dnsNames:
- test2.apps.ocp.aws.ispworld.at
duration: 24h
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod
privateKey:
algorithm: RSA
encoding: PKCS1
rotationPolicy: Always
secretName: test2
subject: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
countries:
- XX
usages:
- server auth&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The subject does not contain the required organization MyOrganization and the country code is set to XX, which is not allowed by the policy.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will lead to the following error in the log of the Approver Policy Pod:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-console" data-lang="console">time=2025-06-03T16:16:02.233Z level=DEBUG+3 msg=&amp;#34;No policy approved this request: [my-approver-policy: [spec.allowed.subject.organizations.required: Required value: true, spec.allowed.subject.countries.values: Invalid value: []string{\&amp;#34;XX\&amp;#34;}: AT, spec.allowed.subject.countries.validations[0]: Invalid value: \&amp;#34;XX\&amp;#34;: Country code must be AT]]&amp;#34; logger=controller-manager/events type=Warning object=&amp;#34;{Kind:CertificateRequest Namespace:myproject Name:test-certificate2-1 ...&amp;#34; reason=Denied&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>It complains that the subject does not meet the policy requirements and therefore the CertificateRequest was denied.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_ok_we_have_a_policy_but_whats_next">Ok we have a policy, but whats next?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The above example shows how the Cert-Manager Approver Policy can be configured and deployed, even if it is not yet supported by the Cert-Manager Operator. However, we only scratched the surface of what is possible with the Approver Policy.
You can create more complex policies that include additional validations, such as checking the validity of the DNS names, IP addresses, or URIs. You can also create policies that require specific email addresses or organizational units in the subject.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can even create fine-grained policies that apply to specific issuers or namespaces by using the &lt;code>selector&lt;/code> field in the CertificateRequestPolicy resource. This allows you to create policies that are tailored to your specific requirements and use cases.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The best references can be found here:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Official documentation: &lt;a href="https://cert-manager.io/docs/policy/approval/approver-policy/" target="_blank" rel="noopener">Cert-Manager Approver Policy&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Example Policies: &lt;a href="https://github.com/cert-manager/approver-policy/tree/main/docs/examples" target="_blank" rel="noopener">Cert-Manager Approver Policy Examples&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The Cert-Manager Approver Policy is a powerful tool that allows you to implement custom policies for certificate requests in OpenShift. It provides a way to control the issuance of TLS certificates based on specific criteria, such as the subject, key size, duration, and usage of the certificate.
While not yet officially supported by the Cert-Manager Operator, it can be easily integrated into your OpenShift environment using a Helm Chart. Future support is currently being discussed, and it is expected that the Approver Policy will be included in the Cert-Manager Operator in the future.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Single log out from Keycloak and OpenShift</title><link>https://blog.stderr.at/openshift/2025/05/single-log-out-from-keycloak-and-openshift/</link><pubDate>Thu, 22 May 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/05/single-log-out-from-keycloak-and-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>The following 1-minute article is a follow-up to my &lt;a href="https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/">previous article&lt;/a> about how to use Keycloak as an authentication provider for OpenShift. In this article, I will show you how to configure Keycloak and OpenShift for Single Log Out (SLO). This means that when you log out from Keycloak, you will also be logged out from OpenShift automatically. This requires some additional configuration in Keycloak and OpenShift, but it is not too complicated.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following prerequisites are required to follow this article:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.16 or higher with cluster-admin privileges&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Keycloak installed and configured, as described in the &lt;a href="https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/">Step by Step - Using Keycloak Authentication in OpenShift&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_keycloak_configuration">Keycloak Configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Configure the logout URL in Keycloak. This is done by adding a new &lt;strong>Valid post logout redirect URIs&lt;/strong> to the Keycloak client configuration. In this case, we want to call the OpenShift logout URL.
Which is: &lt;strong>&lt;a href="https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/logout" class="bare">https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/logout&lt;/a>&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is done in the client settings:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/set-logout-url.png" alt="Set Logout URL"/>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_openshift_configuration">OpenShift Configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now we need to configure OpenShift to use the logout URL. This is done by adding a new &lt;strong>Post Logout Redirect URI&lt;/strong> to the OpenShift Console configuration.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Modify the existing Console resource named cluster and add the logoutRedirect parameter to the authentication section.
The important pieces of the logout URL are the &lt;strong>client_id&lt;/strong> and the &lt;strong>post_logout_redirect_uri&lt;/strong>. The client ID must be the same as the Keycloak client ID, and the post logout redirect URI must be the OpenShift logout URL.
(Also change the &amp;lt;keycloakURL&amp;gt; and &amp;lt;realm&amp;gt; to your Keycloak URL and realm name.)&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Actually, instead of &lt;strong>client_id&lt;/strong>, the &lt;strong>id_token_hint&lt;/strong> should be used. But OpenShift does not store the token, so we are using the client ID instead.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: config.openshift.io/v1
kind: Console
metadata:
name: cluster
spec:
authentication:
logoutRedirect: &amp;#39;https://&amp;lt;keycloakURL&amp;gt;/realms/&amp;lt;realm&amp;gt;/protocol/openid-connect/logout?client_id=&amp;lt;realm&amp;gt;&amp;amp;post_logout_redirect_uri=https://console-openshift-console.apps.ocp.aws.ispworld.at&amp;#39; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The logout URL for OpenShift. This is the URL that will be called when you log out from Keycloak. The URL must contain the client ID and the post logout redirect URI (console of OpenShift).&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Wait a few moments until the OpenShift Console Operator applies the new configuration.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_testing_the_configuration">Testing the configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now that the configuration is done, we can test the Single Log Out functionality.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>We are logged into OpenShift already as user &lt;strong>testuser&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/logged-in.png" alt="Logged in to OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Now we log out from OpenShift using the &lt;strong>Log out&lt;/strong> button in the upper right corner.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/logging-out.png" alt="Log out from OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>This will redirect us to the Keycloak logout page where we need to confirm the logout.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/keycloak-logout.png?width=420" alt="Keycloak Logout"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>This will log us out from Keycloak and redirect us back to the OpenShift logout page.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/logged-out.png?width=420" alt="Logged out from OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is it. You are now logged out from both Keycloak and OpenShift. You can also check the Sessions in Keycloak to see that the session for the user is terminated.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As promised, this was a short article about how to configure Keycloak and OpenShift for Single Log Out. This is a beneficial feature if you want to ensure that users are logged out from all applications when they log out from Keycloak. It is also a good security practice to ensure that users are logged out from all applications when they are done using them.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Step by Step - Using Keycloak Authentication in OpenShift</title><link>https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/</link><pubDate>Sat, 17 May 2025 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2025/05/step-by-step-using-keycloak-authentication-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>I was recently asked about how to use Keycloak as an authentication provider for OpenShift. How to install Keycloak using the Operator and how to configure Keycloak and OpenShift so that users can log in to OpenShift using OpenID.
I have to admit that the exact steps are not easy to find, so I decided to write a blog post about it, describing each step in detail.
This time I will not use GitOps, but the OpenShift and Keycloak Web Console to show the steps, because before we put it into GitOps, we need to understand what is actually happening.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article tries to explain every step required so that a user can authenticate to OpenShift using Keycloak as an Identity Provider (IDP) and that Groups from Keycloak are imported into OpenShift. This article does not cover a production grade installation of Keycloak, but only a test installation, so you can see how it works. For production, you might want to consider a proper database (maybe external, but at least with a backup), high availability, etc.).&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following prerequisites are required to follow this article:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>OpenShift 4.16 or higher with cluster-admin privileges&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_keycloak_operator">Installing Keycloak Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The very first step is to install the Keycloak Operator. This can be done using the OpenShift Web Console or the CLI or GitOps. I will show the steps using the OpenShift Web Console.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Installing the Keycloak Operator via GitOps can be seen in this &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/setup-rh-build-of-keycloak" target="_blank" rel="noopener">GitHub repository&lt;/a>. By the time you read this article, this repository will install and configure a Keycloak instance automatically using a local &lt;strong>EXAMPLE&lt;/strong> Postgres database. It does not yet import any Realm or additional configuration, but I will try to add this in the future when time allows. Oh, and it is just a demo and not production ready, so please do not use it in production.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Log in to the OpenShift Web Console as a user with cluster-admin privileges.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the OpenShift Web Console, navigate to the Operators → OperatorHub.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the OperatorHub, search for &lt;strong>Red Hat build of Keycloak&lt;/strong> and select the Operator from the list.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/search-operator.png?width=320" alt="Search Keycloak Operator"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Install the latest version of the Keycloak Operator.&lt;/p>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
You can keep the default settings for the installation, but I recommend using a specific namespace. In this example, I will use the namespace &lt;code>keycloak&lt;/code> for the installation.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/install-operator.png?width=840" alt="Install Keycloak Operator"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Press the &lt;strong>Install&lt;/strong> button to install the Keycloak Operator. After a few minutes, the Keycloak Operator should be installed and running in the OpenShift cluster. You can check the status of the Operator in the &lt;strong>Installed Operators&lt;/strong> view.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/installed-operator.png" alt="Installed Keycloak Operator"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_create_a_local_example_postgres_database">Create a local example Postgres Database&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Demo only! This is not production ready and should not be used in production.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a next step, we need to create a local Postgres database for Keycloak. Secrets are used to store the database credentials, and a simple StatefulSet is used to create the database. The database will be created in the same namespace as the Keycloak Operator.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>First, let’s create a Secret for the database credentials. In OpenShift select the &lt;strong>keycloak&lt;/strong> namespace and navigate to the &lt;strong>Secrets&lt;/strong> view. Create a new Secret with the following test configuration:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Secret
apiVersion: v1
metadata:
name: keycloak-db-secret
namespace: keycloak
stringData:
password: thisisonly4testingNOT4prod &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
username: testuser
type: Opaque&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The password for the database. This is just a test password and should not be used in production.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Next, we need to create a StatefulSet for the Postgres database, again in the &lt;strong>keycloak&lt;/strong> namespace.
Again, as I cannot mention that enough, this is just a test configuration and should not be used in production.&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
name: postgresql-db
namespace: keycloak
spec:
serviceName: postgresql-db-service
selector:
matchLabels:
app: postgresql-db
replicas: 1 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
template:
metadata:
labels:
app: postgresql-db
spec:
containers:
- name: postgresql-db
image: postgres:15 &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
volumeMounts:
- mountPath: /data
name: psql
env: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
- name: POSTGRES_USER
value: testuser
- name: POSTGRES_PASSWORD
value: thisisonly4testingNOT4prod
- name: PGDATA
value: /data/pgdata
- name: POSTGRES_DB
value: keycloak
volumeClaimTemplates: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- metadata:
name: psql
spec:
accessModes: [ &amp;#34;ReadWriteOnce&amp;#34; ]
storageClassName: &amp;#34;gp3-csi&amp;#34;
resources:
requests:
storage: 10Gi&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The number of replicas for the database. In this example, we are using a single replica.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The image for the database, postgres version 15 in this example.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The environment variables for the database. The username and password are the same as in the Secret we created before, and &lt;strong>clear text&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The volume for the database. In this example, the StatefulSet uses a volume claim template to create a volume with the size of 10 GB for the database. The volume is created using the &lt;code>gp3-csi&lt;/code> storage class. You can use any other storage class that is available in your OpenShift cluster or even remove this line and use the default class instead.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Finally, we need to create a Service for the database so that the Keycloak Operator can access the database. Again, in the &lt;strong>keycloak&lt;/strong> namespace.&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
name: postgres-db
namespace: keycloak
spec:
selector:
app: postgresql-db &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
type: LoadBalancer
ports:
- port: 5432
targetPort: 5432&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The selector for the Service. This must match the label of the StatefulSet we created before.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_a_keycloak_instance">Creating a Keycloak Instance&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now that the Keycloak Operator is installed and our example database is running, we can create a Keycloak instance.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the OpenShift Web Console, navigate to the &lt;strong>Installed Operators&lt;/strong> view and select the Keycloak Operator. (Maybe you need to select the keycloak namespace first.)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the Keycloak Operator view, create a new instance of &lt;strong>Keycloak&lt;/strong> and switch to the &lt;strong>YAML&lt;/strong> view.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-keycloak-instance.png?width=550" alt="Create Keycloak Instance"/>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The fun part here is that the YAML example the Operator provides is actually &lt;strong>wrong and does not work&lt;/strong>. Something that kept me busy for a while.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Replace the YAML with the following configuration:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: k8s.keycloak.org/v2alpha1
kind: Keycloak
metadata:
name: keycloak &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: keycloak
labels:
app: sso
spec:
db: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
host: postgres-db
passwordSecret:
key: password
name: keycloak-db-secret
usernameSecret:
key: username
name: keycloak-db-secret
vendor: postgres
hostname: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
hostname: sso.apps.ocp.aws.ispworld.at
http: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
tlsSecret: keycloak-certificate
instances: 1 &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The name and the namespace of the Keycloak instance.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The database configuration. In this example, we are using a local Postgres database. You can also use an external database, but you need to configure the connection string accordingly.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Hostname of our Keycloak instance.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The TLS secret for the Keycloak instance. You need to create a TLS secret with the certificate and key for the hostname. This is where the example YAML is wrong. It tries to put &lt;em>tlsSecret&lt;/em> under &lt;em>spec&lt;/em>, but it should be under &lt;em>http&lt;/em>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The number of instances of Keycloak. In this example, we are using a single instance.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_what_about_the_ssl_certificate">What about the SSL Certificate?&lt;/h3>
&lt;div class="paragraph">
&lt;p>The Keycloak Operator does not create a certificate for the Keycloak instance. You need to create a certificate manually and store it in a secret. The Operator will use this secret to create the TLS certificate for the Keycloak instance.
In the example above we are referencing a secret called &lt;code>keycloak-certificate&lt;/code> in the &lt;code>keycloak&lt;/code> namespace. This secret was created using the &lt;strong>Cert Manager Operator&lt;/strong>. For example, you can use the following configuration to create a certificate for the Keycloak instance.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: keycloak-certificate
namespace: keycloak
spec:
dnsNames:
- sso.apps.ocp.aws.ispworld.at &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
duration: 2160h0m0s
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
privateKey:
algorithm: RSA
encoding: PKCS1
rotationPolicy: Always
secretName: keycloak-certificate &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The DNS name the Certificate is valid for. This should be the same as the hostname in the Keycloak instance.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The issuer for the certificate. In this example, we are using the &lt;strong>LetsEncrypt&lt;/strong> ClusterIssuer.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The name of the secret where the certificate is stored. This should be the same as the TLS secret in the Keycloak instance.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I strongly recommend using the &lt;strong>Cert Manager Operator&lt;/strong> to automatically request and approve the certificate. However, if you do not have this automation in place, you can use a self-signed certificate. This certificate must be created manually and stored as a secret.
For example, you can use the following command to create a self-signed certificate and store it in a secret:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &amp;#34;/CN=test.keycloak.org/O=Test Keycloak./C=US&amp;#34;
oc create secret -n keycloak tls keycloak-certificate2 --cert=tls.crt --key=tls.key&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_login_in_to_keycloak">Login in to Keycloak&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Once the Keycloak instance is created and all Pods (1) are running, you can log in to the Keycloak Admin Console using the following URL: &lt;a href="https://sso.apps.ocp.aws.ispworld.at" class="bare">https://sso.apps.ocp.aws.ispworld.at&lt;/a>
This is the hostname we configured in the keycloak instance.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To authenticate, you need to fetch the initial password for the admin user. This password is stored in a secret called &lt;strong>keycloak-initial-admin&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can use the following command to fetch the password:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/keycloak-initial-admin -n keycloak --to=-&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>or you can use the OpenShift Web Console to view the secret.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Once authenticated, you should see the Keycloak Admin Console:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/keycloak-initial-login.png" alt="Keycloak Admin Console"/>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The first thing you should do is to change the password for the admin user. I trust you know how to do this :)
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_keycloak_to_be_used_by_openshift">Configure Keycloak to be used by OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The next steps are to configure Keycloak to be used as an Identity Provider (IDP) for OpenShift. This is done by creating a new Realm and a new Client in Keycloak. The following steps will show you the minimum configuration required to use Keycloak as an IDP for OpenShift. It does not cover all the options and features of Keycloak (and there are a lot), but it should be enough to get you started.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The full documentation for Keycloak can be found at &lt;a href="https://docs.redhat.com/en/documentation/red_hat_build_of_keycloak/" target="_blank" rel="noopener">Keycloak Documentation&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_create_a_new_realm_and_client">Create a new Realm and Client&lt;/h3>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the Realm Dropdown (upper left corner) select &lt;strong>Create new Realm&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-new-realm.png?width=420" alt="Create new Realm"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a new Realm called &lt;strong>openshift&lt;/strong> (Enabled, of course) and press &lt;strong>Create&lt;/strong>.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-new-realm-openshift.png?width=1024" alt="Create new Realm OpenShift"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Now, inside the Realm &lt;strong>openshift&lt;/strong>, select &lt;strong>Clients&lt;/strong> and press the &lt;strong>Create client&lt;/strong> button.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/create-new-client.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create a new Client with the following configuration. Name it, for example, &lt;strong>openshift&lt;/strong>.&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Be sure the &lt;strong>Client type&lt;/strong> is set to &lt;strong>OpenID Connect&lt;/strong>&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-client-screen-1.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Enable &lt;strong>Client authentication&lt;/strong>. The rest can be left as default.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-client-screen-2.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Add the following redirect URL and Web origin and press &lt;strong>Save&lt;/strong>.:&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Redirect URL: &lt;a href="https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/oauth2callback/*" class="bare">https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;/oauth2callback/*&lt;/a> …​ redirecting everything under oauth2callback&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Web origin: &lt;a href="https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;" class="bare">https://oauth-openshift.apps.&amp;lt;your-cluster-name&amp;gt;&lt;/a>;&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-client-screen-3.png?width=1024" alt="Create new Client"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_create_a_new_user_and_a_group">Create a new User and a Group&lt;/h3>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the &lt;strong>openshift&lt;/strong> Realm, select &lt;strong>Groups&lt;/strong>, press the &lt;strong>Create group&lt;/strong> button and create a group called, for example, &lt;strong>openshift-users&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In the &lt;strong>openshift&lt;/strong> Realm, select &lt;strong>Users&lt;/strong> and press the &lt;strong>Add user&lt;/strong> button. Be sure to join the group &lt;strong>openshift-users&lt;/strong>.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-user.png?width=1024" alt="Create new User"/>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>No more configuration is needed for the (test) user at this point.&lt;/p>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Set the password for the user. Select the user we have just created, select the &lt;strong>Credentials&lt;/strong> tab and press &lt;strong>Set password&lt;/strong>. Set the password to &lt;strong>Temporary&lt;/strong> to force the user to change the password on the first login.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/new-user-password.png?width=1024" alt="Set password for new User"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_configure_a_group_mapper">Configure a Group Mapper&lt;/h3>
&lt;div class="paragraph">
&lt;p>The above configuration is enough to log in to OpenShift using Keycloak as an IDP (except that we need to configure OpenShift itself). However, we also want to import the groups from Keycloak into OpenShift. This configuration was not easy to find, and is done by creating a Group Mapper in Keycloak.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In the &lt;strong>openshift&lt;/strong> Realm, select &lt;strong>Clients scopes&lt;/strong> and select the &lt;strong>profile&lt;/strong> scope:&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes.png?width=1024" alt="Client Scopes"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Mappers&lt;/strong> tab and Add a mapper &lt;strong>By configuration&lt;/strong>:&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes-mappers.png?width=1024" alt="Client Scopes Mappers"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Select the &lt;strong>Group Membership&lt;/strong> mapper.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes-new-mapper.png?width=1024" alt="Client Scopes Create Group Membership Mapper"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Configure the mapper with the following settings:&lt;/p>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Mapper Type: &lt;strong>Group Membership&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Name: &lt;strong>openshift-groups&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Token Claim Name: &lt;strong>groups&lt;/strong> → This is the name of the claim that will be used to map the groups from Keycloak to OpenShift.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full group path: &lt;strong>OFF&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add to ID token: &lt;strong>ON&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add to access token: &lt;strong>ON&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Add to userinfo: &lt;strong>ON&lt;/strong>&lt;/p>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Disable the &lt;strong>Full groupo path&lt;/strong> option, otherwise the group name will be prefixed with a &lt;strong>/&lt;/strong>. Moreover, be sure that you set the &lt;strong>Token Claim Name&lt;/strong> correctly to the claim we will configure in OpenShift (groups).
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/client-scopes-new-mapper-2.png?width=1024" alt="Client Scopes Create Group Membership Mapper"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_openshift_to_use_keycloak_as_an_idp">Configure OpenShift to use Keycloak as an IDP&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now that Keycloak is configured, we need to configure OpenShift to use Keycloak as an IDP. This is done by creating a new Identity Provider in OpenShift.
Before we do this, we need to create a new OAuth client secret for OpenShift in the Namespace &lt;strong>openshift-config&lt;/strong> The secret will be used to authenticate OpenShift with Keycloak.
When we created the keycloak client, we enabled the &lt;strong>Client authentication&lt;/strong> option. This created a client secret we need to use in OpenShift.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>In Keycloak, select the &lt;strong>openshift&lt;/strong> client and select the &lt;strong>Credentials&lt;/strong> tab and copy the &lt;strong>Client secret&lt;/strong>.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/keycloak-client-secret.png?width=1024" alt="Keycloak Client Secret"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Back in OpenShift, navigate to the &lt;strong>openshift-config&lt;/strong> namespace and select the &lt;strong>Secrets&lt;/strong> view. Create a new secret with the following configuration:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Secret
apiVersion: v1
metadata:
name: openid-client-secret
namespace: openshift-config
stringData:
clientSecret: &amp;lt;you client secret from Keycloak&amp;gt; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
type: Opaque&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The client secret we copied from Keycloak. This is the secret we will use to authenticate OpenShift with Keycloak.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Now we need to create a new Identity Provider in OpenShift. In the OpenShift Web Console, navigate to the &lt;strong>Administration&lt;/strong> → &lt;strong>Cluster Settings&lt;/strong> → &lt;strong>Configuration&lt;/strong> search for &lt;strong>OAuth&lt;/strong> and select the YAML view.
Here the following must be created or added to an existing OAuth configuration:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">[...]
spec:
identityProviders:
- mappingMethod: claim
name: rhsso &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
openID:
claims: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
email:
- email
groups:
- groups
name:
- name
preferredUsername:
- preferred_username
clientID: openshift &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
clientSecret:
name: openid-client-secret &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
extraScopes: []
issuer: &amp;#39;https://sso.apps.ocp.aws.ispworld.at/realms/openshift&amp;#39; &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
type: OpenID &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The name of the Identity Provider. This is the name that will be displayed in the OpenShift login screen.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The claims that will be used to map the user to OpenShift. In this example, we are using the email, groups, name and preferred_username claims from Keycloak.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The client ID we created in Keycloak. This is the client ID that will be used to authenticate OpenShift with Keycloak.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The name of the secret we created in the &lt;strong>openshift-config&lt;/strong> namespace.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The issuer URL for Keycloak. It is &amp;lt;hostname of keycloak&amp;gt;/realms/&amp;lt;realm name&amp;gt;.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>The type of the Identity Provider. In this example, we are using OpenID Connect.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The above configuration will trigger a restart of the authentication Pods in OpenShift. Wait until all Pods have been restarted and the Operator is running again.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/restart-oauth.png" alt="OpenShift OAuth Restart"/>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_test_the_configuration">Test the configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now it is time to test the configuration. Open a new browser window (or incognito window), navigate to the OpenShift login page and try to log in using Keycloak as an IDP &lt;strong>rhsso&lt;/strong>.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
If you have multiple IDPs configured, it is important to select the correct IDP. &lt;strong>rhsso&lt;/strong> in this example.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>By selecting the &lt;strong>rhsso&lt;/strong> Identity Provider, you should be redirected to the Keycloak login page.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-keycloak-login.png?width=1024" alt="OpenShift Login Page"/>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
If you selected &lt;strong>Temporary&lt;/strong> for the password, you will now be asked to change the password on the first login.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>After a successful login, you should see the OpenShift Web Console, and you should be logged in as the user you created in Keycloak.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-web-console.png?width=1024" alt="OpenShift Web Console"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>In OpenShift you will see the user created. In the Identities column you will see that it starts with &lt;strong>rhsso&lt;/strong>, indicating that the user was authenticated using the &lt;strong>rhsso&lt;/strong> Identity Provider.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-user.png" alt="OpenShift User"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>And finally, if you navigate to &lt;strong>User Management&lt;/strong> → &lt;strong>Groups&lt;/strong>, you should see the group &lt;strong>openshift-users&lt;/strong> that was created in Keycloak.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/keycloak/openshift-groups.png" alt="OpenShift Group"/>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_conclusion">Conclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this article, I have shown how to install and configure Keycloak in OpenShift for authentication. I have also shown how to configure Keycloak to be used as an Identity Provider for OpenShift and how to import groups from Keycloak into OpenShift.
The biggest two challenges were to find the correct callback URL and to configure the Group Mapper in Keycloak. The rest was pretty straightforward.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>What’s next? With the groups now mapped into OpenShift, you can now create RoleBindings and ClusterRoleBindings to assign the appropriate roles to the users in Keycloak. This is quite nice, as I do not need to create Users manually in OpenShift anymore (previously used HTPasswd) but instead use Keycloak as the single source of truth for users and groups. All I need to configure is the RoleBindings and ClusterRoleBindings in OpenShift.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I hope this article was helpful and you learned something new. Remember, this is just a test configuration. In production you should use a proper database and keycloak setup (high Availability, backup, etc.).
If you have any questions or comments, please feel free to reach out to me on LinkedIn, Email or via GitHub issues.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_references">References&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://docs.redhat.com/en/documentation/red_hat_build_of_keycloak/" target="_blank" rel="noopener">Keycloak Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://blog.badgerops.net/keycloak-open-shift/" target="_blank" rel="noopener">Keycloak &amp;amp; Open Shift&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/setup-rh-build-of-keycloak" target="_blank" rel="noopener">Set up Keycloak using GitOps (No Realm/Client configuration yet)&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Introducing AdminNetworkPolicies</title><link>https://blog.stderr.at/openshift/2024/11/introducing-adminnetworkpolicies/</link><pubDate>Wed, 06 Nov 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2024/11/introducing-adminnetworkpolicies/</guid><description>&lt;div class="paragraph">
&lt;p>Classic Kubernetes/OpenShift offer a feature called NetworkPolicy that allows users to control the traffic to and from their assigned Namespace.
NetworkPolicies are designed to give project owners or tenants the ability to protect their own namespace. Sometimes, however, I worked with customers where the
cluster administrators or a dedicated (network) team need to enforce these policies.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Since the NetworkPolicy API is namespace-scoped, it is not possible to enforce policies across namespaces. The only solution was to create custom (project) admin and edit
roles, and remove the ability of creating, modifying or deleting NetworkPolicy objects. Technically, this is possible and easily done. But shifts the whole network security to cluster administrators.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Luckily, this is where &lt;strong>AdminNetworkPolicy&lt;/strong> (ANP) and &lt;strong>BaselineAdminNetworkPolicy&lt;/strong> (BANP) comes into play.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adminnetworkpolicy_anp_and_baselineadminnetworkpolicy_banp">AdminNetworkPolicy (ANP) and BaselineAdminNetworkPolicy (BANP)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
This article demonstrates the configuration of the new AdminNetworkPolicy and BaselineAdminNetworkPolicy objects using the Helm Chart &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/admin-networkpolicies" target="_blank" rel="noopener">admin-networkpolicies&lt;/a>. The NetworkPolicy object is not covered in this article.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>ANP and BANP are designed for cluster administrators to protect the entire cluster by creating &lt;strong>cluster-scoped policies&lt;/strong>. They are not replacing NetworkPolicies,
but instead create a tier model and can be used together. Administrators can use ANPs to enforce non-overridable policies that take precedence over NetworkPolicy objects.
Administrators can use BANP to set up and enforce optional cluster-scoped network policy rules that are overridable by users using NetworkPolicy objects when necessary.
When used together, ANP, BANP, and network policy can achieve full multi-tenant isolation that administrators can use to secure their cluster.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The three resources create a 3-Tier Access Control List (ACL) that is evaluated in descending order:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Tier 1 - AdminNetworkPolicy (ANP): If the traffic matches an &lt;strong>allow&lt;/strong> or &lt;strong>deny&lt;/strong> rule, then any existing
NetworkPolicy and BaselineAdminNetworkPolicy (BANP) objects in the cluster are skipped from evaluation. If a &lt;strong>pass&lt;/strong> rule is matched, then the evaluation is handed over to
the next tier (NetworkPolicy). This means, that Cluster Administrators can enforce policies that cannot be overwritten by users (allow/deny rules) or pass the evaluation to the Network Policy,
where the project owners can decide further.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tier 2 - NetworkPolicy (NP): If the traffic passed the ANP then the NetworkPolicy is evaluating the traffic. The NetworkPolicy resources are controlled by the project owners by default.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tier 3 - BaselineAdminNetworkPolicy (BANP): If the traffic passed the ANP and the NetworkPolicy, then the BANP is evaluating the traffic.
These objects are controlled by the cluster administrators again and are cluster scoped. There can only be one BANP (named &amp;#34;default&amp;#34;) configured on the cluster.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adminnetworkpolicy">AdminNetworkPolicy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>An AdminNetworkPolicy (ANP) is a cluster-scoped resource, that allow cluster administrators to secure the network traffic &lt;strong>before&lt;/strong> NetworkPolicies in the namespaces are evaluated.
These rules cannot be overwritten by project owners or developers and allow the administrators to enforce the security. Use cases could be, for example:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>You want to enforce only specific egress endpoints (e.g. only allow traffic to the specific database servers)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You want to be sure that traffic from OpenShift monitoring is always allowed&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You want to allow the management of NetworkPolicies to project owners and do not want to take care for them or during the onboarding.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The ANP allows cluster administrators to define:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A priority value that determines the order of its evaluation. The lower the value the higher the precedence.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A set of pods that consists of a set of namespaces or namespace on which the policy is applied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of ingress rules to be applied for all ingress traffic towards the subject.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of egress rules to be applied for all egress traffic from the subject.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adminnetworkpolicy_actions_for_rules">AdminNetworkPolicy Actions for Rules&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The AdminNetworkPolicy allows three actions for the rules:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Allow&lt;/strong>: The traffic is allowed, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Deny&lt;/strong>: The traffic is denied, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Pass&lt;/strong>: The traffic is passed to the next tier (NetworkPolicy).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_subject_of_a_policy">Subject of a Policy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In any ANP (or BANP) a &lt;strong>subject&lt;/strong> can be defined and they specify the pods to which this AdminNetworkPolicy applies. (Note that host-networked pods are not included in subject.selection.) There are two ways to define the subject:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;strong>namespaces&lt;/strong>: The namespaces block is used to select pods via namespace selectors. Here, &lt;strong>matchLabels&lt;/strong> or &lt;strong>matchExpressions&lt;/strong> can be used to limit the namespaces.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>pods&lt;/strong>: The Pods-Array is used to select pods via namespace AND pod selectors. Here &lt;strong>namespaceSelector&lt;/strong> and &lt;strong>podSelector&lt;/strong> can be set to limit the Pods.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If &lt;strong>subject&lt;/strong> is not defined, the policy applies to all pods and namespaces in the cluster.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In my Helm chart the options are supported like the following snippets show:&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_select_namespaces_with_matchexpressions">Select Namespaces with matchExpressions&lt;/h3>
&lt;div class="paragraph">
&lt;p>Values in the Helm Chart:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">anp:
- name: sample-anp-rule-1
enabled: true
priority: 50
subject:
matchNamespaces: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
matchExpressions: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- key: kubernetes.io/metadata.name
operator: NotIn
values:
- kube-system
- openshift*
- default
- kubde-info&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>matchNamespaces is used to select namespaces&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>matchExpressions is used to select namespaces with &lt;strong>matchExpressions&lt;/strong>. In this example all namespaces that do not match (operator == NotIn) the values, so all namespaces except &amp;#34;kube-system, kube-info, default and openshift*&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will result in the following AdminNetworkPolicy snippet:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> subject:
namespaces:
matchExpressions:
- key: kubernetes.io/metadata.name
operator: NotIn
values:
- &amp;#34;kube-system&amp;#34;
- &amp;#34;openshift*&amp;#34;
- &amp;#34;default&amp;#34;
- &amp;#34;kubde-info&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_select_namespaces_with_matchlabels">Select Namespaces with matchLabels&lt;/h3>
&lt;div class="paragraph">
&lt;p>Values in the Helm Chart:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">anp:
- name: sample-anp-rule-1
enabled: true
priority: 5
subject:
matchNamespaces: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
matchLabels: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
apps: my-apps
tenant: my-tenant&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>matchNamespaces is used to select namespaces&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>&lt;strong>matchLabels&lt;/strong> is used to select namespaces based on labels. In this example, all namespaces that have the labels &amp;#34;apps: my-apps&amp;#34; and &amp;#34;tenant: my-tenant&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will result in the following AdminNetworkPolicy snippet:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">spec:
priority: 5
subject:
namespaces:
matchLabels:
apps: &amp;#34;my-apps&amp;#34;
tenant: &amp;#34;my-tenant&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_select_pods_with_podselectors_and_namespaceselectors">Select Pods with podSelectors and namespaceSelectors&lt;/h3>
&lt;div class="paragraph">
&lt;p>Values in the Helm Chart:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">anp:
- name: sample-anp-rule-1
enabled: true
priority: 5
subject:
matchPods:
- pods: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespaceSelector: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
labels:
kubernetes.io/metadata.name: openshift-dns
podSelector: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
labels:
app: dns&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>matchPods is used to select pods. Here a list of pods can be defined.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>&lt;strong>namespaceSelector&lt;/strong> is used to select namespaces based on labels. In this example all namespaces that have the label &amp;#34;kubernetes.io/metadata.name: openshift-dns&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>&lt;strong>podSelector&lt;/strong> is used to select pods based on labels. In this example all pods that have the label &amp;#34;app: dns&amp;#34; are selected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will result in the following AdminNetworkPolicy snippet:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> subject:
- pods:
namespaceSelector:
matchLabels:
kubernetes.io/metadata.name: openshift-dns
podSelector:
matchLabels:
app: dns&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_baselineadminnetworkpolicy">BaselineAdminNetworkPolicy&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>BaselineAdminNetworkPolicy (BANP) is a cluster-scoped resource, that allow cluster administrators to secure the network traffic &lt;strong>after&lt;/strong> NetworkPolicies in the namespaces have been evaluated. These rules can be overwritten by project owners or developers using NetworkPolicies.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
BANP is a singleton resource, meaning it can be defined only one time. Therefore, its name must be &lt;strong>default&lt;/strong>. Moreover, the &lt;strong>priority&lt;/strong> field is not required here.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Use cases could be, for example:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Creating default rules, such as blocking any intra-cluster traffic by default. Users will need to explicitly use NetworkPolicy objects to allow known traffic.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A BANP allows administrators to specify:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A subject that consists of a set of namespaces or namespace.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of ingress rules to be applied for all ingress traffic towards the subject.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A list of egress rules to be applied for all egress traffic from the subject.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_baselineadminnetworkpolicy_actions_for_rules">BaselineAdminNetworkPolicy Actions for Rules&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The BaselineAdminNetworkPolicy allows two actions for the rules. They are like the AdminNetworkPolicy, except for the &lt;strong>pass&lt;/strong> action, which does not make sense here as BANP is the last tier (nowhere to pass).&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Allow&lt;/strong>: The traffic is allowed, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Deny&lt;/strong>: The traffic is denied, and no further rules are evaluated.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_examples_examples_examples">Examples Examples Examples&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The following examples are taken directly from &lt;a href="https://network-policy-api.sigs.k8s.io/blog/2024/01/30/getting-started-with-the-adminnetworkpolicy-api/" target="_blank" rel="noopener">Kubernetes Blog: Getting started with the AdminNetworkPolicy API&lt;/a> and &lt;a href="https://docs.openshift.com/container-platform/4.16/networking/network_security/network-policy-apis.html" target="_blank" rel="noopener">Official OpenShift Documentation&lt;/a>. Verify the values-file of the &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/admin-networkpolicies" target="_blank" rel="noopener">Helm Chart&lt;/a> for the further examples.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
I will show, how to configure them using the Helm Chart &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/admin-networkpolicies" target="_blank" rel="noopener">admin-networkpolicies&lt;/a> and the actual result. The chart is already configured with these examples and prepared to be used with GitOps/Argo CD.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_1_allow_all_traffic_from_the_openshift_monitoring_namespace">Example 1: Allow all traffic from the OpenShift monitoring namespace&lt;/h3>
&lt;div class="paragraph">
&lt;p>Typically, it makes sense to allow the traffic from OpenShift Monitoring to all namespaces. After all, monitoring is useful :)
The following example shows the possible configuration for the Helm Chart, which will render a valid ANP resource for us. It will allow ALL (including OpenShift internal Namespaces) traffic from the OpenShift monitoring namespace (labeled as &lt;code>kubernetes.io/metadata.name: monitoring&lt;/code>).&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
anp:
- name: sample-anp-rule-1 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
enabled: true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: 10
priority: 5 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
subject: {} &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
ingress: &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>
- name: allow-ingress-from-monitoring &lt;i class="conum" data-value="6">&lt;/i>&lt;b>(6)&lt;/b>
enabled: true &lt;i class="conum" data-value="7">&lt;/i>&lt;b>(7)&lt;/b>
action: Allow &lt;i class="conum" data-value="8">&lt;/i>&lt;b>(8)&lt;/b>
peers: &lt;i class="conum" data-value="9">&lt;/i>&lt;b>(9)&lt;/b>
- type: namespaces
labels:
kubernetes.io/metadata.name: monitoring&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Name of the ANP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Enable or disable the ANP. If disabled, the ANP will not be created. (Default is &lt;code>false&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Priority of the ANP. The lower the value the higher the precedence. (Default is &lt;code>50&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Subject of the ANP. In this case, it is empty, which means all namespaces including OpenShift internal namespaces.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Ingress rules of the ANP. Here a list of ingress rules for this ANP can be defined&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="6">&lt;/i>&lt;b>6&lt;/b>&lt;/td>
&lt;td>Name of the ingress rule&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="7">&lt;/i>&lt;b>7&lt;/b>&lt;/td>
&lt;td>Enable or disable the ingress rule. If disabled, the particular ingress rule will not be created. (Default is &lt;code>false&lt;/code>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="8">&lt;/i>&lt;b>8&lt;/b>&lt;/td>
&lt;td>Action of the ingress rule. In this case, it is &lt;code>Allow&lt;/code>, which means all traffic from the OpenShift monitoring namespace will be allowed. Other options are described at &lt;a href="#_adminnetworkpolicy_actions_for_rules">AdminNetworkPolicy Actions for Rules&lt;/a>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="9">&lt;/i>&lt;b>9&lt;/b>&lt;/td>
&lt;td>Peers of the ingress rule. In this case, all namespaces labeled as &lt;code>kubernetes.io/metadata.name: monitoring&lt;/code> are allowed to access all namespaces.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The ANP that will be created is the following. It is a valid ANP resource and can be applied to the cluster. (Typically applied by Argo CD)
As described above it will allow incoming access from the OpenShift monitoring namespace to all namespaces.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: policy.networking.k8s.io/v1alpha1
kind: AdminNetworkPolicy
metadata:
name: &amp;#34;sample-anp-rule-1&amp;#34;
labels:
helm.sh/chart: admin-networkpolicies-1.0.2
app.kubernetes.io/name: admin-networkpolicies
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
annotations:
argocd.argoproj.io/sync-wave: &amp;#34;10&amp;#34;
argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
spec:
priority: 5
subject:
namespaces: {}
ingress:
- name: &amp;#34;allow-ingress-from-monitoring&amp;#34;
action: &amp;#34;Allow&amp;#34;
from:
- namespaces:
matchLabels:
kubernetes.io/metadata.name: &amp;#34;monitoring&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_2_allow_all_traffic_from_labeled_namespaces">Example 2: Allow all traffic from labeled namespaces&lt;/h3>
&lt;div class="paragraph">
&lt;p>As a second example, we want to allow all traffic from namespaces that are labeled with &lt;code>tenant: restricted&lt;/code> to all namespaces that are labeled with &lt;code>anp: cluster-control-anp&lt;/code>.
This is useful, if you want to restrict access to certain namespaces. However, the rule action is configured as &lt;strong>Pass&lt;/strong> which means that the traffic will be allowed but might be further restricted by a NetworkPolicy in the tenant namespace.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
anp:
- name: sample-anp-rule-2
enabled: true
priority: 5
subject:
matchNamespaces: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
matchLabels:
anp: cluster-control-anp &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
ingress:
- name: pass-from-restricted-tenants
enabled: true
action: Pass &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
peers:
- type: namespaces &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
labels:
tenant: restricted&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Subject of the ANP. In this case, we select based on labels.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Label selector for the namespaces. In this case, all namespaces that are labeled with &lt;code>anp: cluster-control-anp&lt;/code> are subject of this ANP.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Action of the ingress rule. In this case, it is &lt;code>Pass&lt;/code>, which means the traffic is allowed, but might be restricted by NetworkPolicies in the tenant namespace. Other options are described at &lt;a href="#_adminnetworkpolicy_actions_for_rules">AdminNetworkPolicy Actions for Rules&lt;/a>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Peers of the ingress rule. In this case, all namespaces labeled as &lt;code>tenant: restricted&lt;/code> are allowed to access all namespaces.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: policy.networking.k8s.io/v1alpha1
kind: AdminNetworkPolicy
metadata:
name: &amp;#34;sample-anp-rule-2&amp;#34;
labels:
helm.sh/chart: admin-networkpolicies-1.0.2
app.kubernetes.io/name: admin-networkpolicies
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
annotations:
argocd.argoproj.io/sync-wave: &amp;#34;10&amp;#34;
argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
spec:
priority: 5
subject:
namespaces:
matchLabels:
anp: &amp;#34;cluster-control-anp&amp;#34;
ingress:
- name: &amp;#34;pass-from-restricted-tenants&amp;#34;
action: &amp;#34;Pass&amp;#34;
from:
- namespaces:
matchLabels:
tenant: &amp;#34;restricted&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_3_show_possible_peers_settings">Example 3: Show possible peers settings&lt;/h3>
&lt;div class="paragraph">
&lt;p>The most important settings for the rules are the &lt;code>peers&lt;/code> settings. The following examples show the snippets of possible peers.
For further information, please refer to the example in the values file: &lt;a href="https://github.com/tjungbauer/helm-charts/blob/main/charts/admin-networkpolicies/values.yaml" target="_blank" rel="noopener">Helm Chart Values with further examples&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The following rules are examples of &lt;strong>EGRESS&lt;/strong> rules.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to namespaces labeled&lt;/strong> splunk on ports 80 and 443:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: namespaces
labels:
tenant: splunk
ports:
- protocol: TCP
portNumber: 80
- portName: https&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="2">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to nodes&lt;/strong> where the key &amp;#34;node-role.kubernetes.io/control-plane&amp;#34; exists &lt;strong>on the port 6443&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: nodes
expr:
- key: node-role.kubernetes.io/control-plane
operator: Exists
ports:
- protocol: TCP
portNumber: 6443&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="3">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to pods&lt;/strong> labeled &amp;#34;app: dns&amp;#34; &lt;strong>in the namespace&lt;/strong> openshift-dns &lt;strong>on the port 53 and 5353&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: pods
namespaceSelector:
matchLabels:
kubernetes.io/metadata.name: openshift-dns
podSelector:
matchLabels:
app: dns
ports:
- protocol: TCP
port: 5353
- protocol: TCP
port: 53
- protocol: UDP
port: 53
- protocol: UDP
port: 5353&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="4">
&lt;li>
&lt;p>Allow egress traffic &lt;strong>to a list of IPs&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: networks
ips:
- 172.29.0.0/30
- 10.0.54.0/19
- 10.0.56.38/32
- 10.0.69.0/24&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="5">
&lt;li>
&lt;p>Allows egress traffic &lt;strong>to a list of domain names&lt;/strong> (*.kubernetes.io and kubernetes.io)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> peers:
- type: domainNames
domains:
- &amp;#39;*.kubernetes.io&amp;#39;
- kubernetes.io&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic" start="6">
&lt;li>
&lt;p>&lt;strong>Deny all egress traffic&lt;/strong>. This should be the last rule when full egress traffic shall be disabled. This might also be put into the BANP.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> - name: default-deny
enabled: true
action: Deny
peers:
- type: networks
ips:
- 0.0.0.0/0&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_example_4_baselineadminnetworkpolicy">Example 4: BaselineAdminNetworkPolicy&lt;/h3>
&lt;div class="paragraph">
&lt;p>The BANP is more or less identical to ANP, except that you cannot define a &amp;#34;name&amp;#34; and a &amp;#34;priority&amp;#34;. The following example creates a BANP that allows incoming and outgoing traffic to namespaces labeled &amp;#34;tenant-1&amp;#34;.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">banp: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- enabled: true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
syncwave: 10
subject:
matchNamespaces:
matchLabels:
kubernetes.io/metadata.name: example.name
ingress:
- name: &amp;#34;deny-all-ingress-from-tenant-1&amp;#34;
enabled: true
action: Deny
peers:
- type: pods
namespaceSelector:
matchLabels:
custom-banp: tenant-1
podSelector:
matchLabels:
custom-banp: tenant-1
egress:
- name: allow-all-egress-to-tenant-1
enabled: true
action: Allow
peers:
- type: pods
namespaceSelector:
matchLabels:
custom-banp: tenant-1
podSelector:
matchLabels:
custom-banp: tenant-1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Using the key &lt;strong>banp&lt;/strong> (instead of &lt;strong>anp&lt;/strong>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>No &lt;strong>name&lt;/strong> or &lt;strong>priority&lt;/strong> are defined here.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_further_information">Further Information&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/blob/main/charts/admin-networkpolicies/values.yaml" target="_blank" rel="noopener">Helm Chart Values with further examples&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://docs.openshift.com/container-platform/4.16/networking/network_security/network-policy-apis.html" target="_blank" rel="noopener">Official OpenShift Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://network-policy-api.sigs.k8s.io/blog/2024/01/30/getting-started-with-the-adminnetworkpolicy-api/" target="_blank" rel="noopener">Kubernetes Blog: Getting started with the AdminNetworkPolicy API&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://network-policy-api.sigs.k8s.io/reference/spec/#policy.networking.k8s.io/v1alpha1.AdminNetworkPolicyEgressPeer" target="_blank" rel="noopener">Kubernetes API Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>OpenShift Data Foundation - Noobaa Bucket Data Retention (Lifecycle)</title><link>https://blog.stderr.at/openshift/2024/02/openshift-data-foundation-noobaa-bucket-data-retention-lifecycle/</link><pubDate>Mon, 12 Feb 2024 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2024/02/openshift-data-foundation-noobaa-bucket-data-retention-lifecycle/</guid><description>&lt;div class="paragraph">
&lt;p>Data retention or lifecycle configuration for S3 buckets is done by the S3 provider directly. The provider keeps track and files are automatically rotated after the requested time.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This article is a simple step-by-step guide to configure such lifecycle for OpenShift Data Foundation (ODF), where buckets are provided by Noobaa. Knowledge about ODF is assumed, however similar steps can be reproduced for any S3-compliant storage operator.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Installed OpensShift 4.x cluster (latest version during the creation of this article 4.14)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Installed Open Data Foundation Operator (4.14+)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configured Multi-Cloud Gateway (for example) to provide OpenShift with object storage.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Installed aws command line tool. The deployment for different operating system is explained at: &lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#cliv2-linux-install">Installing AWS Client&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A configured bucket and running openshift logging.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
In the further steps we use the bucket that is created for OpenShift Logging (using Lokistack) as a reference.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_working_with_aws_client">Working with aws client&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The first thing to do to work with the aws client is to retrieve the &lt;strong>access key&lt;/strong> and &lt;strong>secret key&lt;/strong> to be able to authenticate against the S3 API. During the deployment of OpenShift logging and the Lokistack a bucket has been created. The secret to authenticate against this bucket can be found in the openshift-logging namespace. In my example the name of this secret is &lt;strong>logging-loki-s3&lt;/strong> and it contains the following values:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/lokisecret.png?width=220" alt="Loki Secret"/>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The easiest way to authenticate against the S3 API is to create the following configuration file:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">&amp;gt; vim ~/.aws/credentials
[default]
aws_access_key_id = &amp;lt;value of access_key_id&amp;gt;
aws_secret_access_key = &amp;lt;value of access_key_secret&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be sure that this file is not globally accessible.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_listing_objects">Listing Objects&lt;/h3>
&lt;div class="paragraph">
&lt;p>As a first test, we can try to list objects. The following command uses the S3 endpoint and the name of the bucket. Again, these values can be found in the Loki secret, mentioned above:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ aws --endpoint https://s3-openshift-storage.apps.ocp.local --no-verify-ssl s3 ls s3://logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56
PRE application/
PRE audit/
PRE index/
PRE infrastructure/&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This command simply lists the current content (some folders in our case) of this bucket.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_copy_a_file_into_the_bucket">Copy a file into the bucket&lt;/h3>
&lt;div class="paragraph">
&lt;p>For further testing we copy a test file into the bucket. This can be any file, I have created an empty one called &lt;strong>testfile.txt&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ aws --endpoint https://s3-openshift-storage.apps.ocp.local --no-verify-ssl s3 cp testfile.txt s3://logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56
upload: ./testfile.txt to s3://logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56/testfile.txt&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Listing the content again, will now show the uploaded testfile.txt&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ aws --endpoint https://s3-openshift-storage.apps.ocp.local --no-verify-ssl s3 ls s3://logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56
PRE application/
PRE audit/
PRE index/
PRE infrastructure/
2024-02-10 04:23:14 32 testfile.txt&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_verifying_current_lifecycle_configuration">Verifying current Lifecycle configuration&lt;/h3>
&lt;div class="paragraph">
&lt;p>To verify the current lifecycle configuration, execute the following command. It will show any configuration that is currently available, or an empty value if there is no such setting yet.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ aws --endpoint https://s3-openshift-storage.apps.ocp.local --no-verify-ssl s3api get-bucket-lifecycle-configuration --bucket logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_put_a_lifecycle_configuration_in_place">Put a lifecycle configuration in place&lt;/h3>
&lt;div class="paragraph">
&lt;p>To configure a data retention of 4 days for our bucket we first need to create the following JSON file:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">cat logging-bucket-lifecycle.json
{
&amp;#34;Rules&amp;#34;: [
{
&amp;#34;Expiration&amp;#34;: {
&amp;#34;Days&amp;#34;: 4 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
},
&amp;#34;ID&amp;#34;: &amp;#34;123&amp;#34;, &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
&amp;#34;Filter&amp;#34;: {
&amp;#34;Prefix&amp;#34;: &amp;#34;&amp;#34; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
},
&amp;#34;Status&amp;#34;: &amp;#34;Enabled&amp;#34;
}
]
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Defines the retention period is days.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>A simple ID for this Rule. (string).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>A filter used to identify objects that a Lifecycle Rule applies to, here the filter is empty, so all objects are affected.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
There are much more setting possible as describe at &lt;a href="https://docs.aws.amazon.com/cli/latest/reference/s3api/put-bucket-lifecycle-configuration.html">AWS S3API&lt;/a>.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following command will put the defined rule in place:&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Already defined rules will be overwritten by the JSON file. If there have been previous configurations, put them into the JSON file as well.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ aws --endpoint https://s3-openshift-storage.apps.ocp.local --no-verify-ssl s3api put-bucket-lifecycle-configuration --bucket logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56 --lifecycle-configuration file://logging-bucket-lifecycle.json&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Checking again with the previous command, the rule should now be configured:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ aws --endpoint https://s3-openshift-storage.apps.ocp.local --no-verify-ssl s3api get-bucket-lifecycle-configuration --bucket logging-bucket-d39a258c-e971-4a0f-a1fa-302cb7e76a56&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_what_now">What now?&lt;/h3>
&lt;div class="paragraph">
&lt;p>Now you have to wait. With the configuration used above, it takes 4 days until the file is rotated. I have tested this using a 1 day retention period and saw that the file will be rotated after about 30 hours. So the rotation will not happen exactly at 24 hours but a bit afterwards.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_consclusion">Consclusion&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>This article describes very, and I mean very, briefly how to configure such data retention for OpenShift Data Foundation. Unfortunately, public documentation can be confusing, so I summarized here the commands I have used.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There are some limitations with the Noobaa integration though. For example file transition (to a different storage class) is (currently) not supported.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also, there are much more possible API calls that might be interesting. Please follow the AWS documentation:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://docs.aws.amazon.com/cli/latest/reference/s3api/">S3 API&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://docs.aws.amazon.com/cli/latest/reference/s3/">S3&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Running Falco on OpenShift 4.12</title><link>https://blog.stderr.at/openshift/2023/11/running-falco-on-openshift-4.12/</link><pubDate>Sun, 26 Nov 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/11/running-falco-on-openshift-4.12/</guid><description>&lt;p>
As mentioned in our &lt;a href="https://blog.stderr.at/openshift/2023-10-23-openshift-falco/">previous post&lt;/a> about &lt;a href="https://falco.org/">Falco&lt;/a>, Falco is a security
tool to monitor kernel events like system calls or Kubernetes audit
logs to provide real-time alerts.&lt;/p>
&lt;p>
In this post I&amp;#39;ll show to customize Falco for a specific use case.
We would like to monitor the following events:&lt;/p>
&lt;ul>
&lt;li>An interactive shell is opened in a container&lt;/li>
&lt;li>Log all commands executed in an interactive shell in a container&lt;/li>
&lt;li>Log read and writes to files within an interactive shell inside a container&lt;/li>
&lt;li>Log commands execute via `kubectl/oc exec` which leverage the
&lt;code>pod/exec&lt;/code> K8s endpoint&lt;/li>
&lt;/ul>
&lt;p>
The rules we created for those kind of events are available &lt;a href="https://raw.githubusercontent.com/tosmi-gitops/openshift-gitops/main/components/apps/falco/overlays/custom-rules/falco-extra-rules.yaml">here&lt;/a>.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Deploying custom rules and disabling the default ruleset
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
Falco comes with a quite elaborate ruleset for creating security
relevant events. But for our use case we just want to deploy a
specific set of rules (see the list above).&lt;/p>
&lt;p>
As we are deploying Falco via &lt;a href="https://github.com/falcosecurity/charts">Helm&lt;/a>, we use the following values for
`rules_files`:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">rules_file&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/etc/falco/extra-rules.d&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/etc/falco/rules.d&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
This instructs Falco to only load rules from the directories mentioned
above.&lt;/p>
&lt;p>
We use a &lt;span style="text-decoration: underline;">Kustomize&lt;/span> &lt;code>configMapGenerator&lt;/code> to create a Kubernetes &lt;code>ConfigMap&lt;/code>
from our custom rules file:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">configMapGenerator&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">options&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">disableNameSuffixHash&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">files&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">falco-extra-rules.yaml&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
The complete &lt;span style="text-decoration: underline;">Kustomize&lt;/span> configuration is &lt;a href="https://raw.githubusercontent.com/tosmi-gitops/openshift-gitops/main/components/apps/falco/overlays/custom-rules/kustomization.yaml">here&lt;/a>.&lt;/p>
&lt;p>
Furthermore we instruct Falco to mount our custom rule &lt;code>ConfigMap&lt;/code>
created above in the Helm values file:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">mounts&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules-volume&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">optional&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMap&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumeMounts&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">mountPath&lt;/span>: &lt;span style="color:#ae81ff">/etc/falco/extra-rules.d&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-extra-rules-volume&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
The complete Helm values files is available &lt;a href="https://raw.githubusercontent.com/tosmi-gitops/openshift-gitops/main/components/apps/falco/base/values.yaml">here&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-2" class="outline-2">
&lt;h2 id="headline-2">
Disable automatic rule updates
&lt;/h2>
&lt;div id="outline-text-headline-2" class="outline-text-2">
&lt;p>
Falco updates all rules when it starts (via an &lt;span style="text-decoration: underline;">initContainer&lt;/span>) and also
updates those rules on a regular basis. We would also like to disable
this behavior:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falcoctl&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">artifact&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">install&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">follow&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Create events for &lt;span style="text-decoration: underline;">kubectl/oc exec&lt;/span>
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
One problem problem is monitoring pod exec events. Using Falcos eBPF
monitoring capabilities we found no way to limit those events to pod
exec&amp;#39;s. This might be because the Falco rule language is new to us
and maybe there is a way to use eBPF filtering. Just let us know if
you find a solution!&lt;/p>
&lt;p>
But we came up with a different way of capturing pod/exec events:&lt;/p>
&lt;p>
Falco also allows monitoring Kubernetes audit events, logged by the
&lt;code>kube-apiserver&lt;/code>. Every time you hit the &lt;code>pod/exec&lt;/code> endpoint, K8s logs the
following event in the audit log:&lt;/p>
&lt;div class="src src-json">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#f92672">&amp;#34;kind&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;Event&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;audit.k8s.io/v1&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;level&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;Metadata&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;auditID&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;5c19c1d0-00a7-4af5-a236-5345b5963581&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;stage&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;ResponseComplete&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;requestURI&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;/api/v1/namespaces/falco/pods/falco-8mqj7/exec?command=cat\u0026command=%2Fetc%2Ffalco%2Fextra-rules.d%2Ffalco-extra-rules.yaml\u0026container=falco\u0026stderr=true\u0026stdout=true&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;verb&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;create&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;user&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;username&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;root&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;uid&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;d82ec74a-75e3-4798-a084-4b766dcea5ef&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;groups&amp;#34;&lt;/span>:[&lt;span style="color:#e6db74">&amp;#34;cluster-admins&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;system:authenticated:oauth&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;system:authenticated&amp;#34;&lt;/span>],&lt;span style="color:#f92672">&amp;#34;extra&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;scopes.authorization.openshift.io&amp;#34;&lt;/span>:[&lt;span style="color:#e6db74">&amp;#34;user:full&amp;#34;&lt;/span>]}},&lt;span style="color:#f92672">&amp;#34;sourceIPs&amp;#34;&lt;/span>:[&lt;span style="color:#e6db74">&amp;#34;10.0.32.220&amp;#34;&lt;/span>],&lt;span style="color:#f92672">&amp;#34;userAgent&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;oc/4.13.0 (linux/amd64) kubernetes/92b1a3d&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;objectRef&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;resource&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;pods&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;namespace&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;name&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;falco-8mqj7&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;apiVersion&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;v1&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;subresource&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;exec&amp;#34;&lt;/span>},&lt;span style="color:#f92672">&amp;#34;responseStatus&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;metadata&amp;#34;&lt;/span>:{},&lt;span style="color:#f92672">&amp;#34;code&amp;#34;&lt;/span>:&lt;span style="color:#ae81ff">101&lt;/span>},&lt;span style="color:#f92672">&amp;#34;requestReceivedTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2023-11-13T17:23:16.999602Z&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;stageTimestamp&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;2023-11-13T17:23:17.231121Z&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;annotations&amp;#34;&lt;/span>:{&lt;span style="color:#f92672">&amp;#34;authorization.k8s.io/decision&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;allow&amp;#34;&lt;/span>,&lt;span style="color:#f92672">&amp;#34;authorization.k8s.io/reason&amp;#34;&lt;/span>:&lt;span style="color:#e6db74">&amp;#34;RBAC: allowed by ClusterRoleBinding \&amp;#34;root-cluster-admin\&amp;#34; of ClusterRole \&amp;#34;cluster-admin\&amp;#34; to User \&amp;#34;root\&amp;#34;&amp;#34;&lt;/span>}}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
As you can hopefully see, the command executed is available in the
&lt;span style="text-decoration: underline;">requestURI&lt;/span> field.&lt;/p>
&lt;p>
So we enabled the &lt;span style="text-decoration: underline;">k8saudit&lt;/span> Falco plugin and created an additional rule
for those kind of events.&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">plugins&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">k8saudit&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">library_path&lt;/span>: &lt;span style="color:#ae81ff">libk8saudit.so&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">init_config&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># maxEventSize: 262144&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># webhookMaxBatchSize: 12582912&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># sslCertificate: /etc/falco/falco.pem&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># open_params: &amp;#34;http://:9765/k8s-audit&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">open_params&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/host/var/log/kube-apiserver/audit.log&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">json&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">library_path&lt;/span>: &lt;span style="color:#ae81ff">libjson.so&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">init_config&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-4" class="outline-2">
&lt;h2 id="headline-4">
Implementing event routing
&lt;/h2>
&lt;div id="outline-text-headline-4" class="outline-text-2">
&lt;p>
We had an additional requirement to route events based on the following rules:&lt;/p>
&lt;ul>
&lt;li>Events that &lt;strong>do not&lt;/strong> contain sensitive data (like usernames) should go
to a specific Kafka topic&lt;/li>
&lt;li>Events that &lt;strong>do&lt;/strong> contain sensitive data (like usernames) should be
routed to another Kafka topic&lt;/li>
&lt;/ul>
&lt;p>Our first thought was to leverage Falcosidekick&amp;#39;s &lt;a href="https://github.com/falcosecurity/falcosidekick/blob/2.28.0/config_example.yaml#L279">minimumpriority&lt;/a>
field for routing. Events with sensitive data would get a higher
priority. But the sink with a lower &lt;span style="text-decoration: underline;">minimumpriority&lt;/span> would get events
with higher priority as well, which means events with sensitive data.&lt;/p>
&lt;p>
Furthermore as far as we know Falco currently only supports one Kafka
configuration (we need two for two topics).&lt;/p>
&lt;p>
At this point in time we are not aware of a possibility to implement
this with Falco or Falcosidekick directly.&lt;/p>
&lt;p>
There are some discussions upstream on implementing such a feature:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/falcosecurity/falcosidekick/issues/161">https://github.com/falcosecurity/falcosidekick/issues/161&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/falcosecurity/falcosidekick/issues/161#issuecomment-747714289">https://github.com/falcosecurity/falcosidekick/issues/161#issuecomment-747714289&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/falcosecurity/falcosidekick/issues/224">https://github.com/falcosecurity/falcosidekick/issues/224&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Our current idea is to use &lt;a href="https://vector.dev/">Vector&lt;/a> for event routing. We will try to
implement the following pipeline:&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/openshift/images/falco/falco-pipeline.png" alt="/openshift/images/falco/falco-pipeline.png" title="/openshift/images/falco/falco-pipeline.png" />&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-2">
&lt;h2 id="headline-5">
Tips and Tricks
&lt;/h2>
&lt;div id="outline-text-headline-5" class="outline-text-2">
&lt;div id="outline-container-headline-6" class="outline-3">
&lt;h3 id="headline-6">
Monitor Redis disk usage
&lt;/h3>
&lt;div id="outline-text-headline-6" class="outline-text-3">
&lt;p>
One small hint when using &lt;code>falcosidekick-ui&lt;/code> to debug/monitor events. It
happened to us that the Redis volume was full and suddenly we couldn&amp;#39;t
see new events in the UI.&lt;/p>
&lt;p>
We stopped the UI and Redis pods, removed the PVC and just ran our kustomization
again, to recreate the PVC and the pods.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-7" class="outline-3">
&lt;h3 id="headline-7">
Monitor &lt;span style="text-decoration: underline;">falco&lt;/span> pod logs when changing rules
&lt;/h3>
&lt;div id="outline-text-headline-7" class="outline-text-3">
&lt;p>
It&amp;#39;s always wise to monitor one Falco pod for errors when deploying
new rules, for example at one point we hit the following error:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>{&amp;#34;hostname&amp;#34;:&amp;#34;falco-2hlkm&amp;#34;,&amp;#34;output&amp;#34;:&amp;#34;Falco internal: hot restart failure: /etc/falco/extra-rules.d/falco-extra-rules.yaml: Invalid\n1 Errors:\nIn rules content: (/etc/falco/extra-rules.d/falco-extra-rules.yaml:0:0)\n rule &amp;#39;Terminal shell in container&amp;#39;: (/etc/falco/extra-rules.d/falco-extra-rules.yaml:25:2)\n condition expression: (\&amp;#34;spawned_process a...\&amp;#34;:26:71)\n------\n...ocess and container and shell_procs and proc.tty != 0 and container_entrypoint\n ^\n------\nLOAD_ERR_VALIDATE (Error validating rule/macro/list/exception objects): Undefined macro &amp;#39;container_entrypoint&amp;#39; used in filter.\n&amp;#34;,&amp;#34;output_fields&amp;#34;:{},&amp;#34;priority&amp;#34;:&amp;#34;Critical&amp;#34;,&amp;#34;rule&amp;#34;:&amp;#34;Falco internal: hot restart failure&amp;#34;,&amp;#34;source&amp;#34;:&amp;#34;internal&amp;#34;,&amp;#34;time&amp;#34;:&amp;#34;2023-11-13T11:47:14.639547735Z&amp;#34;}&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Falco is quite resilient when it comes to errors in rules files and
provides useful hints on what might be wrong:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Undefined macro &amp;#39;container_entrypoint&amp;#39; used in filter&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So we just added the missing macro and all was swell again.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Quay Deployment and Configuration using GitOps</title><link>https://blog.stderr.at/openshift/2023/11/quay-deployment-and-configuration-using-gitops/</link><pubDate>Fri, 03 Nov 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/11/quay-deployment-and-configuration-using-gitops/</guid><description>&lt;div class="paragraph">
&lt;p>Installing and configuring Quay Enterprise using a GitOps approach is not as easy as it sounds.
On the one hand, the operator is deployed easily, on the other hand, the configuration of Quay is quite tough to do in a declarative way and syntax rules must be strictly followed.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article, I am trying to explain how I solved this issue by using a Kubernetes Job and a Helm Chart.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_what_about_quay_configuration">What about Quay configuration?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Quay Enterprise is using a (quite big) Secrets object that defines tons of settings for the registry. The syntax must strictly be followed.
For example, a Boolean must be &lt;code>true&lt;/code> or &lt;code>false&lt;/code>. Quay ignores if a string like &lt;strong>&amp;#34;true&amp;#34;&lt;/strong> or &lt;strong>&amp;#34;false&amp;#34;&lt;/strong> is provided.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This alone is already a hassle since working with Booleans in Helm is not as easy as you might think.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Secret combines &lt;strong>non-sensitive data&lt;/strong> (like &lt;em>DEFAULT_TAG_EXPIRATION&lt;/em>) with &lt;strong>sensitive data&lt;/strong> (like settings for the Object Store)&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If there is any error in the configuration file, or if the Operator is configured to manage a specific component, but finds settings for this component in the Secret, the deployment will fail.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_the_solution">The solution?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>I thought for a long time about how to solve this issue. One solution might be to create the whole Secret upfront and simply provide it
during the deployment. This works and I have done this previously, but I wanted to generate the Secret during the deployment.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Therefore, I am now trying to create a ConfigMap that holds a complete skeleton of the required Secret. This ConfigMap is used by a
Kubernetes Job, which reads the required sensitive information out of other existing Secrets (such as S3 information) and generates a
quay-secret by replacing the required fields.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Is this the perfect and optimal way to do that? Probably not, however, it works :)&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_let_us_see_that_in_action">Let us see that in action&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="sect2">
&lt;h3 id="_prerequisites">Prerequisites&lt;/h3>
&lt;div class="paragraph">
&lt;p>First, we have some prerequisites.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Quay is very …​ very hungry for resources. Quay application pods require 8 CPU and 16GB Memory per pod and per default…​ and it tries to spin up 2 pods. The
same goes for Clair and so on. Therefore, I will configure Quay to only use 1 replica for these services.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Quay requires node roles &lt;code>infra&lt;/code>. I am not sure if this is new or if I never saw that, but the nodeSelector, which it seems you cannot
configure, is looking for the label infra. Therefore, the nodes that should host Quay must have the label: &lt;code>node-role.kubernetes.io/infra: &amp;#39;&amp;#39;&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Currently, I am using a &lt;code>BucketClaim&lt;/code> object to create an S3-bucket
and once created I read the required information of the bucket to
replace the settings in the generated Quay configuration accordingly.
The BucketClaim object comes from the &lt;strong>OpenShift Data Foundation&lt;/strong>. I
installed the &lt;strong>Multicloud Object Gateway&lt;/strong> only, which allows me to
provide Object Storage (S3). (Very useful to test other solutions too,
like OpenShift Logging or Network Observability)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Meeting these requirements, allows us to deploy Quay. But first some theory.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_deployment_workflow">Deployment Workflow&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The workflow of the deployment is as the following image demonstrates&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/quay-setup/quay-synwaves.png" alt="Argo CD Syncwaves"/>
&lt;/div>
&lt;div class="title">Figure 1. Argo CD: Syncwaves&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Everything starts with the Helm Chart &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/setup-quay">setup-quay&lt;/a>. This Chart itself provides the logic to create an S3-bucket, a Job to generate the configuration and the creation of a Secret, that provides the initial administrator credential.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>setup-quay&lt;/strong> has multiple dependencies to other Helm charts, that can be found at my &lt;a href="https://charts.stderr.at">Helm repository&lt;/a>:&lt;/p>
&lt;div class="olist loweralpha">
&lt;ol class="loweralpha" type="a">
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/quay-registry-setup">quay-registry-setup&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-operator">helper-operator&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-status-checker">helper-status-checker&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuration">Configuration&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>All values for the Helm Charts can be found in the &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/blob/main/clusters/management-cluster/setup-quay/values.yaml">values file&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Since sub-charts are used the file is divided into 4 blocks:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>helper-operator: Here the sub-chart helper-operator is configured. All settings here are bypassed to the subchart. It defines the required settings to deploy the operator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>helper-status-checker: Here settings for the status-checker Job are defined.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>quay-registry-setup: This defines the actual configuration of the QuayEnterprise object. It will spin up the Quay instance. Some components are set to &amp;#34;false&amp;#34; or &amp;#34;replica == 1&amp;#34; to minimize the required resources in my lab. For a production environment, additional replicas or components might be required.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>quay: These are the actual values for the configuration. It defines the bucketClaim as well as settings for the Quay configuration that might be overwritten.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_deploy_it">Deploy it&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Using for example the following Argo CD Application we can deploy everything.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
name: in-cluster-setup-quay
namespace: openshift-gitops
spec:
destination:
name: in-cluster &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: default
ignoreDifferences: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- jsonPointers:
- /data/password
kind: Secret
name: init-user
namespace: quay-enterprise
info:
- name: Description
value: ApplicationSet that Deploys on Management Cluster (Matrix Generator)
project: in-cluster
source:
path: clusters/management-cluster/setup-quay &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
repoURL: &amp;#39;https://github.com/tjungbauer/openshift-clusterconfig-gitops&amp;#39;
targetRevision: main&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The destination cluster. Here the &amp;#34;in-cluster&amp;#34; means the local cluster of Argo CD.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The initial credential for Quay is being generated and would change if the Argo CD application gets refreshed and therefore it would be out of sync. So, we are ignoring differences in the password field.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The source of the Helm Chart.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In Argo CD this Application will look like&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/quay-setup/quay-in-argocd.png?width=640px" alt="Quay in Argo CD"/>
&lt;/div>
&lt;div class="title">Figure 2. Quay in Argo CD&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Deployment means in GitOps approach: synchronizing the Argo CD Application.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will install the Operator and spin up all required Pods and Jobs. It will take several minutes until everything is up and running. During the deployment, some Pods may fail and will get restarted automatically. This happens because they are dependent on the Postgres DB which must be started first.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_quay_is_alive">Quay is Alive&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Congratulations, you have now a Quay instance. Use the auto-generated
credentials, that are stored in the Secret &lt;code>init-user&lt;/code> to authenticate.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/quay-setup/quay-login.png?width=320px" alt="Quay Login"/>
&lt;/div>
&lt;div class="title">Figure 3. Quay Login&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_is_that_all_kind_of_summary">Is that All - Kind of Summary?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Several configurations are done here now. However, there are tons to follow. For example, log forwarding or additional certificates. Some
settings will contain sensitive information some will not. All these settings can be added to the ConfigMap skeleton and be replaced
accordingly with &amp;#34;little&amp;#34; effort.
For me, it is simply not possible to test every setting and possibility. Maybe I will extend the
Helm Chart during the journey. If you find this useful, feel free to re-use it and of course, if you find any issues feel free to create a GitHub issue.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Setting up Falco on OpenShift 4.12</title><link>https://blog.stderr.at/openshift/2023/10/setting-up-falco-on-openshift-4.12/</link><pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/10/setting-up-falco-on-openshift-4.12/</guid><description>&lt;p>
&lt;a href="https://falco.org/">Falco&lt;/a> is a security tool to monitor kernel events like system calls to
provide real-time alerts. In this post I&amp;#39;ll document the steps taken
to get Open Source &lt;a href="https://falco.org/">Falco&lt;/a> running on an OpenShift 4.12 cluster.&lt;/p>
&lt;p>
&lt;a href="https://blog.stderr.at/openshift/2023-10-23-openshift-falco/#headline-4">UPDATE&lt;/a>: Use the &lt;code>falco-driver-loader-legacy&lt;/code> image for OpenShift 4.12 deployments.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
First Try
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
We will use the &lt;a href="https://falcosecurity.github.io/charts">Falco Helm chart&lt;/a> version 3.8.0 for our first try of setting up Falco on our OpenShift cluster.&lt;/p>
&lt;p>
This is our values file:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>driver:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: ebpf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> json_output: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> json_include_output_property: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log_syslog: false
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log_level: info
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falcosidekick:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: true
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> webui:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: true&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We would like to use the eBPF driver to monitor kernel events, enable
falco sidekick, which is used to route events and the falco sidekick
UI for easier testing.&lt;/p>
&lt;p>
Because of reasons we leverage kustomize to render the helm chart. The
final kustomize config is &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/tree/main/components/apps/falco/base">here&lt;/a> (after fixing all problems mentioned
below).&lt;/p>
&lt;p>
So after deploying the chart via ArgoCD (another story), we have the following pods:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc get pods -n falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-4cc8j 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>95s ago&lt;span style="color:#f92672">)&lt;/span> 4m31s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-bx87j 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>75s ago&lt;span style="color:#f92672">)&lt;/span> 4m29s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-ds9w6 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>99s ago&lt;span style="color:#f92672">)&lt;/span> 4m30s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 4m28s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-gxznz 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">3&lt;/span> &lt;span style="color:#f92672">(&lt;/span>14s ago&lt;span style="color:#f92672">)&lt;/span> 4m30s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-vtnk5 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>98s ago&lt;span style="color:#f92672">)&lt;/span> 4m29s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-wbn2k 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">5&lt;/span> &lt;span style="color:#f92672">(&lt;/span>80s ago&lt;span style="color:#f92672">)&lt;/span> 4m29s&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
hm, not so good. Seems like some &lt;code>initContainers&lt;/code> are failing.&lt;/p>
&lt;p>
Let&amp;#39;s check the &lt;code>falco-driver-loader&lt;/code> initContainer:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>* Setting up /usr/src links from host
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader &lt;span style="color:#66d9ef">for&lt;/span>: falco version&lt;span style="color:#f92672">=&lt;/span>0.36.1, driver version&lt;span style="color:#f92672">=&lt;/span>6.0.1+driver, arch&lt;span style="color:#f92672">=&lt;/span>x86_64, kernel release&lt;span style="color:#f92672">=&lt;/span>4.18.0-372.73.1.el8_6.x86_64, kernel version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader with: driver&lt;span style="color:#f92672">=&lt;/span>bpf, compile&lt;span style="color:#f92672">=&lt;/span>yes, download&lt;span style="color:#f92672">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Mounting debugfs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mount: /sys/kernel/debug: permission denied.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dmesg&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> may have more information after failed mount system call.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Filename &lt;span style="color:#e6db74">&amp;#39;falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&amp;#39;&lt;/span> is composed of:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - driver name: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - target identifier: rhcos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel release: 4.18.0-372.73.1.el8_6.x86_64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel version: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to download a prebuilt eBPF probe from https://download.falco.org/driver/6.0.1%2Bdriver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl: &lt;span style="color:#f92672">(&lt;/span>22&lt;span style="color:#f92672">)&lt;/span> The requested URL returned error: &lt;span style="color:#ae81ff">404&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find a prebuilt falco eBPF probe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to compile the eBPF probe &lt;span style="color:#f92672">(&lt;/span>falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>expr: syntax error: unexpected argument &lt;span style="color:#e6db74">&amp;#39;1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span>: *** /lib/modules/4.18.0-372.73.1.el8_6.x86_64/build: No such file or directory. Stop.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make: *** &lt;span style="color:#f92672">[&lt;/span>Makefile:38: all&lt;span style="color:#f92672">]&lt;/span> Error &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv: cannot stat &lt;span style="color:#e6db74">&amp;#39;/usr/src/falco-6.0.1+driver/bpf/probe.o&amp;#39;&lt;/span>: No such file or directory
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to load the falco eBPF probe&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Seems to be an issue with a missing directory &lt;span style="text-decoration: underline;">/lib/modules/4.18.0-372.73.1.el8_6.x86_64/build&lt;/span>.&lt;/p>
&lt;p>
And we told the helm chart to enable &lt;code>falco-sidekick&lt;/code> and
&lt;code>falco-sidekick-ui&lt;/code>, but where are they?&lt;/p>
&lt;p>
Let&amp;#39;s check the events with &lt;code>oc get events&lt;/code> as well, and what do we see?&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>8s Warning FailedCreate replicaset/falco-falcosidekick-7cfbbbf89f Error creating: pods &lt;span style="color:#e6db74">&amp;#34;falco-falcosidekick-7cfbbbf89f-&amp;#34;&lt;/span> is forbidden: unable to validate against any security context constraint: &lt;span style="color:#f92672">[&lt;/span>provider &lt;span style="color:#e6db74">&amp;#34;anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider restricted-v2: .spec.securityContext.fsGroup: Invalid value: &lt;span style="color:#f92672">[]&lt;/span>int64&lt;span style="color:#f92672">{&lt;/span>1234&lt;span style="color:#f92672">}&lt;/span>: &lt;span style="color:#ae81ff">1234&lt;/span> is not an allowed group, provider restricted-v2: .containers&lt;span style="color:#f92672">[&lt;/span>0&lt;span style="color:#f92672">]&lt;/span>.runAsUser: Invalid value: 1234: must be in the ranges: &lt;span style="color:#f92672">[&lt;/span>1000730000, 1000739999&lt;span style="color:#f92672">]&lt;/span>, provider &lt;span style="color:#e6db74">&amp;#34;restricted&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostmount-anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;machine-api-termination-handler&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostaccess&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;node-exporter&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;privileged&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>6s Warning FailedCreate replicaset/falco-falcosidekick-ui-76885bd484 Error creating: pods &lt;span style="color:#e6db74">&amp;#34;falco-falcosidekick-ui-76885bd484-&amp;#34;&lt;/span> is forbidden: unable to validate against any security context constraint: &lt;span style="color:#f92672">[&lt;/span>provider &lt;span style="color:#e6db74">&amp;#34;anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider restricted-v2: .spec.securityContext.fsGroup: Invalid value: &lt;span style="color:#f92672">[]&lt;/span>int64&lt;span style="color:#f92672">{&lt;/span>1234&lt;span style="color:#f92672">}&lt;/span>: &lt;span style="color:#ae81ff">1234&lt;/span> is not an allowed group, provider restricted-v2: .containers&lt;span style="color:#f92672">[&lt;/span>0&lt;span style="color:#f92672">]&lt;/span>.runAsUser: Invalid value: 1234: must be in the ranges: &lt;span style="color:#f92672">[&lt;/span>1000730000, 1000739999&lt;span style="color:#f92672">]&lt;/span>, provider &lt;span style="color:#e6db74">&amp;#34;restricted&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;nonroot&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostmount-anyuid&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;machine-api-termination-handler&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork-v2&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostnetwork&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;hostaccess&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;node-exporter&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount, provider &lt;span style="color:#e6db74">&amp;#34;privileged&amp;#34;&lt;/span>: Forbidden: not usable by user or serviceaccount&lt;span style="color:#f92672">]&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Looks like a problem with OpenShifts Security Context constraints (SCC&amp;#39;s).&lt;/p>
&lt;div id="outline-container-headline-2" class="outline-3">
&lt;h3 id="headline-2">
Summary of problems
&lt;/h3>
&lt;div id="outline-text-headline-2" class="outline-text-3">
&lt;ul>
&lt;li>The falco &lt;code>DaemonSet&lt;/code> fails to start pods because there is an issue with a missing directory&lt;/li>
&lt;li>Falco Sidekick and Falco Sidekick UI fails to start because of
Security Context Constraint (SCC) issues&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Fixing the Falco daemonset
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
Falco tries to download a pre-compiled eBPF probe, fails and then
tries to compile that probe for our host OS kernel. This fails with the message:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span>: *** /lib/modules/4.18.0-372.73.1.el8_6.x86_64/build: No such file or directory. Stop.&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
As far as we know there are no kernel sources installed on RHCOS nodes
in OpenShift. After a little bit of searching the interweb we found
the following issue comment on Github:&lt;/p>
&lt;p>
&lt;a href="https://github.com/falcosecurity/falco/issues/1505#issuecomment-754745960">OpenShift under vsphere: Download failed, consider compiling your own falco module and loading it or getting in touch with the Falco community&lt;/a>&lt;/p>
&lt;p>
So we need to enable the &lt;code>kernel-devel&lt;/code> extension, the official docs are
&lt;a href="https://docs.openshift.com/container-platform/4.12/post_installation_configuration/machine-configuration-tasks.html#rhcos-add-extensions_post-install-machine-configuration-tasks">here&lt;/a>. It does not mention &lt;code>kernel-devel&lt;/code>, but there&amp;#39;s a &lt;a href="https://access.redhat.com/solutions/6972423">knowledge base
article&lt;/a> mentioning &lt;code>kernel-devel&lt;/code>, so let&amp;#39;s give it a try.&lt;/p>
&lt;p>
We deploy two &lt;code>MachineConfigs&lt;/code>, one for &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/worker-machineconfig.yaml">worker&lt;/a> and one for &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/master-machineconfig.yaml">master&lt;/a> nodes
to rollout the extension, the worker configuration looks like this:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">machineconfiguration.openshift.io/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">MachineConfig&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">machineconfiguration.openshift.io/role&lt;/span>: &lt;span style="color:#ae81ff">worker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">99&lt;/span>-&lt;span style="color:#ae81ff">worker-kernel-devel-extensions&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">extensions&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">kernel-devel&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
See also our Kustomize configuration &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/kustomization.yaml">here&lt;/a>.&lt;/p>
&lt;p>
As soon as we apply our &lt;code>MachineConfigs&lt;/code>, OpenShift starts the rollout via MaschineConfigPool&amp;#39;s:&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>$ oc get mcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME CONFIG UPDATED UPDATING DEGRADED MACHINECOUNT READYMACHINECOUNT UPDATEDMACHINECOUNT DEGRADEDMACHINECOUNT AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>master rendered-master-ce464ff45cc049fce3e8a63e36a4ee9e False True False 3 0 0 0 13d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>worker rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d False True False 3 0 0 0 13d&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
When the rollout is done, let&amp;#39;s restart all Falco &lt;code>DaemonSet&lt;/code> pods:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc delete pods -l app.kubernetes.io/name&lt;span style="color:#f92672">=&lt;/span>falco&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
And check the status:&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc get pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-5wfnk 0/2 Init:Error &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>3s ago&lt;span style="color:#f92672">)&lt;/span> 7s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-66fxw 0/2 Init:0/2 &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-6fbc7 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 8s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-8h8n4 0/2 Init:0/2 &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 18m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-nhld2 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>2s ago&lt;span style="color:#f92672">)&lt;/span> 6s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-xqv4b 0/2 Init:CrashLoopBackOff &lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">(&lt;/span>3s ago&lt;span style="color:#f92672">)&lt;/span> 8s&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
still, the &lt;code>initContainers&lt;/code> fail. Lets check the log again&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ oc logs -c falco-driver-loader falco-5wfnk
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Setting up /usr/src links from host
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader &lt;span style="color:#66d9ef">for&lt;/span>: falco version&lt;span style="color:#f92672">=&lt;/span>0.36.1, driver version&lt;span style="color:#f92672">=&lt;/span>6.0.1+driver, arch&lt;span style="color:#f92672">=&lt;/span>x86_64, kernel release&lt;span style="color:#f92672">=&lt;/span>4.18.0-372.73.1.el8_6.x86_64, kernel version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader with: driver&lt;span style="color:#f92672">=&lt;/span>bpf, compile&lt;span style="color:#f92672">=&lt;/span>yes, download&lt;span style="color:#f92672">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Mounting debugfs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mount: /sys/kernel/debug: permission denied.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dmesg&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> may have more information after failed mount system call.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Filename &lt;span style="color:#e6db74">&amp;#39;falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&amp;#39;&lt;/span> is composed of:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - driver name: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - target identifier: rhcos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel release: 4.18.0-372.73.1.el8_6.x86_64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel version: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to download a prebuilt eBPF probe from https://download.falco.org/driver/6.0.1%2Bdriver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl: &lt;span style="color:#f92672">(&lt;/span>22&lt;span style="color:#f92672">)&lt;/span> The requested URL returned error: &lt;span style="color:#ae81ff">404&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find a prebuilt falco eBPF probe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to compile the eBPF probe &lt;span style="color:#f92672">(&lt;/span>falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Makefile:1005: *** &lt;span style="color:#e6db74">&amp;#34;Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel&amp;#34;&lt;/span>. Stop.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make: *** &lt;span style="color:#f92672">[&lt;/span>Makefile:38: all&lt;span style="color:#f92672">]&lt;/span> Error &lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mv: cannot stat &lt;span style="color:#e6db74">&amp;#39;/usr/src/falco-6.0.1+driver/bpf/probe.o&amp;#39;&lt;/span>: No such file or directory
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to load the falco eBPF probe&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So this time we get another error, the culprit is the following line&lt;/p>
&lt;div class="src src-bash">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>Makefile:1005: *** &lt;span style="color:#e6db74">&amp;#34;Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel&amp;#34;&lt;/span>. Stop.&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Back to searching the interweb only reveals an old &lt;a href="https://github.com/falcosecurity/falco/issues/376">issue&lt;/a>, that should
be fixed already.&lt;/p>
&lt;p>
So as a quick hack we &lt;a href="https://github.com/tosmi/playground/blob/master/openshift/falco/custom-falco-driver-loader/Dockerfile">modified&lt;/a> the &lt;code>falco-driver-loader&lt;/code> image to
contain &lt;code>libelf-dev&lt;/code> and pushed to image to &lt;a href="https://quay.io/repository/tosmi/falco-driver-loader?tab=tags">quay&lt;/a>.&lt;/p>
&lt;p>
We then modified our falco helm configuration to use the updated image:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">driver&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ebpf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">loader&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">initContainer&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">registry&lt;/span>: &lt;span style="color:#ae81ff">quay.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">repository&lt;/span>: &lt;span style="color:#ae81ff">tosmi/falco-driver-loader&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tag&lt;/span>: &lt;span style="color:#ae81ff">0.36.1&lt;/span>-&lt;span style="color:#ae81ff">libelf-dev&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_output&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_include_output_property&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_syslog&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_level&lt;/span>: &lt;span style="color:#ae81ff">info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falcosidekick&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">webui&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Note the updated &lt;code>diver.loader.initContainer&lt;/code> section.&lt;/p>
&lt;p>
Let&amp;#39;s check the our pods again:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-2ssgx 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 66s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-5hqgg 1/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 66s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-82kq9 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-99zxw 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-test-connection 0/1 Error &lt;span style="color:#ae81ff">0&lt;/span> 67s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 31m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-slx5k 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-tzm8d 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 65s&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Success! This time the &lt;code>DaemonSet&lt;/code> pods started successfully. Just note
that you have to be patient. The first start took about 1-2 minutes to
complete.&lt;/p>
&lt;p>
Let&amp;#39;s check the logs of one &lt;code>DaemonSet&lt;/code> pod just to sure:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>oc logs -c falco-driver-loader falco-2ssgx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Setting up /usr/src links from host
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader &lt;span style="color:#66d9ef">for&lt;/span>: falco version&lt;span style="color:#f92672">=&lt;/span>0.36.1, driver version&lt;span style="color:#f92672">=&lt;/span>6.0.1+driver, arch&lt;span style="color:#f92672">=&lt;/span>x86_64, kernel release&lt;span style="color:#f92672">=&lt;/span>4.18.0-372.73.1.el8_6.x86_64, kernel version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Running falco-driver-loader with: driver&lt;span style="color:#f92672">=&lt;/span>bpf, compile&lt;span style="color:#f92672">=&lt;/span>yes, download&lt;span style="color:#f92672">=&lt;/span>yes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Mounting debugfs
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mount: /sys/kernel/debug: permission denied.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dmesg&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> may have more information after failed mount system call.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Filename &lt;span style="color:#e6db74">&amp;#39;falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&amp;#39;&lt;/span> is composed of:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - driver name: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - target identifier: rhcos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel release: 4.18.0-372.73.1.el8_6.x86_64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kernel version: &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to download a prebuilt eBPF probe from https://download.falco.org/driver/6.0.1%2Bdriver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl: &lt;span style="color:#f92672">(&lt;/span>22&lt;span style="color:#f92672">)&lt;/span> The requested URL returned error: &lt;span style="color:#ae81ff">404&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Unable to find a prebuilt falco eBPF probe
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Trying to compile the eBPF probe &lt;span style="color:#f92672">(&lt;/span>falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* eBPF probe located in /root/.falco/6.0.1+driver/x86_64/falco_rhcos_4.18.0-372.73.1.el8_6.x86_64_1.o
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>* Success: eBPF probe symlinked to /root/.falco/falco-bpf.o&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Especially the line&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>* Success: eBPF probe symlinked to /root/.falco/falco-bpf.o&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
looks promising. So up to the next problem, getting falco-sidekick and falco-sidekick-ui running.&lt;/p>
&lt;p>
We also &lt;a href="https://github.com/falcosecurity/falco/issues/2884">opened a bug&lt;/a> report upstream to get feedback from the
developers on this issue.&lt;/p>
&lt;div id="outline-container-headline-4" class="outline-3">
&lt;h3 id="headline-4">
UPDATE
&lt;/h3>
&lt;div id="outline-text-headline-4" class="outline-text-3">
&lt;p>
&lt;a href="https://github.com/Andreagit97">Andreagit97&lt;/a> was so nice mentioning in the issue above that
actually there is an image with libelf-dev available,
&lt;a href="https://hub.docker.com/r/falcosecurity/falco-driver-loader-legacy">falco-driver-loader-legacy&lt;/a>. We can confirm that this image fixes the
problem mentioned above.&lt;/p>
&lt;p>
So this is our final falco helm chart values.yaml:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">driver&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ebpf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">loader&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">initContainer&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">repository&lt;/span>: &lt;span style="color:#ae81ff">falcosecurity/falco-driver-loader-legacy&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falco&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_output&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">json_include_output_property&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_syslog&lt;/span>: &lt;span style="color:#66d9ef">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">log_level&lt;/span>: &lt;span style="color:#ae81ff">info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">falcosidekick&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">webui&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-2">
&lt;h2 id="headline-5">
Fixing falco-sidekick and falco-sidekick-ui
&lt;/h2>
&lt;div id="outline-text-headline-5" class="outline-text-2">
&lt;p>
Remember pod startup actually failed because of the following event (check with &lt;code>oc get events&lt;/code>):&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>.spec.securityContext.fsGroup: Invalid value: []int64{1234}: 1234 is not an allowed group&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
It seems the sidekick pods want to run with a specific UID. The
default OpenShift Security Context Constraint (SCC) &lt;code>restricted&lt;/code>
prohibits this.&lt;/p>
&lt;p>
Lets confirm our suspicion:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.securityContext}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;fsGroup&amp;#34;&lt;/span>:1234,&lt;span style="color:#e6db74">&amp;#34;runAsUser&amp;#34;&lt;/span>:1234&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.securityContext}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick-ui
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">{&lt;/span>&lt;span style="color:#e6db74">&amp;#34;fsGroup&amp;#34;&lt;/span>:1234,&lt;span style="color:#e6db74">&amp;#34;runAsUser&amp;#34;&lt;/span>:1234&lt;span style="color:#f92672">}&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Bingo! &lt;code>securityContext&lt;/code> is set to 1234 for both deployments. There is
another SCC that we could leverage, &lt;code>nonroot&lt;/code>, which basically allows any
UID expect 0. We just need to get the &lt;code>ServiceAccount&lt;/code> that
falco-sidekick and falco-sidekick-ui are actually using:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.serviceAccount}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc get deploy -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.template.spec.serviceAccount}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span> falco-falcosidekick-ui
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>falco-falcosidekick-ui&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So falco-sidekick uses &lt;code>falco-sidekick&lt;/code> as &lt;code>ServiceAccount&lt;/code> and falco-sidekick-ui &lt;code>falco-sidekick-ui&lt;/code>. Lets
grant both &lt;code>ServiceAccounts&lt;/code> access to the &lt;code>nonroot&lt;/code> SCC.&lt;/p>
&lt;div class="src src-text">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>kind: ClusterRoleBinding
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: falco-falcosidekick-scc:nonroot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>roleRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiGroup: rbac.authorization.k8s.io
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: ClusterRole
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: system:openshift:scc:nonroot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>subjects:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: ServiceAccount
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: falco-falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: falco
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: ServiceAccount
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: falco-falcosidekick-ui
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: falco&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We&amp;#39;ve already added this &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/falcosidekick-any-uid-scc.yaml">file&lt;/a> to our &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/blob/main/components/apps/falco/base/falcosidekick-any-uid-scc.yaml#L19">Kustomize&lt;/a> configuration.&lt;/p>
&lt;p>
Let&amp;#39;s trigger a redeployment by deleting the &lt;code>ReplicaSets&lt;/code> of both deployments, they will be re-created automatically:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc delete rs -l app.kubernetes.io/name&lt;span style="color:#f92672">=&lt;/span>falcosidekick
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc delete rs -l app.kubernetes.io/name&lt;span style="color:#f92672">=&lt;/span>falcosidekick-ui&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Finally let&amp;#39;s confirm everything is up and running:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get deploy,ds,pods
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY UP-TO-DATE AVAILABLE AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/falco-falcosidekick 2/2 &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> 5d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>deployment.apps/falco-falcosidekick-ui 2/2 &lt;span style="color:#ae81ff">2&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span> 5d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>daemonset.apps/falco &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &lt;span style="color:#ae81ff">6&lt;/span> &amp;lt;none&amp;gt; 6d2h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME READY STATUS RESTARTS AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-2ssgx 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-5hqgg 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-82kq9 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-99zxw 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-7cfbbbf89f-qxwxs 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 118s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-7cfbbbf89f-rz5lj 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 118s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-ui-76885bd484-p7lqm 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 2m18s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-ui-76885bd484-sfgh4 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 2m18s
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-falcosidekick-ui-redis-0 1/1 Running &lt;span style="color:#ae81ff">0&lt;/span> 51m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-slx5k 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pod/falco-tzm8d 2/2 Running &lt;span style="color:#ae81ff">0&lt;/span> 21m&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-6" class="outline-2">
&lt;h2 id="headline-6">
Testing Falco
&lt;/h2>
&lt;div id="outline-text-headline-6" class="outline-text-2">
&lt;p>
Now that everything seems to be running, lets do a quick test. First
we will try to access the Falco Sidekick user interface.&lt;/p>
&lt;p>
Falco will not deploy a route for the UI automatically, instead we&amp;#39;ve
created a &lt;a href="https://github.com/tosmi-gitops/openshift-gitops/tree/main/components/apps/falco/overlays/sidekick-ui-route">Kustomize overlay&lt;/a> with a custom route:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">route.openshift.io/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Route&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-falcosidekick-ui&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">falco&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">host&lt;/span>: &lt;span style="color:#ae81ff">falcosidekick-ui.apps.hub.aws.tntinfra.net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">port&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">targetPort&lt;/span>: &lt;span style="color:#ae81ff">http&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tls&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">termination&lt;/span>: &lt;span style="color:#ae81ff">edge&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">to&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Service&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">falco-falcosidekick-ui&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">wildcardPolicy&lt;/span>: &lt;span style="color:#ae81ff">None&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
After deploying the &lt;code>Route&lt;/code> we can access the Falco UI with the hostname
specified in the route object. The default username seems to be
&lt;span style="text-decoration: underline;">admin/admin&lt;/span> which is kind of strange for a security tool, maybe that&amp;#39;s
the reason Falco does not expose the UI per default.&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/openshift/images/falco/falco-ui.png" alt="/openshift/images/falco/falco-ui.png" title="/openshift/images/falco/falco-ui.png" />&lt;/p>
&lt;div id="outline-container-headline-7" class="outline-3">
&lt;h3 id="headline-7">
Creating an event
&lt;/h3>
&lt;div id="outline-text-headline-7" class="outline-text-3">
&lt;p>
As a last test let&amp;#39;s try to trigger an event. We open a shell to one
of the falco &lt;code>DaemonSet&lt;/code> pods and execute a suspicious command:&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc rsh falco-2ssgx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Defaulted container &lt;span style="color:#e6db74">&amp;#34;falco&amp;#34;&lt;/span> out of: falco, falcoctl-artifact-follow, falco-driver-loader &lt;span style="color:#f92672">(&lt;/span>init&lt;span style="color:#f92672">)&lt;/span>, falcoctl-artif# cat /etc/shadow
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>root:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>daemon:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bin:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sys:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sync:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>games:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>man:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lp:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mail:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>news:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>uucp:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>proxy:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>www-data:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>backup:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>list:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>irc:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>_apt:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nobody:*:19639:0:99999:7:::
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
and we can see an event with priority &lt;strong>Warning&lt;/strong> in the Falco ui.&lt;/p>
&lt;p>
&lt;img src="https://blog.stderr.at/openshift/images/falco/falco-cat-etc-shadow.png" alt="/openshift/images/falco/falco-cat-etc-shadow.png" title="/openshift/images/falco/falco-cat-etc-shadow.png" />&lt;/p>
&lt;p>
That&amp;#39;s it, seems like Falco is successfully running on OpenShift 4.12.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>How to force a MachineConfig rollout</title><link>https://blog.stderr.at/openshift/2023/10/how-to-force-a-machineconfig-rollout/</link><pubDate>Wed, 18 Oct 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/10/how-to-force-a-machineconfig-rollout/</guid><description>&lt;p>
While playing around with &lt;a href="https://falco.org/">Falco&lt;/a> (worth another post) I had to force a
MachineConfig update even so the actual configuration of the machine
did not change.&lt;/p>
&lt;p>
This posts documents the steps taken.&lt;/p>
&lt;p>
As this seems to be not clearly documented here it comes&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Get the list of current MachineConfigs&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get mc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>NAME GENERATEDBYCONTROLLER IGNITIONVERSION AGE
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>00-master 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>00-worker 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-master-container-runtime 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-master-kubelet 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-worker-container-runtime 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>01-worker-kubelet 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-kernel-devel-extensions 25h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-master-generated-registries 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-master-ssh 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-worker-generated-registries 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>99-worker-ssh 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-master-b8a2011b0b09e36088acf47e225b0ed2 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 5h49m
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-master-ce464ff45cc049fce3e8a63e36a4ee9e 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 25h
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d 7101fb0720d05771bdc174af918b64deb4efa604 3.2.0 8d&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>We want to force the rollout of a worker node, so remember the name of an old worker config, in our case &lt;code>rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Currently the desiredConfig and the currentConfig should have the same value&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$oc get node node1 -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.metadata.annotations.machineconfiguration\.openshift\.io/desiredConfig}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ oc get node node1 -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.metadata.annotations.machineconfiguration\.openshift\.io/currentConfig}{&amp;#34;\n&amp;#34;}&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rendered-worker-a0f8f0d915ef01ba4a1ab3047b6c863d&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Touch a file called 4 touch /run/machine-config-daemon-force&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>oc debug node/node1 -- touch /host/run/machine-config-daemon-force&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>patch the node and set the annotation &lt;code>machineconfiguration.openshift.io/currentConfig&lt;/code> to the &lt;strong>old&lt;/strong> rendered config rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>oc patch node ip-10-0-182-18.eu-central-1.compute.internal --patch &lt;span style="color:#e6db74">&amp;#39;{ &amp;#34;metadata&amp;#34;: { &amp;#34;annotations&amp;#34;: { &amp;#34;machineconfiguration.openshift.io/currentConfig&amp;#34;: &amp;#34;rendered-worker-5baefb5bb7ad1d69cd7a0c3dc52ef2f3&amp;#34; } } }&amp;#39;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Watch the MachineConfigPool&lt;/p>
&lt;div class="src src-shell">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ oc get mcp&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;p>Wait for the config rollout to complete.&lt;/p></description></item><item><title>Operator installation with Argo CD</title><link>https://blog.stderr.at/openshift/2023/03/operator-installation-with-argo-cd/</link><pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/03/operator-installation-with-argo-cd/</guid><description>&lt;div class="paragraph">
&lt;p>GitOps for application deployment and cluster configuration is a must-have I am trying to convince every customer to follow from the very beginning when starting the Kubernetes journey. For me, as more on the infrastructure side of things, I am more focused on the configuration of an environment.
Meaning, configuring a cluster, installing an operator etc.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article, I would like to share how I deal with cluster configuration when certain Kubernetes objects are dependent on each other and how to use Kubernetes but also Argo CD features to resolve these dependencies.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
This article assumes that you have the &lt;strong>openshift-gitops&lt;/strong> Operator, which provides Argo CD, already installed, and configured. If you are new to GitOps check out this article: &lt;a href="https://blog.stderr.at/openshift/2020-08-06-argocd/">Argo CD&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_tldr">TL;DR&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>If you want to jump directly to the technical fun part, go here: &lt;a href="#source_1">Let’s start&lt;/a>.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_the_idea">The Idea&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Everything should be seen as a code. Everything should be possible to be deployed in a repeatable way. With a GitOps approach, everything is stored naturally in Git and from there, a GitOps agent validates and synchronizes changes to one or more clusters.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When it comes to OpenShift, Red Hat supports Argo CD using the Operator &lt;strong>openshift-gitops&lt;/strong>. This gives you everything you need to deploy an Argo CD instance. The only thing you need to take care of is a Git repository, no matter if it is GitHub, Gitlab, Bitbucket etc.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_the_problem">The Problem&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Sometimes Kubernetes objects depend on each other. This is especially true when you would like to install and configure Operators, where the configuration, based on a Customer Resource Definition (CRD), can only happen after the Operator has been installed and is ready.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Why is that? Well, when you want to deploy an Operator, you will store a “Subscription object” in Git. Argo CD will take this object and applies it to the cluster. However, for an Operator, the creation of the Subscription object is just the first step. A lot of other steps are required until the Operator gets ready. Unfortunately, Argo CD cannot verify if the installation is successful. All it sees is that the Subscription object has been created and then it immediately tries to deploy the CRD. The CRD which is not yet available on the system because the Operator is still installing it.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Even if you use Argo CD features like Sync waves it would not wait until the Operator is successfully installed because for Argo CD the “success” is the creation of the Subscription object.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Subsequently, the Argo CD synchronisation process will fail.
You could now try to automatically “Retry” the sync or use multiple Argo CD applications that you execute one after each other, but I was not fully happy with that and tried a different approach.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_my_solution">My Solution&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Let’s say I would like to deploy and configure the &lt;strong>Compliance Operator&lt;/strong>. The steps would be:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Install the Operator.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wait until the Operator is ready.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configure Operator specific CRDs.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This “Wait until the Operator is ready” is the tricky party for Argo CD. What I have done is the following:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Install the Operator, this is the first step and is done during Sync Wave 0.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a Kubernetes Job that verifies the status of the Operator. This Job additionally requires a ServiceAccount and a role with a binding. They are configured during Sync Wave is 1. Moreover, I use a &lt;strong>Hook&lt;/strong> (another Argo CD feature) with the deletion policy “HookSucceeded”. This makes sure that the Job, ServiceAccount, Role and RoleBinding are removed after the status has been verified.
The verification is successful as soon as the Operator status says “Succeeded”. In fact, all the Job does is to execute some oc commands. For example,&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get clusterserviceversion openshift-gitops-operator.v1.8.0 -n openshift-gitops -o jsonpath={.status.phase}
Succeeded&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Finally, during the next Sync Wave (2+) the CRD can be deployed. In this case, I deploy the object &lt;strong>ScanSettingBinding&lt;/strong>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In Argo CD everything is correctly synchronized, and the Operator and its configuration is in place.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
If you are new to the compliance operator, I recommend the following article: &lt;a href="https://blog.stderr.at/compliance/2021/07/compliance-operator/">Compliance Operator&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I use this approach for every Operator that I would like to install and configure at the same time. For example, I do the same for Advanced Cluster Security or Advanced Cluster Management where I use the Job to verify if everything is ready before I let Argo CD continue.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
More information about Sync Waves and Hooks can be found in the official Argo CD documentation: &lt;a href="https://argo-cd.readthedocs.io/en/stable/user-guide/sync-waves/">Sync Phases and Waves&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="source_1">Let’s see this in Action&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>&lt;strong>Prerequisites&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>OpenShift cluster 4.x&lt;/p>
&lt;/li>
&lt;li>
&lt;p>openshift-gitops is installed and ready to be used.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Access to GitHub (or to your own Repository)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I will be using my Helm Chart repository at &lt;a href="https://charts.stderr.at/" class="bare">https://charts.stderr.at/&lt;/a> and from there the charts:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>compliance-operator-full-stack&lt;/p>
&lt;div class="olist loweralpha">
&lt;ol class="loweralpha" type="a">
&lt;li>
&lt;p>helper-operator (sub chart): Responsible to install the Operators.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>helper-status-checker (sub chart): Responsible to check the status of the Operator.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>Why do I use Helm charts?&lt;/strong>
There is no specific reason for that. I started with Helm for the cluster configuration and now it has evolved with a separate Chart repository and sub-charts and so on.&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_argo_cd_application">Argo CD Application&lt;/h3>
&lt;div class="paragraph">
&lt;p>In Argo CD I have the following Application:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
name: in-cluster-install-compliance-scans
namespace: openshift-gitops
spec:
destination:
namespace: default
server: &amp;#39;https://kubernetes.default.svc&amp;#39; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
info:
- name: Description
value: Deploy and configure the Compliance Scan Operator
project: in-cluster
source:
path: charts/compliance-operator-full-stack &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
repoURL: &amp;#39;https://github.com/tjungbauer/helm-charts&amp;#39;
targetRevision: main&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Installing on the local cluster where Argo CD is installed.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Git configuration, including path and revision.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Actually, this Application is created out of an ApplicationSet, but I did not want to make it too complex :)
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Application would like to synchronize the objects:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Subscription&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OperatorGroup&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Namespace (openshift-compliance)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ScanSettingBinding&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-operator-installation.png" alt="Installing Compliance Operator"/>
&lt;/div>
&lt;div class="title">Figure 1. Argo CD: Installing Compliance Operator&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
&lt;strong>Where are the objects we need for the Job?&lt;/strong> Since they are only available during the Sync-Hook they will not show up here. In fact, they will only show up during the time they are alive and will disappear again after the status of the operator has been verified.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_helm_chart_configuration">Helm Chart Configuration&lt;/h3>
&lt;div class="paragraph">
&lt;p>The &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/compliance-operator-full-stack">Helm Chart&lt;/a> gets its configuration from a values file. You can verify the whole file on GitHub.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The important pieces here are that some variables are handed over to the appropriate Sub Charts.&lt;/p>
&lt;/div>
&lt;div class="sect3">
&lt;h4 id="_operator_configuration">Operator Configuration&lt;/h4>
&lt;div class="paragraph">
&lt;p>This part is handed over to the Chart “&lt;strong>helper-operator&lt;/strong>”.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">helper-operator:
operators:
compliance-operator:
enabled: true
syncwave: &amp;#39;0&amp;#39;
namespace:
name: openshift-compliance
create: true
subscription:
channel: release-0.1
approval: Automatic
operatorName: compliance-operator
source: redhat-operators
sourceNamespace: openshift-marketplace
operatorgroup:
create: true
notownnamespace: true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>It is executed during Sync Wave 0 and defines if a Namespace (openshift-compliance) shall be created (true) and the specification of the Operator which you need to know upfront:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;strong>channel&lt;/strong>: Defines which channel shall be used. Some operators offer different channels.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>approval&lt;/strong>: Either Automatic or Manual … defines if the Operator shall be updated automatically or requires an approval.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>operatorName&lt;/strong>: the actual name of the Operator (compliance-operator)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>source&lt;/strong>: Where does this Operator come from (redhat-operator)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>sourceNamespace&lt;/strong>: In this case openshift-marketplace&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can fetch these values by looking at the Packagemanifest:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get packagemanifest compliance-operator -o yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect3">
&lt;h4 id="_status_checker_configuration">Status Checker Configuration&lt;/h4>
&lt;div class="paragraph">
&lt;p>This part is handed over to the Sub-Chart &amp;#34;&lt;strong>helper-status-checker&lt;/strong>&amp;#34;&amp;#34;. The main values here are the operatorName and the namespace where the Operator is installed.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>What is not visible here is the Sync Wave, which is per default set to 1 inside the Helm Chart. If you need to overwrite it, it can be configured in this section as well.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">helper-status-checker:
enabled: true &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
# use the value of the currentCSV (packagemanifest) but WITHOUT the version !!
operatorName: compliance-operator &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
# where operator is installed
namespace:
name: openshift-compliance &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
serviceAccount:
create: true
name: &amp;#34;sa-compliance&amp;#34; &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Is the status checker enabled or is it not.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The name of the operator as it is reported by the value currentCSV inside the packageManifest&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The namespace where the Operator has been installed.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The name of the ServiceAccount that is created temporarily.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
The operatorName is sometimes different than the Operator name required for helper-operator chart. Here it seems the value of the currentCSV must be used but without the version number. (The Job will look up the version itself)
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect3">
&lt;h4 id="_operator_crd_configuration">Operator CRD configuration&lt;/h4>
&lt;div class="paragraph">
&lt;p>The final section of the values file manages the configuration for the Operator itself. This section does not use a Sub Chart. Instead, the variables are used in the Main-Chart. In this example, the &lt;strong>ScanSettingBinding&lt;/strong> will be configured during Sync Wave 3, which is all we need to basic functionality.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">compliance:
scansettingbinding:
enabled: true
syncwave: &amp;#39;3&amp;#39; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
profiles: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- name: ocp4-cis-node
- name: ocp4-cis
scansetting: default&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Define the Sync Wave. This value must be higher than the Sync Wave of the &lt;strong>helper-status-checker&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>ScanSettingBinding configuration. Two profiles are used in this example.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_synchronizing_argo_cd">Synchronizing Argo CD&lt;/h3>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Basic Application in Argo CD before it is synced:&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-operator-installation.png?width=480" alt="argocd operator installation"/>
&lt;/div>
&lt;div class="title">Figure 2. Argo CD: Application&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Sync Wave 0: Synchronization has started. Namespace and Subscription are deployed.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-starting-operator-installation.png?width=480" alt="argocd starting operator installation"/>
&lt;/div>
&lt;div class="title">Figure 3. Argo CD: Synchronization is started (Sync Wave 0)&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Sync Wave 1: Status Checker Job has started and tries to verify the Operator.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-starting-job.png?width=480" alt="argocd starting job"/>
&lt;/div>
&lt;div class="title">Figure 4. Argo CD: Status Checker Job started (Sync Wave 1)&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>The Log output of the Operator. You can see that the status switches from Pending to Installing to Succeeded.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-status-checker-log.png?width=480" alt="argocd status checker log"/>
&lt;/div>
&lt;div class="title">Figure 5. Argo CD: Log of the Status Checker Pod&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>After Sync Wave 3, the whole Application has been synchronized and the Checker Job has been removed.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-operator-installed.png?width=480" alt="argocd operator installed"/>
&lt;/div>
&lt;div class="title">Figure 6. Argo CD: Compliance Operator is fully deployed&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>SSL Certificate Management for OpenShift on AWS</title><link>https://blog.stderr.at/openshift/2023/02/ssl-certificate-management-for-openshift-on-aws/</link><pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2023/02/ssl-certificate-management-for-openshift-on-aws/</guid><description>&lt;div class="paragraph">
&lt;p>Finally, after a long time on my backlog, I had some time to look into the &lt;strong>Cert-Manager Operator&lt;/strong> and use this Operator to automatically issue new SSL certificates.
This article shall show step-by-step how to create a certificate request and use this certificate for a Route and access a service via your Browser.
I will focus on the technical part, using a given domain on AWS Route53.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_introduction">Introduction&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>After a new OpenShift Cluster has been deployed, self-signed certificates are used to access the Routes (for example the console) and the API. Typically, an application is exposed to the world using the schema &lt;em>&amp;lt;app-name&amp;gt;-&amp;lt;namespace-name&amp;gt;.apps.&amp;lt;clusterdomain&amp;gt;&lt;/em>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We will try to create a certificate for a specific application with a custom domain name and for the cluster domains: *.apps.clusterdomain and api.clusterdomain.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The domain is already available and delegated to AWS Route53. As certificate authority, I am using &lt;a href="https://letsencrypt.org/">Let’s Encrypt&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>We will install 2 operators:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>&lt;strong>Cert Manager&lt;/strong>: to issue new certificates.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Cert Utils Operator&lt;/strong>: injects the certificate into a Route object.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The &lt;strong>Cert Utils Operator&lt;/strong> can provide additional information for a certificate and monitors the expiration date. Here we mainly use it to automatically inject Route objects by defining specific annotations.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>OpenShift cluster with a user that has privileges to install Operators.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A domain hosted for example at Route 53&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Credentials for your Cloud Provider (AWS)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_deploy_an_example_application">Deploy an Example Application&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Let’s use the super complex demo application &lt;strong>bookimport&lt;/strong>.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc new-project bookimport
oc apply -f https://raw.githubusercontent.com/tjungbauer/book-import/master-no-pre-post/book-import/deployment.yaml -n bookimport
oc apply -f https://raw.githubusercontent.com/tjungbauer/book-import/master-no-pre-post/book-import/service.yaml -n bookimport
oc expose service book-import -n bookimport
oc get route -n bookimport&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The last command will print you an URL which, copied into the browser, will open our application:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/cert-manager/bookimport.png?width=480px" alt="Bookimport"/>
&lt;/div>
&lt;div class="title">Figure 1. Application Book Import using HTTP&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see in the address line the connection is not secured (&lt;em>Nicht sicher&lt;/em> in German) and my domain is &lt;strong>*.apps.ocp.aws.ispworld.at&lt;/strong>&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_an_aws_user_for_accessing_route_53">Configure an AWS user for accessing Route 53&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>On AWS I have currently 2 Zones, the public &lt;strong>aws.ispworld.at&lt;/strong> and a private zone, created by the OpenShift Installer.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/cert-manager/hostedzones.png?width=340px" alt="DomainZones"/>
&lt;/div>
&lt;div class="title">Figure 2. Domain Zones&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Before you can manage your domains a user with appropriate privileges must be created.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Store the following in the file &lt;code>policy.json&lt;/code>. This will allow a user to perform DNS Upgrades.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">{
&amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;,
&amp;#34;Statement&amp;#34;: [
{
&amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;,
&amp;#34;Action&amp;#34;: &amp;#34;route53:GetChange&amp;#34;,
&amp;#34;Resource&amp;#34;: &amp;#34;arn:aws:route53:::change/*&amp;#34;
},
{
&amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;,
&amp;#34;Action&amp;#34;: [
&amp;#34;route53:ChangeResourceRecordSets&amp;#34;,
&amp;#34;route53:ListResourceRecordSets&amp;#34;
],
&amp;#34;Resource&amp;#34;: &amp;#34;arn:aws:route53:::hostedzone/*&amp;#34;
},
{
&amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;,
&amp;#34;Action&amp;#34;: [
&amp;#34;route53:ListHostedZones&amp;#34;,
&amp;#34;route53:ListResourceRecordSets&amp;#34;,
&amp;#34;route53:ListHostedZonesByName&amp;#34;
],
&amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34;
}
]
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Apply the new policy to AWS and store the ARN into a variable:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">aws iam create-policy --policy-name AllowDNSUpdates --policy-document file://policy.json
export POLICY_ARN=$(aws iam list-policies --query &amp;#39;Policies[?PolicyName==`AllowDNSUpdates`].Arn&amp;#39; --output text)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Create the user &lt;code>route53-openshift&lt;/code> and assign the policy to that user:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">aws iam create-user --user-name route53-openshift
aws iam attach-user-policy --policy-arn $POLICY_ARN --user-name route53-openshift&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally, create the access key and store the &lt;strong>AccessKeyId&lt;/strong> and the &lt;strong>SecretAccessKey&lt;/strong> for later use:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">aws iam create-access-key --user-name route53-openshift --output json
{
&amp;#34;AccessKey&amp;#34;: {
&amp;#34;UserName&amp;#34;: &amp;#34;route53-openshift&amp;#34;,
&amp;#34;AccessKeyId&amp;#34;: &amp;#34;XXXXXXXXXXXXXX&amp;#34;,
&amp;#34;Status&amp;#34;: &amp;#34;Active&amp;#34;,
&amp;#34;SecretAccessKey&amp;#34;: &amp;#34;XXXXXXXXXXXXXXXXXXX&amp;#34;,
&amp;#34;CreateDate&amp;#34;: &amp;#34;2023-02-15T12:34:06+00:00&amp;#34;
}
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_operators_to_openshift">Installing Operators to OpenShift&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>We will install 2 Operators to our cluster:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>cert-manager Operator for Red Hat OpenShift&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cert Utils Operator&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Simply search both on OLM and install them keeping the default values.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The Cert Utils Operator is a &lt;strong>Community&lt;/strong> Operator.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/cert-manager/operators.png?width=480px" alt="Operators"/>
&lt;/div>
&lt;div class="title">Figure 3. Operators&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will install the Cert-Manager into the namespace &lt;strong>openshift-cert-manager&lt;/strong>&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_the_cert_manager_operator">Configure the Cert-Manager Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before we can issue a certificate, we need to create a secret with our AWS SecretAccessKey (see above):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc create secret generic prod-route53-credentials-secret --from-literal secret-access-key=&amp;#34;XXXXXXXXXXXXXXXXXXX&amp;#34; -n openshift-cert-manager&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As next step, we create a &lt;strong>ClusterIssuer&lt;/strong> that will be available cluster-wide using &lt;strong>Let’s Encrypt&lt;/strong> as certificate authority:&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The connection to Let’s Encrypt is using the &lt;strong>productive&lt;/strong> API. If you would like to use the staging environment instead, change the server URL to &lt;a href="https://acme-staging-v02.api.letsencrypt.org/directory" class="bare">https://acme-staging-v02.api.letsencrypt.org/directory&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
name: letsencrypt-prod
spec:
acme:
email: your@email.com &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
preferredChain: &amp;#39;&amp;#39;
privateKeySecretRef:
name: letsencrypt-account-key
server: &amp;#39;https://acme-v02.api.letsencrypt.org/directory&amp;#39;
solvers:
- dns01:
route53:
accessKeyID: XXXXXXXXXXXXXX &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
region: eu-central-1 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
secretAccessKeySecretRef:
key: secret-access-key
name: prod-route53-credentials-secret &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
selector:
dnsZones:
- your-domain &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Change your email address&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Use the &lt;strong>AccessKeyId&lt;/strong> created above&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Using AWS you need to define a region&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>The name of the secret created during the step before&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Your &lt;strong>public&lt;/strong> domain, for example aws.ispworld.at.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Once created the &lt;strong>ClusterIssuer&lt;/strong> should switch to the status &amp;#34;Ready&amp;#34;&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc describe clusterissuer letsencrypt-prod
Status:
...
Conditions:
Last Transition Time: 2023-02-16T13:54:49Z
Message: The ACME account was registered with the ACME server
Observed Generation: 1
Reason: ACMEAccountRegistered
Status: True
Type: Ready&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_optional_when_using_private_domains_or_firewalls">OPTIONAL: When using private Domains or Firewalls&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As you can see in one of the images above, I have two domains:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>aws.ispworld.at&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ocp.aws.ispworld.at&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The first one is marked as &lt;strong>public&lt;/strong>, that means everybody can resolve names. The second one is set to &lt;strong>private&lt;/strong> and only define VPCs (in this case the cluster itself) can resolve hostnames.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In case of the following error:&lt;/p>
&lt;/div>
&lt;div class="literalblock">
&lt;div class="content">
&lt;pre>E0216 15:27:29.513080 1 controller.go:163] cert-manager/challenges &amp;#34;msg&amp;#34;=&amp;#34;re-queuing item due to error processing&amp;#34; &amp;#34;error&amp;#34;=&amp;#34;failed to determine Route 53 hosted zone ID: zone not found in Route 53 for domain _acme-challenge.bookimport.apps.ocp.aws.ispworld.at.&amp;#34; &amp;#34;key&amp;#34;=&amp;#34;bookimport/bookimport-cert-jbmh6-2173685137-2399596362&amp;#34;&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Add the following into &lt;strong>ClusterManager&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">oc edit CertManager.operator.openshift.io/cluster
unsupportedConfigOverrides:
controller:
args:
- --v=2
- --cluster-resource-namespace=$(POD_NAMESPACE)
- --leader-election-namespace=kube-system
- --dns01-recursive-nameservers-only
- --dns01-recursive-nameservers=ns-362.awsdns-45.com:53,ns-930.awsdns-52.net:53 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>List of nameserver the PUBLIC domain is hosted on.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Operator will then try to resolve the names using the specified nameserver only.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_issue_a_new_certificate">Issue a new certificate&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>At this step, we can create a Certificate:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: bookimport-cert &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: bookimport &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
spec:
dnsNames:
- bookimport.apps.ocp.aws.ispworld.at &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
secretName: bookimport.apps.ocp.aws.ispworld.at-certificate &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Name of the certificate objects&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Application namespace&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>List of domain names&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Issuer that shall be used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>Name of the Secret that will be created and hold the certificate information&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_create_a_route">Create a Route&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>After a while the certificate will be &lt;strong>Ready&lt;/strong>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get certificate/bookimport-cert -n bookimport
NAME READY SECRET AGE
bookimport-cert True bookimport.apps.ocp.aws.ispworld.at-certificate 87m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now we can create a Route object to configure the IngressController. The important part here is the annotation, which will tell the Cert Utils Operator to automatically inject the certificate.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Route
apiVersion: route.openshift.io/v1
metadata:
name: bookimport-tls
namespace: bookimport
annotations:
cert-utils-operator.redhat-cop.io/certs-from-secret: bookimport.apps.ocp.aws.ispworld.at-certificate &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
spec:
host: bookimport.apps.ocp.aws.ispworld.at &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
to:
kind: Service
name: book-import
weight: 100
tls:
termination: edge
port:
targetPort: web
wildcardPolicy: None&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Annotation that points to the Secret which stored the certificate. The values of this Secret will be automatically injected into this Route object.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The hostname for our Route&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see, the Browser will show no warning when opening the URL.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/cert-manager/bookimport-tls.png?width=480px" alt="BookimportTLS"/>
&lt;/div>
&lt;div class="title">Figure 4. Book Import using HTTPS&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_cluster_default_certificates">Cluster Default Certificates&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>During a cluster deployment, OpenShift will create self-signed certificates for its API and for the default IngressController *.apps.clusterdomain.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Usually, we want to change them as well. So why not use the Cert-Manager to issue the appropriate certificates?&lt;/p>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_default_ingresscontroller">Default IngressController&lt;/h3>
&lt;div class="paragraph">
&lt;p>For the default IngressController I create a certificate request with 2 domain names: the wildcard and the base domain (just to be sure, actually the wildcard should be enough)&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: router-certificate
namespace: openshift-ingress &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
spec:
dnsNames:
- apps.ocp.aws.ispworld.at &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- &amp;#39;*.apps.ocp.aws.ispworld.at&amp;#39;
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod
secretName: router-certificate &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The default IngressController runs in the namespace &lt;strong>openshift-ingress&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>List of domains&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Name of the Secret that will be created once the Certificate has been approved.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After a while, the certificate request should be &lt;strong>Ready&lt;/strong> again. In the namespace &lt;em>openshift-ingress&lt;/em> a Secret will be available with the name &lt;em>router-certificate&lt;/em>&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_api">API&lt;/h3>
&lt;div class="paragraph">
&lt;p>For the API URL we do the same. This time it is stored in the namepsace &lt;strong>openshift-config&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
name: api-certificate
namespace: openshift-config
spec:
dnsNames:
- api.ocp.aws.ispworld.at
issuerRef:
kind: ClusterIssuer
name: letsencrypt-prod
secretName: api-certificate&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
It is possible to create one certificate with all required Domainnames. Just be sure that the Secret is available in the appropriate Namespace.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_patching_api_server_and_ingresscontroller">Patching API Server and IngressController&lt;/h3>
&lt;div class="paragraph">
&lt;p>As a final step we need to patch the IngressController and the API server so they will use the correct Secrets with the officially signed certificates.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># IngressController
oc patch ingresscontroller default -n openshift-ingress-operator --type=merge --patch=&amp;#39;{&amp;#34;spec&amp;#34;: { &amp;#34;defaultCertificate&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;router-certificate&amp;#34; }}}&amp;#39;
# API Server
oc patch apiserver cluster --type=merge -p &amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;servingCerts&amp;#34;: {&amp;#34;namedCertificates&amp;#34;: [{&amp;#34;names&amp;#34;: [&amp;#34;api.ocp.aws.ispworld.at&amp;#34;], &amp;#34;servingCertificate&amp;#34;: {&amp;#34;name&amp;#34;: &amp;#34;api-certificate&amp;#34;}}]}}}&amp;#39; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Be sure to use the correct URL for the API&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will restart a bunch of services. Once everything is up and running again (your can watch using the command &lt;code>watch oc get co&lt;/code>), the correct certificate will be shown in the browser:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/cert-manager/console-cert.png?width=340px" alt="UI"/>
&lt;/div>
&lt;div class="title">Figure 5. UI&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>or via curl:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">curl -v https://api.ocp.aws.ispworld.at:6443
* Connected to api.ocp.aws.ispworld.at (13.52.208.31) port 6443
[...]
* Server certificate:
* subject: CN=api.ocp.aws.ispworld.at
* start date: Feb 16 15:11:36 2023 GMT
* expire date: May 17 15:11:35 2023 GMT
* subjectAltName: host &amp;#34;api.ocp.aws.ispworld.at&amp;#34; matched cert&amp;#39;s &amp;#34;api.ocp.aws.ispworld.at&amp;#34;
* issuer: C=US; O=Let&amp;#39;s Encrypt; CN=R3
* SSL certificate verify ok.&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_summary">Summary&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now with these steps, it is possible to issue new Certificates. Of course, there I many more options to configure a certificate. I encourage everybody to read the official documentation of the &lt;a href="https://cert-manager.io/docs/">Cert Manager&lt;/a>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Especially, if you are interested in the whole certificate &lt;a href="https://cert-manager.io/docs/concepts/certificate/#certificate-lifecycle">Certificate Lifecycle&lt;/a>&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Using ServerSideApply with ArgoCD</title><link>https://blog.stderr.at/openshift/2022/11/using-serversideapply-with-argocd/</link><pubDate>Fri, 04 Nov 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2022/11/using-serversideapply-with-argocd/</guid><description>&lt;div class="paragraph">
&lt;p>„&lt;em>If it is not in GitOps, it does not exist&lt;/em>“ - However, managing objects partially only by Gitops was always an issue, since ArgoCD would like to manage the whole object. For example, when you tried to work with node labels and would like to manage them via Gitops, you would need to put the whole node object into ArgoCD. This is impractical since the node object is very complex and typically managed by the cluster.
There were 3rd party solutions (like the patch operator), that helped with this issue.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>However, with the Kubernetes feature &lt;strong>Server-Side Apply&lt;/strong> this problem is solved. Read further to see a working example of this feature.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_what_is_server_side_apply_ssa">What is Server-Side Apply (SSA)&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Quoting from &lt;a href="https://kubernetes.io/docs/reference/using-api/server-side-apply/">Kuberneted Documentation&lt;/a>:&lt;/p>
&lt;/div>
&lt;hr/>
&lt;div class="paragraph">
&lt;p>&lt;em>Server-Side Apply helps users and controllers manage their resources through declarative configurations. Clients can create and modify their objects declaratively by sending their fully specified intent.&lt;/em>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;em>A fully specified intent is a partial object that only includes the fields and values for which the user has an opinion. That intent either creates a new object or is combined, by the server, with the existing object.&lt;/em>&lt;/p>
&lt;/div>
&lt;hr/>
&lt;div class="paragraph">
&lt;p>In other words: you can send a snippet of an object to the cluster and the cluster will eventually combine everything on the server and not validate on the client side first. All you need is a way to identify the object. Usually, the name and maybe the namespace too.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_ssa_and_argocd">SSA and ArgoCD&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>When it comes to GitOps the implementation of SSA is quite new. However, it is important to note, that (managed field) conflicts are currently not handled by ArgoCD. Instead, ArgoCD forces a change and overrides everything, even if the field is managed by somebody else. This might be improved in the future. Nevertheless …​ let’s test the feature.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The support of the Server-Side Apply feature is currently available in the &lt;strong>latest&lt;/strong> version of ArgoCD. This means, that the channel of the openshift-gitops operator must be changed to &amp;#34;latest&amp;#34;, which will deploy openshift-gitops version &lt;strong>1.6&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>A new stable version will arrive soon. :)&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_node_labelling_chart">Node Labelling Chart&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>In this example, I would like to use a Helm chart that will try to set two different labels on 2 nodes. This is a very easy example to demonstrate the feature.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a Helm chart, I have prepared the following: &lt;a href="https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/node-configuration" class="bare">https://github.com/tjungbauer/openshift-clusterconfig-gitops/tree/main/clusters/management-cluster/node-configuration&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The values for this chart are straightforward: per node, a list of custom labels is defined.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">helper-server-side-apply:
nodes: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
- name: ip-10-0-233-237.us-west-1.compute.internal &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
enabled: true
custom_labels: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
environment: &amp;#39;Production&amp;#39;
gpu: false
- name: ip-10-0-193-67.us-west-1.compute.internal
enabled: true
custom_labels:
environment: &amp;#39;Test&amp;#39;
gpu: true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>List of nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Node name as OpenShift knows the node (&lt;em>oc get nodes&lt;/em>)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>List of labels that should be added to the node: here environment and gpu&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The Chart is using a sub-chart called &lt;strong>helper-server-side-apply&lt;/strong>. The source can be found at the &lt;a href="https://github.com/tjungbauer/helm-charts/tree/main/charts/helper-server-side-apply">Helm Repository&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The output of this Helm Chart will be the following:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"># Source: node-labels/charts/helper-server-side-apply/templates/node.yaml
kind: Node
apiVersion: v1
metadata:
name: &amp;#34;ip-10-0-233-237.us-west-1.compute.internal&amp;#34; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
labels:
gitops.ownedBy: openshift-gitops
helm.sh/chart: helper-server-side-apply-1.0.3
app.kubernetes.io/name: helper-server-side-apply
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
environment: &amp;#34;Production&amp;#34; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
gpu: &amp;#34;false&amp;#34; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
---
# Source: node-labels/charts/helper-server-side-apply/templates/node.yaml
kind: Node
apiVersion: v1
metadata:
name: &amp;#34;ip-10-0-193-67.us-west-1.compute.internal&amp;#34;
labels:
gitops.ownedBy: openshift-gitops
helm.sh/chart: helper-server-side-apply-1.0.3
app.kubernetes.io/name: helper-server-side-apply
app.kubernetes.io/instance: release-name
app.kubernetes.io/managed-by: Helm
environment: &amp;#34;Test&amp;#34;
gpu: &amp;#34;true&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The name of the node and our identifier&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>The first label we set&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The second label we set&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
This is not a full definition of a Node object. The only things defined are the node name and the labels. (Besides the customer labels we would like to add, some default labels are added automatically.)
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_argocd_application">ArgoCD Application&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>So we have a Helm chart in Git. Perfect, but to automate everything with Gitops we need to create the object &lt;strong>Application&lt;/strong>. For example the following:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
name: node-labelling
namespace: openshift-gitops
spec:
destination:
namespace: default
server: &amp;#39;https://kubernetes.default.svc&amp;#39;
info:
- name: Description
value: Deploy Node Labels
project: default
source:
helm:
valueFiles:
- values.yaml
path: clusters/management-cluster/node-configuration &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
repoURL: &amp;#39;https://github.com/tjungbauer/openshift-clusterconfig-gitops&amp;#39;
targetRevision: main
syncPolicy:
syncOptions:
- ServerSideApply=true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
- Validate=false &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Path and URL of the node labelling Helm chart&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Must be set to &lt;strong>true&lt;/strong> to enable SSA&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Must be set to &lt;strong>false&lt;/strong> to skip schema validation&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The two &lt;strong>syncOptions&lt;/strong> are important to set. Since the yaml output might not pass the validation, the schema validation should be disabled.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will create the following application in ArgoCD:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/argocd2/argocd-app-nodelabelling.png?width=840px" alt="ApplicationSet"/>
&lt;/div>
&lt;div class="title">Figure 1. Argo CD: Application&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_syncing_the_application">Syncing the Application&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>When you now synchronize the ArgoCD application, ArgoCD will take the yaml and will tell Kubernetes (or OpenShift) to perform a Server-Side Apply. This will result in the following yaml for the node:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">kind: Node
apiVersion: v1
metadata:
name: ip-10-0-193-67.us-west-1.compute.internal
labels:
beta.kubernetes.io/os: linux
app.kubernetes.io/instance: node-labelling
[...]
node-role.kubernetes.io/worker: &amp;#39;&amp;#39;
gitops.ownedBy: openshift-gitops
[...]
environment: Test
[...]&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>That’s it …​ all the magic is done.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Secrets Management - Vault on OpenShift</title><link>https://blog.stderr.at/openshift/2022/08/secrets-management-vault-on-openshift/</link><pubDate>Tue, 16 Aug 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2022/08/secrets-management-vault-on-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>Sensitive information in OpenShift or Kubernetes is stored as a so-called Secret. The management of these Secrets is one of the most important questions,
when it comes to OpenShift. Secrets in Kubernetes are encoded in base64. This is &lt;strong>not&lt;/strong> an encryption format.
Even if etcd is encrypted at rest, everybody can decode a given base64 string which is stored in the Secret.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For example: The string &lt;code>Thomas&lt;/code> encoded as base64 is &lt;code>VGhvbWFzCg==&lt;/code>. This is simply a masked plain text and it is not secure to share these values, especially not on Git.
To make your CI/CD pipelines or Gitops process secure, you need to think of a secure way to manage your Secrets. Thus, your Secret objects must be encrypted somehow. HashiCorp Vault is one option to achieve this requirement.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_hashicorp_vault">HashiCorp Vault&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>HashiCorp Vault is a solution to solve our Secret management problem. It stores and encrypts our sensitive information at rest and in transit and enables you to create fine grained access
controls (ACL). This defines who has access to a specific secret. Application A should only get access to secret A and so on. However, that is just the tip of the iceberg. Vault can do much more.
If you are interested in further details, check out the introduction video by Armon, the Co-Founder of Hashicorp Vault at: &lt;a href="https://learn.hashicorp.com/tutorials/vault/getting-started-intro?in=vault/getting-started" class="bare">https://learn.hashicorp.com/tutorials/vault/getting-started-intro?in=vault/getting-started&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For this article we will keep it simple and cover:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Installing HashiCorp Vault to OpenShift&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Integrating the plugin &amp;#34;Kubernetes Authentication&amp;#34; to access the Secrets&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Accessing a static secret stored in HashiCorp Vault by an example application&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_installing_vault">Installing Vault&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The easiest way to install Vault is by using the supported Helm chart.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Add the Helm repository to your repo:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">helm repo add hashicorp https://helm.releases.hashicorp.com&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Update the repository to get the latest updates.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">helm repo update&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Before we install Vault, we need to create a values file to set certain variables. Let’s create a file called &amp;#34;overwrite-values.yaml&amp;#34; with the following content&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">global:
openshift: true
server:
ha:
enabled: true
replicas: 3
raft:
enabled: true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will tell HashiCorp Vault the environment we are going to install is (OpenShift), enables high availability with 3 replicas and enables RAFT (see below for some introduction).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Finally, let us deploy HashiCorp Vault into the namespace &lt;strong>vault&lt;/strong> using the values file we have created in the previous step:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">helm upgrade --install vault hashicorp/vault --values bootstrap/vault/overwrite-values.yaml --namespace=vault --create-namespace&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will start the agent-injector and 3 vault-pods:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get pods -n vault
NAME READY STATUS RESTARTS AGE
vault-0 0/1 Running 0 36s
vault-1 0/1 Running 0 36s
vault-2 0/1 Running 0 36s
vault-agent-injector-74c848f67b-sq4dq 1/1 Running 0 37s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>vault agent injector: detecting applications with annotations that require vault agent which will get injected&lt;/p>
&lt;/li>
&lt;li>
&lt;p>vault-0: vault server&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The vault servers remain in &lt;strong>not-ready&lt;/strong> state until Vault has been unsealed by you.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When you check the logs of one of the pods you will see:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc logs vault-0 -n vault
...
2022-08-11T12:31:22.497Z [INFO] core: security barrier not initialized
2022-08-11T12:31:22.497Z [INFO] core: seal configuration missing, not initialized&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Vault always starts uninitialized and sealed, to protect the secrets. You need to give at least three different unseal-keys in order to be able to use Vault.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Vault’s seal mechanism uses &lt;a href="https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing" target="_blank" rel="noopener">Shamir’s secret sharing&lt;/a>. This is a manual process to secure the cluster if it restarts. You can use auto-unseal for specific cloud providers to bypass the manual requirement.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_raft_storage">Raft Storage&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>During the deployment we have enabled Raft which is the integrated HA storage for Vault. Vault can use several different styles of storage backends, but when it comes to HA and Kubernetes, Raft is
easiest one since it has no other dependencies, and it is well known inside OpenShift. Etcd is using Raft as well. It is a distributed Consensus Algorithm where multiple members form a cluster and elect one leader. The leader has the responsibility to replicate everything to the followers. Since this leader election requires a majority an odd number of cluster members must be available to ensure there is a minimum number left if a member is failing.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_initialize_and_unseal_vault">Initialize and Unseal Vault&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As mentioned, the Vault Pods are not fully available yet, since Vault it currently sealed and cannot be used. The first thing to do is to initialize and unseal it.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
The following commands will login into one Pod and execute commands from there.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s get the status of our Vault fist:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault operator init -status&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will return the message:
&lt;code>Vault is not initialized&lt;/code>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following command will initialize Vault for further usage:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti -n vault vault-0 -- vault operator init -format=json &amp;gt; unseal.json&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will create the file &lt;strong>unseal.json&lt;/strong> locally on your machine. &lt;strong>Keep this file secure&lt;/strong> It contains by default 5 key shards and the root token you will need to unseal Vault and authenticate as root.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Keep this file secure, it contains keys to unseal Vault and the root_token to authenticate against.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Never share this file. It will look like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">{
&amp;#34;unseal_keys_b64&amp;#34;: [
&amp;#34;key_1&amp;#34;,
&amp;#34;key_2&amp;#34;,
&amp;#34;key_3&amp;#34;,
&amp;#34;key_4&amp;#34;,
&amp;#34;key_5&amp;#34;
],
&amp;#34;unseal_keys_hex&amp;#34;: [
&amp;#34;key_hex_1&amp;#34;,
&amp;#34;key_hex_2&amp;#34;,
&amp;#34;key_hex_3&amp;#34;,
&amp;#34;key_hex_4&amp;#34;,
&amp;#34;key_hex_5&amp;#34;
],
&amp;#34;unseal_shares&amp;#34;: 5,
&amp;#34;unseal_threshold&amp;#34;: 3,
&amp;#34;recovery_keys_b64&amp;#34;: [],
&amp;#34;recovery_keys_hex&amp;#34;: [],
&amp;#34;recovery_keys_shares&amp;#34;: 5,
&amp;#34;recovery_keys_threshold&amp;#34;: 3,
&amp;#34;root_token&amp;#34;: &amp;#34;root.token&amp;#34;
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With the initialization in place Vault is put into a sealed mode. This means Vault cannot decrypt secrets at this moment.
To unseal Vault you need the unseal key, which is split into multiple shards using &lt;a href="https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing" target="_blank" rel="noopener">Shamir’s secret sharing&lt;/a>. A certain number of individual shards (default 3) must be provided to reconstruct the unseal key.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To unseal Vault lets login to our Pod &amp;#34;vault-0&amp;#34; and unseal it. Use the following command and provide one of the keys:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti -n vault vault-0 -- vault operator unseal
Unseal Key (will be hidden):
Key Value
--- -----
Seal Type shamir
Initialized true &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Sealed true &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
Total Shares 5
Threshold 3
Unseal Progress 1/3 &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
Unseal Nonce 08b01535-be15-e865-251c-f948ed0661c9
Version 1.11.2
Build Date 2022-07-29T09:48:47Z
Storage Type raft
HA Enabled true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Vault is initialized&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Vault is still sealed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The unseal progress: Currently 1 out of 3 keys have been provided&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Use the same command another 2 times using &lt;strong>different&lt;/strong> keys to complete the unseal process:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>At the end the following output should be shown:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Unseal Key (will be hidden):
Key Value
--- -----
Seal Type shamir
Initialized true
Sealed false &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
Total Shares 5
Threshold 3
Version 1.11.2
Build Date 2022-07-29T09:48:47Z
Storage Type raft
Cluster Name vault-cluster-f7402e5b &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
Cluster ID aff648f0-b3a2-1fdd-12f6-492842b08b2b
HA Enabled true
HA Cluster https://vault-0.vault-internal:8201
HA Mode active &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
Active Since 2022-08-16T07:20:45.828215961Z
Raft Committed Index 36
Raft Applied Index 36&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Vault is now unsealed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Name of our cluster&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>High availability is enabled&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>Vault-0&lt;/strong> is now initialized, but there are 2 other members in our HA cluster which must be added.
Let &lt;strong>vault-1&lt;/strong> and &lt;strong>vault-2&lt;/strong> join the cluster and perform the same unseal process as previously: use 3 different keys:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti vault-1 -n vault -- vault operator raft join http://vault-0.vault-internal:8200
# 3 times....
oc exec -ti vault-1 -n vault -- vault operator unseal
oc exec -ti vault-2 -n vault -- vault operator raft join http://vault-0.vault-internal:8200
# 3 times...
oc exec -ti vault-2 -n vault -- vault operator unseal&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verify_vault_cluster">Verify Vault Cluster&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>To verify if the Raft cluster has successfully been initialized, run the following.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>First, login using the &lt;strong>root_token&lt;/strong>, that was created above, on the vault-0 pod.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti vault-0 -n vault -- vault login
Token (will be hidden): &amp;lt;root_token&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc exec -ti vault-0 -n vault -- vault operator raft list-peers&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This should return:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">Node Address State Voter
---- ------- ----- -----
16ec7490-f621-42ea-976d-5f054cfaeecc vault-0.vault-internal:8201 leader true
60ba2885-432a-c7d3-d280-a824f0acce42 vault-1.vault-internal:8201 follower true
bcc4f551-79bc-47e5-d01b-97fc12d1afa5 vault-2.vault-internal:8201 follower true&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see Vault-0 is the leader while the other two members are followers.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_kubernetes_authentication">Configure Kubernetes Authentication&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>There are multiple ways how an application can interact with Vault. One example is to use Tokens. This is quite easy but has the disadvantage that it does require additional steps of managing the life cycle of such token, moreover they might be shared, which is not what we want.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>HashiCorp Vault supports different authentication methods. One of which is the &lt;strong>Kubernetes Auth Method&lt;/strong> that must be enabled before we can use.
The Kubernetes Auth Method makes use of Jason Web Tokens (JWT)s that are bound to a Service Account. When we tell Vault that a Service Account is fine to authenticate, then a Deployment using this account is able to authenticate and
request Secrets.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Vault has a plugin ecosystem, which allows to enable certain plugins. To enable &lt;strong>Kubernetes Auth Method&lt;/strong> use the following process:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Login vault-0 pods
&lt;code>oc exec -it vault-0 -n vault — /bin/sh&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>execute the command:
&lt;code>vault auth enable kubernetes&lt;/code> which returns:
&lt;em>Success! Enabled kubernetes auth method at: kubernetes/&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set up the Kubernetes configuration to use Vault’s service account JWT.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
the address to the OpenShift API (KUBERNETES_PORT_443_TCP_ADDR) is automatically available via an environment variable.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">vault write auth/kubernetes/config issuer=&amp;#34;&amp;#34; \
token_reviewer_jwt=&amp;#34;$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&amp;#34; \
kubernetes_host=&amp;#34;https://$KUBERNETES_PORT_443_TCP_ADDR:443&amp;#34; \
kubernetes_ca_cert=@/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
Success! Data written to: auth/kubernetes/config&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>With this step authentication against OpenShift is enabled.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configure_a_secret">Configure a Secret&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>With the Kubernetes Auth Method in place we can configure a secret to test our setup. We will use an example application called &lt;strong>expenses&lt;/strong> that has a MySQL database.
The static password to bootstrap this database shall be stored in Vault. A plugin called &lt;strong>key-value secrets&lt;/strong> engine will be used to achieve this.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There are other plugins that are specifically designed to automatically rotate secrets. For example, it is possible to dynamically create user credentials für MySQL.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
You can list available engines by using the command: &lt;code>oc -n vault exec -it vault-0 — vault secrets list&lt;/code>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There are currently two versions of this key/value engine:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>KV Version 1: does not versionize the key/values, thus updates will overwrite the old values.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>KV Version 2: does versionize the key/value pairs&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our example we will use version 2.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Like the authentication method, we need to enable the secrets engine:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault secrets enable \
-path=expense/static \ &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
-version=2 \ &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
kv &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>API path where our secrets are stored&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Version 2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>name of our engine&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You can list the enabled engines with the following command:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault secrets list
Path Type Accessor Description
---- ---- -------- -----------
cubbyhole/ cubbyhole cubbyhole_f1e955f9 per-token private secret storage
expense/static/ kv kv_6db09e5d n/a
identity/ identity identity_ca05e6ab identity store &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
sys/ system system_e34a76c3 system endpoints used for control, policy and debugging&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Enabled KV secrets engine using the path &lt;strong>expense/static/&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now lets put a secret into our store. We will store our super-secure MySQL password into &lt;strong>expense/static/mysql&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">MYSQL_DB_PASSWORD=mysuperpassword$
oc -n vault exec -it vault-0 -- vault kv put expense/static/mysql db_login_password=${MYSQL_DB_PASSWORD}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This command will store the key &lt;strong>db_login_password&lt;/strong> with the database as value. We can get the secret by calling:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault kv get expense/static/mysql
====== Secret Path ======
expense/static/data/mysql &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
======= Metadata =======
Key Value
--- -----
created_time 2022-08-17T06:08:05.839663508Z
custom_metadata &amp;lt;nil&amp;gt;
deletion_time n/a
destroyed false
version 1
========== Data ==========
Key Value
--- -----
db_login_password mysuperpassword$ &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The data path of our secret&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>our password&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_configuring_policies">Configuring policies&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The Secret is now stored at &lt;strong>expense/static/mysql&lt;/strong> but there is no policy in place. Everybody who is authenticated and is calling this path will get to see the secrets.
Luckily, one or more policies can be assigned to the authentication method. A policy defines capabilities that allow you to perform certain actions.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following capabilities are known:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;strong>create&lt;/strong> - to create new data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>read&lt;/strong> - to read data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>delete&lt;/strong> - to delete data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>list&lt;/strong> - to list data&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Policies can be written either in JSON or HCL (HashiCorp Configuration Language). Let’s create a file with the following content:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">path &amp;#34;expense/static/data/mysql&amp;#34; {
capabilities = [&amp;#34;read&amp;#34;, &amp;#34;list&amp;#34;]
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
KV Version2 stores the secrets in a path with the prefix &lt;code>data/&lt;/code>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will limit my access to &lt;strong>read&lt;/strong> and &lt;strong>list&lt;/strong> only.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Write the policy:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">cat my-policy.hcl | oc -n vault exec -it vault-0 -- vault policy write expense-db-mysql -&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Next, we are going to bind the Vault secret to a service account and a namespace. Both objects will be created later, when we deploy the application.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n vault exec -it vault-0 -- vault write auth/kubernetes/role/expense-db-mysql \ &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
bound_service_account_names=expense-db-mysql \ &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
bound_service_account_namespaces=expenses \ &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
policies=expense-db-mysql \ &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
ttl=1h &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Path or our new role&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Name of the service account we will create and that will be used by the application&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Name of the namespace we will create&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Name of the policy we created earlier&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The token is valid for 1 hour, after this period the service account must re-authenticate&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_lets_start_an_application">Let’s start an Application&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now we will create our MySQL application into the namespace &lt;strong>expenses&lt;/strong>. Use the following command to create the namespace and the application containing the objects Deployment, ServiceAccount (expense-db-mysql) and Service.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
See at the &lt;a href="https://raw.githubusercontent.com/joatmon08/vault-argocd/part-1/database/deployment.yaml" target="_blank" rel="noopener">Github Page&lt;/a> for a full yaml specification of the three objects.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc new-project expenses
oc apply -f https://raw.githubusercontent.com/joatmon08/vault-argocd/part-1/database/deployment.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The deployment will start a Pod with a sidecar container &lt;strong>vault-agent&lt;/strong>. This sidecar is automatically created and must not be defined inside the Deployment specification.
Instead, some annotations in the Deployment define what the container should be automatically injected and also where to find our secret:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> annotations:
vault.hashicorp.com/agent-inject: &amp;#34;true&amp;#34; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
vault.hashicorp.com/role: &amp;#34;expense-db-mysql&amp;#34; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
vault.hashicorp.com/agent-inject-secret-db: &amp;#34;expense/static/data/mysql&amp;#34; &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
vault.hashicorp.com/agent-inject-template-db: | &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
{{ with secret &amp;#34;expense/static/data/mysql&amp;#34; -}}
export MYSQL_ROOT_PASSWORD=&amp;#34;{{ .Data.data.db_login_password }}&amp;#34;
{{- end }}
...
spec:
serviceAccountName: expense-db-mysql &lt;i class="conum" data-value="5">&lt;/i>&lt;b>(5)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Defines that the &lt;strong>vault-agent&lt;/strong> side car container shall be automatically injected. This is the most important annotation.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Name of the role that was created created previously&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>The agent will inject the data from &lt;strong>expense/static/data/mysql&lt;/strong> and stores it in a file &lt;strong>db&lt;/strong> The file name is everything that comes after &lt;strong>vault.hashicorp.com/agent-inject-secret-&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Configuration…​ the template that defines how the secret will be rendered&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="5">&lt;/i>&lt;b>5&lt;/b>&lt;/td>
&lt;td>The service account name we bound our secret to, using the Consul language. In this case the MySQL password is simply exported&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The vault-agent is requesting the database password from Vault and provides it to the application where it is stored at &lt;code>/vault/secrets/db&lt;/code>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc -n expenses exec -it $(oc get pods -l=app=expense-db-mysql -o jsonpath=&amp;#39;{.items[0].metadata.name}&amp;#39;) -c expense-db-mysql -- cat /vault/secrets/db
# output
export MYSQL_ROOT_PASSWORD=&amp;#34;mysuperpassword$&amp;#34;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Deployment sources this file when it starts and MySQL will take this information to configure itself.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_tip_using_vault_cli_on_your_local_environment">TIP: Using vault CLI on your local environment&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>All above commands that are dealing with Vault commands, first login to a pod and then execure the commands from there.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>If you have the &lt;a href="https://www.vaultproject.io/docs/install" target="_blank" rel="noopener">Vault CLI&lt;/a> installed on your local machine, you can open a port forwarding to your Vault cluster at OpenShift and execute the commands locally:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc port-forward -n vault svc/vault 8200
export VAULT_ADDR=http://localhost:8200
vault login
...&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_thanks">Thanks&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Thanks to the wonderful Rosemary Wang and her Github repository: &lt;a href="https://github.com/joatmon08/vault-argocd/tree/part-1" class="bare">https://github.com/joatmon08/vault-argocd/tree/part-1&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Also check out the Youtube Video: &lt;a href="https://www.youtube.com/watch?v=Bce_0qa6ias" target="_blank" rel="noopener">GitOps Guide to the Galaxy (Ep 31) | GitOps With Vault Part 1&lt;/a> in which Rosemary and Christian discuss this setup&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Overview of Red Hat's Multi Cloud Gateway (Noobaa)</title><link>https://blog.stderr.at/openshift/2022/04/overview-of-red-hats-multi-cloud-gateway-noobaa/</link><pubDate>Fri, 22 Apr 2022 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2022/04/overview-of-red-hats-multi-cloud-gateway-noobaa/</guid><description>
&lt;p>
This is my personal summary of experimenting with Red Hat&amp;#39;s Multi
Cloud Gateway (MCG) based on the upstream &lt;a href="https://www.noobaa.io/">Noobaa&lt;/a> project. MCG is part
of Red Hat&amp;#39;s OpenShift Data Foundation (ODF). ODF bundles the upstream
projects &lt;a href="https://ceph.io/en/">Ceph&lt;/a> and &lt;a href="https://noobaa.io">Noobaa&lt;/a>.&lt;/p>
&lt;div id="outline-container-headline-1" class="outline-2">
&lt;h2 id="headline-1">
Overview
&lt;/h2>
&lt;div id="outline-text-headline-1" class="outline-text-2">
&lt;p>
Noobaa, or the Multicloud Gateway (MCG), is a S3 based data federation
tool. It allows you to use S3 backends from various sources and&lt;/p>
&lt;ul>
&lt;li>sync&lt;/li>
&lt;li>replicate&lt;/li>
&lt;li>or simply use existing&lt;/li>
&lt;/ul>
&lt;p>S3 buckets. Currently the following sources, or backing stores are supported:&lt;/p>
&lt;ul>
&lt;li>AWS S3&lt;/li>
&lt;li>Azure Blob&lt;/li>
&lt;li>Google Cloud Storage&lt;/li>
&lt;li>
&lt;p>Any other S3 compatible storage, for example&lt;/p>
&lt;ul>
&lt;li>Ceph&lt;/li>
&lt;li>Minio&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Noobaa also supports using a local file system as a backing store for S3.&lt;/p>
&lt;p>
The main purpose is to provide a single API endpoint for applications
using various S3 backends.&lt;/p>
&lt;p>
One of the main features of Noobaa is the storage pipeline. With a
standard Noobaa S3 bucket, when storing a new Object Noobaa executes
the following steps:&lt;/p>
&lt;ul>
&lt;li>Chunking of the Object&lt;/li>
&lt;li>De-duplication&lt;/li>
&lt;li>Compression&lt;/li>
&lt;li>and Encryption&lt;/li>
&lt;/ul>
&lt;p>This means that data stored in public cloud S3 offerings is
automatically encrypted. Noobaa also supports using Hashicorp &lt;a href="https://www.hashicorp.com/products/vault">Vault&lt;/a>
for storing and retrieving encryption keys.&lt;/p>
&lt;p>
If you need to skip the storage pipeline, Noobaa also supports
namespace buckets. For example these type of buckets allow you to
write directly to AWS S3 and retrieve Objects via Noobaa. Or it could
be used to migrate buckets from one cloud provider to another.&lt;/p>
&lt;p>
Noobaa also has support for triggering JavaScript based function when&lt;/p>
&lt;ul>
&lt;li>creating new objects&lt;/li>
&lt;li>reading existing objects&lt;/li>
&lt;li>deleting objects&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-2" class="outline-2">
&lt;h2 id="headline-2">
Setup
&lt;/h2>
&lt;div id="outline-text-headline-2" class="outline-text-2">
&lt;p>
With OpenShift Plus or an OpenShift Data Foundation subscription you
can use the OpenShift Data Foundation Operator.&lt;/p>
&lt;p>
For testing Noobaa we used the standalone installation method
&lt;span style="text-decoration: underline;">without&lt;/span> setting up Ceph storage (see &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.10/html/deploying_openshift_data_foundation_using_amazon_web_services/deploy-standalone-multicloud-object-gateway">here&lt;/a>). OpenShift was running in
AWS for testing.&lt;/p>
&lt;p>
If you would like to use the upstream version you can use the Noobaa
operator (&lt;a href="https://github.com/noobaa/noobaa-operator">https://github.com/noobaa/noobaa-operator&lt;/a>). This is what the
OpenShift Data Foundation (ODF) is using as well.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-3" class="outline-2">
&lt;h2 id="headline-3">
Command line interface
&lt;/h2>
&lt;div id="outline-text-headline-3" class="outline-text-2">
&lt;p>
Noobaa also comes with a command line interface &lt;code>noobaa&lt;/code>. It&amp;#39;s
available via an ODF subscription or can be installed separately. See
the noobaa-operator &lt;a href="https://github.com/noobaa/noobaa-operator/blob/master/README.md">readme&lt;/a> for more information.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-4" class="outline-2">
&lt;h2 id="headline-4">
Resources
&lt;/h2>
&lt;div id="outline-text-headline-4" class="outline-text-2">
&lt;p>
Before using an S3 object store with Noobaa we need to create so
called &lt;span style="text-decoration: underline;">Resources&lt;/span>. This can be done via the Noobaa user interface or
via the command line. For example the following commands create a new
Resource using an AWS S3 bucket as a backing store&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create an S3 bucket in eu-north-1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aws s3api create-bucket &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-north-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --bucket tosmi-eu-north-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --create-bucket-configuration LocationConstraint&lt;span style="color:#f92672">=&lt;/span>eu-north-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create an S3 bucket in eu-north-1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aws s3api create-bucket &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-west-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --bucket tosmi-eu-west-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --create-bucket-configuration LocationConstraint&lt;span style="color:#f92672">=&lt;/span>eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create Noobaa backing store using the tosmi-eu-north-1 bucket above&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>noobaa backingstore create aws-s3 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-north-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --target-bucket tosmi-eu-north-1 aws-eu-north
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create Noobaa backing store using the tosmi-eu-west-1 bucket above&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>noobaa backingstore create aws-s3 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --region eu-west-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --target-bucket tosmi-eu-west-1 aws-eu-west&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Or if we would like to use Azure blob&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create two resource groups for storage&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az group create --location northeurope -g mcg-northeurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create two storage accounts&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account create --name mcgnortheurope -g mcg-northeurope --location northeurope --sku Standard_LRS --kind StorageV2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># create containers for storing blobs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage container create --account-name mcgnortheurope -n mcg-northeurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># list storage account keys for noobaa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account list
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account show -g mcg-northeurope -n mcgnortheurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account keys list -g mcg-westeurope -n mcgwesteurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>az storage account keys list -g mcg-northeurope -n mcgnortheurope
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>noobaa backingstore create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> azure-blob azure-northeurope &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --account-key&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;lt;the key&amp;gt;&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --account-name&lt;span style="color:#f92672">=&lt;/span>mcgnortheurope &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --target-blob-container&lt;span style="color:#f92672">=&lt;/span>mcg-northeurope&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Using&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>noobaa backingstore list&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
we are able to confirm that our stores were created successfully.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-5" class="outline-2">
&lt;h2 id="headline-5">
Buckets
&lt;/h2>
&lt;div id="outline-text-headline-5" class="outline-text-2">
&lt;p>
After creating the backend stores we are able to create Buckets and define the
layout of backends.&lt;/p>
&lt;p>
There are two ways how to create buckets, either directly via the Noobaa UI,
or using Kubernetes (K8s) objects.&lt;/p>
&lt;p>
We will focus on using K8s objects in this post.&lt;/p>
&lt;div id="outline-container-headline-6" class="outline-3">
&lt;h3 id="headline-6">
Required K8s objects
&lt;/h3>
&lt;div id="outline-text-headline-6" class="outline-text-3">
&lt;p>
The Noobaa operator provides the following Custom Resource Definitions:&lt;/p>
&lt;ul>
&lt;li>&lt;code>BackingStore&lt;/code>: we already created &lt;code>BackingStores&lt;/code> in the Resources
section&lt;/li>
&lt;li>&lt;code>BucketClass&lt;/code>: a bucket class defines the layout of our bucket
(single, mirrored or tiered)&lt;/li>
&lt;li>&lt;code>StorageClass&lt;/code>: a standard K8s &lt;code>StorageClass&lt;/code> referencing the &lt;code>BucketClass&lt;/code>&lt;/li>
&lt;li>&lt;code>ObjectBucketClaim&lt;/code>: A OBC or &lt;code>ObjectBucketClaim&lt;/code> creates the bucket
for us in Noobaa. Additionally the Noobaa operator creates a
&lt;code>ConfigMap&lt;/code> and a &lt;code>Secret&lt;/code> with the same name as the Bucket, storing
access details (&lt;code>ConfigMap&lt;/code>) and credentials (&lt;code>Secret&lt;/code>) for accessing
the bucket.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-7" class="outline-3">
&lt;h3 id="headline-7">
BucketClass
&lt;/h3>
&lt;div id="outline-text-headline-7" class="outline-text-3">
&lt;p>
Let&amp;#39;s create a example &lt;code>BucketClass&lt;/code> which mirrors objects between the
AWS S3 buckets eu-west-1 and eu-north-1.&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">noobaa.io/v1alpha1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">BucketClass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">noobaa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-bucket-class&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">openshift-storage&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">placementPolicy&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">tiers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">backingStores&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">aws-eu-north&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">aws-eu-west&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">placement&lt;/span>: &lt;span style="color:#ae81ff">Mirror&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
So we are defining a &lt;code>BucketClass&lt;/code> &lt;span style="text-decoration: underline;">aws-mirrored-bucket-class&lt;/span> that
has the following placement policy:&lt;/p>
&lt;ul>
&lt;li>A single tier with one backing store&lt;/li>
&lt;li>
&lt;p>The backing store uses two AWS buckets&lt;/p>
&lt;ul>
&lt;li>aws-eu-north&lt;/li>
&lt;li>aws-eu-west&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>The placement policy is mirror, so all objects uploaded to buckets
using this &lt;code>BucketClass&lt;/code> will be mirrored between &lt;span style="text-decoration: underline;">aws-eu-north&lt;/span> and
&lt;span style="text-decoration: underline;">aws-eu-west&lt;/span>.&lt;/li>
&lt;/ul>
&lt;p>A &lt;code>BucketClass&lt;/code> could have multiple tiers, moving cold data
transparently to a lower tier, but let&amp;#39;s keep this simple.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-8" class="outline-3">
&lt;h3 id="headline-8">
StorageClass
&lt;/h3>
&lt;div id="outline-text-headline-8" class="outline-text-3">
&lt;p>
After creating our &lt;code>BucketClass&lt;/code> we are now able to define a standard
K8s &lt;code>StorageClass&lt;/code>:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">storage.k8s.io/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">StorageClass&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">annotations&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">description&lt;/span>: &lt;span style="color:#ae81ff">Provides Mirrored Object Bucket Claims (OBCs) in AWS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-openshift-storage.noobaa.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">parameters&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">bucketclass&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-bucket-class&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">provisioner&lt;/span>: &lt;span style="color:#ae81ff">openshift-storage.noobaa.io/obc&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">reclaimPolicy&lt;/span>: &lt;span style="color:#ae81ff">Delete&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">volumeBindingMode&lt;/span>: &lt;span style="color:#ae81ff">Immediate&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
This &lt;code>StorageClass&lt;/code> uses our &lt;code>BucketClass&lt;/code> &lt;span style="text-decoration: underline;">aws-mirrored-bucket-class&lt;/span>
as a backend. All buckets created leveraging this &lt;code>StorageClass&lt;/code> will
mirror data between &lt;span style="text-decoration: underline;">aws-eu-north&lt;/span> and &lt;span style="text-decoration: underline;">aws-eu-west&lt;/span> (see the previous
chapter).&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="outline-container-headline-9" class="outline-3">
&lt;h3 id="headline-9">
ObjectBucketClaim
&lt;/h3>
&lt;div id="outline-text-headline-9" class="outline-text-3">
&lt;p>
Finally we are able to create &lt;code>ObjectBucketClaims&lt;/code> for projects
requiring object storage. An &lt;code>ObjectBucketClaim&lt;/code> is similar to an
&lt;code>PersistentVolumeClaim&lt;/code>. Every time a claim is created the Noobaa
operator will create a corresponding S3 bucket for us.&lt;/p>
&lt;p>
Let&amp;#39;s start testing this out by creating a new OpenShift project&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>oc new-project obc-test&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Now we define a &lt;code>ObjectBucketClaim&lt;/code> to create a new bucket for our application:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">objectbucket.io/v1alpha1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ObjectBucketClaim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">labels&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">app&lt;/span>: &lt;span style="color:#ae81ff">noobaa&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">generateBucketName&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">storageClassName&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-openshift-storage.noobaa.io&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We use the &lt;code>StorageClass&lt;/code> created in the previous step. This will create&lt;/p>
&lt;ul>
&lt;li>a S3 Bucket in the requested &lt;code>StorageClass&lt;/code>&lt;/li>
&lt;li>a &lt;code>ConfigMap&lt;/code> storing access information&lt;/li>
&lt;li>a &lt;code>Secret&lt;/code> storing credentials for accessing the S3 Bucket&lt;/li>
&lt;/ul>
&lt;p>For testing we will upload some data via &lt;a href="https://s3tools.org/s3cmd">&lt;span style="text-decoration: underline;">s3cmd&lt;/span>&lt;/a> and use a pod to monitor
data within the bucket.&lt;/p>
&lt;p>
Let&amp;#39;s do the upload with &lt;span style="text-decoration: underline;">s3cmd&lt;/span>, we need the following config file:&lt;/p>
&lt;div class="src src-ini">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ini" data-lang="ini">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">[default]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">check_ssl_certificate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">check_ssl_hostname&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">access_key&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;lt;access key&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">secret_key&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;lt;secret key&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">host_base&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">s3-openshift-storage.apps.ocp.aws.tntinfra.net&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">host_bucket&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">%(bucket).s3-openshift-storage.apps.ocp.aws.tntinfra.net&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Of course you must change &lt;span style="text-decoration: underline;">host-base&lt;/span> according to your cluster
name. It&amp;#39;s a route in the &lt;span style="text-decoration: underline;">openshift-storage&lt;/span> namespace:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>oc get route -n openshift-storage s3 -o jsonpath&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;{.spec.host}&amp;#39;&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
You can extract the access and secret key from the
K8s secret via:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>oc extract secret/aws-mirrored-claim --to&lt;span style="color:#f92672">=&lt;/span>-&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Copy the access key and the secret key to the s3 command config file
(we&amp;#39;ve called our config &lt;span style="text-decoration: underline;">noobaa-s3.cfg&lt;/span>). Now we can list all
available buckets via:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ s3cmd ls -c noobaa-s3.cfg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2022-04-22 13:56 s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Now we are going to upload a sample file:&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>$ s3cmd -c noobaa-s3.cfg put simple-aws-mirrored-obc.yaml s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>upload: &lt;span style="color:#e6db74">&amp;#39;simple-aws-mirrored-obc.yaml&amp;#39;&lt;/span> -&amp;gt; &lt;span style="color:#e6db74">&amp;#39;s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4/simple-aws-mirrored-obc.yaml&amp;#39;&lt;/span> &lt;span style="color:#f92672">[&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> of 1&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#ae81ff">226&lt;/span> of &lt;span style="color:#ae81ff">226&lt;/span> 100% in 0s 638.18 B/s &lt;span style="color:#66d9ef">done&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
We can also list available files via&lt;/p>
&lt;div class="src src-sh">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>s3cmd -c noobaa-s3.cfg ls s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2022-04-22 13:57 &lt;span style="color:#ae81ff">226&lt;/span> s3://aws-mirrored-c1087a17-5c84-4c62-9f36-29081a6cf5a4/simple-aws-mirrored-obc.yaml&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Our we could use a &lt;code>Pod&lt;/code> to list available files from within
OpenShift. Note how we use the &lt;code>ConfigMap&lt;/code> and the &lt;code>Secret&lt;/code> the Noobaa
operater created for us, when we created the &lt;code>ObjectBucketClaim&lt;/code>:&lt;/p>
&lt;div class="src src-yaml">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">batch/v1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Job&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">s3-test-job&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">template&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">metadata&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">s3-pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">spec&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">containers&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">d3fk/s3cmd:latest&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">s3-pod&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_NAME&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMapKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_NAME&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_HOST&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMapKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_HOST&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_PORT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">configMapKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">BUCKET_PORT&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">AWS_ACCESS_KEY_ID&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">secretKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">AWS_ACCESS_KEY_ID&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">AWS_SECRET_ACCESS_KEY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">valueFrom&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">secretKeyRef&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">aws-mirrored-claim&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">key&lt;/span>: &lt;span style="color:#ae81ff">AWS_SECRET_ACCESS_KEY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">command&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">/bin/sh&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - -&lt;span style="color:#ae81ff">c&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#39;s3cmd --host $BUCKET_HOST --host-bucket &amp;#34;%(bucket).$BUCKET_HOST&amp;#34; --no-check-certificate ls s3://$BUCKET_NAME&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">restartPolicy&lt;/span>: &lt;span style="color:#ae81ff">Never&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
That&amp;#39;s all for now. If time allows we are going to write a follow up blog post on&lt;/p>
&lt;ul>
&lt;li>Replicating Buckets and&lt;/li>
&lt;li>Functions&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Secure your secrets with Sealed Secrets</title><link>https://blog.stderr.at/openshift/2021/09/secure-your-secrets-with-sealed-secrets/</link><pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021/09/secure-your-secrets-with-sealed-secrets/</guid><description>&lt;div class="paragraph">
&lt;p>Working with a GitOps approach is a good way to keep all configurations and settings versioned and in sync on Git. Sensitive data, such as passwords to a database connection, will quickly come around.
Obviously, it is not a idea to store clear text strings in a, maybe even public, Git repository. Therefore, all sensitive information should be stored in a secret object. The problem with secrets in Kubernetes is that they are actually not encrypted. Instead, strings are base64 encoded which can be decoded as well. Thats not good …​ it should not be possible to decrypt secured data. Sealed Secret will help here…​&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Sealed Secrets by Bitnami[&lt;a href="#source_1">1&lt;/a>] is one option to create real, encrypted secrets. It contains two parts:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>A cluster-side controller / operator, which decrypts the secrets server-side on OpenShift installed in a dedicated namespace usually called &lt;code>sealed secrets&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>kubeseal&lt;/code> - a client-side command line tool&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_prerequisites">Prerequisites&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>An OpenShift 4 cluster with cluster-admin permissions.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_sealed_secrets_operator">Sealed Secrets Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Goto &lt;strong>OperatorHub&lt;/strong> and search for Sealed Secrets (This is a Community Operator)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/sealed-secrets/sealed-secrets-operatorhub.png?width=480px" alt="Search Sealed Secrets in OperatorHub"/>
&lt;/div>
&lt;div class="title">Figure 1. Search Sealed Secrets in OperatorHub&lt;/div>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Install the operator, using the default settings, into the namespace &lt;code>sealed-secrets&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/sealed-secrets/sealed-secrets-operator-install.png?width=480px" alt="Installed Sealed Secret Operator"/>
&lt;/div>
&lt;div class="title">Figure 2. Installed Sealed Secret Operator&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_install_the_crd_sealedsecretcontroller">Install the CRD SealedSecretController&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Install the following object. For now the default values can be used.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: bitnami.com/v1alpha1
kind: SealedSecretController
metadata:
name: controller &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
namespace: sealed-secrets
spec:
networkPolicy: false
nodeSelector: {}
podLabels: {}
resources: {}
affinity: {}
securityContext:
fsGroup: &amp;#39;&amp;#39;
runAsUser: &amp;#39;&amp;#39;
rbac:
create: true
pspEnabled: false
crd:
create: true
keep: true
ingress:
annotations: {}
enabled: false
hosts:
- chart-example.local
path: /v1/cert.pem
tls: []
serviceAccount:
create: true
name: &amp;#39;&amp;#39;
image:
pullPolicy: IfNotPresent
repository: &amp;gt;-
quay.io/bitnami/sealed-secrets-controller@sha256:8e9a37bb2e1a6f3a8bee949e3af0e9dab0d7dca618f1a63048dc541b5d554985
secretName: sealed-secrets-key
tolerations: []
controller:
create: true
priorityClassName: &amp;#39;&amp;#39;
podAnnotations: {}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Be aware of the name of the controller OBJECT (name: controller). It is used lated as part of the actual controller name&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_install_the_command_line_tool_kubeseal">Install the command line tool kubeseal&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The kubeseal binary can be easily installed using either&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>on Mac: &lt;code>brew install kubeseal&lt;/code> or&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>on Linux:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.16.0/kubeseal-linux-amd64 -O kubeseal
install -m 755 kubeseal /usr/local/bin/&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_testing_sealed_secrets">Testing Sealed Secrets&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Create a new project &lt;code>oc new-project myproject&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a secret&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">echo -n &amp;#34;my_super_secret_string&amp;#34; \
| kubectl create secret generic mypasswords --dry-run=client --from-file=password=/dev/stdin -o json \
| kubeseal --controller-namespace=sealed-secrets --controller-name=controller-sealed-secrets --format json &amp;gt; mysealedsecret.json &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The switches --controller-namespace define the namespace where the operator is installed, --controller-name is a combination of the SealedSecretController object name and the name of the namespace&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;code>password=my_super_secret_string&lt;/code> is created and piped into &lt;strong>kubeseal&lt;/strong> which is using the controller, where the server created a certificate for encryption, to create an encrypted json file &lt;strong>mysealedsecret.json&lt;/strong>. It is important to note, that the actually Kubernetes secret object is not created at this stage.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The file &lt;strong>mysealedsecret.json&lt;/strong> is encrypted now and it is safe to store this file on Github.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>It looks like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-json" data-lang="json">{
&amp;#34;kind&amp;#34;: &amp;#34;SealedSecret&amp;#34;,
&amp;#34;apiVersion&amp;#34;: &amp;#34;bitnami.com/v1alpha1&amp;#34;,
&amp;#34;metadata&amp;#34;: {
&amp;#34;name&amp;#34;: &amp;#34;mypasswords&amp;#34;,
&amp;#34;namespace&amp;#34;: &amp;#34;myproject&amp;#34;, &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
&amp;#34;creationTimestamp&amp;#34;: null
},
&amp;#34;spec&amp;#34;: {
&amp;#34;template&amp;#34;: {
&amp;#34;metadata&amp;#34;: {
&amp;#34;name&amp;#34;: &amp;#34;mypasswords&amp;#34;,
&amp;#34;namespace&amp;#34;: &amp;#34;myproject&amp;#34;, &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
&amp;#34;creationTimestamp&amp;#34;: null
},
&amp;#34;data&amp;#34;: null
},
&amp;#34;encryptedData&amp;#34;: {
&amp;#34;password&amp;#34;: &amp;#34;AgBsSZVcTfzfNFI7ZlCsH3/4b3L7m52/O9f70pMtn1myPWHeY1QJFoxpWkH0tWosfeIoko+iB0kCyFk/iJEYSvd31zgnr90hv4e2qVtEBmm6n5B7V40ZERdiy2Cz7UXakUKDdhTjA0BTjcf0f0b2FRDenGxCHJB7cyOVGOZ36jF6IdP2k6kbsZXklti/4MXK7oskDXGzU7rTsESK0ttk5uQgrpfWrhaUip5+Db5vcG1OlHhMJ7In3NlNr0mbl+YiXsKKDNvyw9T14L3rlfvHz1xe0lIqC72i5LSCarpGoSKNOr+Sev9+b/+no6P4VDPuSLORbwVXlP5kt+8xnpZJIEqnetwhr78dt8F3xmjXVBZncdwKk22Y/b9L+uUKWPAvOT78khpUIHQPo9dV/nmz1ldvu58fCFL4TjOOtyTBcUPD3qQJp+sEXgy63l8hEaMXuLUlk+srSnJfMtwkFhl0CG2fKsg4CsQoZlvq5oKOl50sujg3Trv4W9qVVCYHA7BUXEj6J0DxjOCqSQixHRr7Z7JqIyhhdLYdHwMH80scsIb6Ok7keC82v1yae770NWWxJJ4M7Ieb2ERzgwy825gkdq9nx9I6fVxYJkkZlpKKoTvL0uno4sKjC1yQjCgW1vpiZeLIJO2f9TpvVdK2nrag0/gXPMboAL2BGnMPMwjR7OZm+iHq3NXNKiIV1aWRO4wkd/spWziLjOpeS7T1k9w4XxoACwv3g4it&amp;#34;
}
}
}&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The sealed secret will be created in your project&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Upload the sealed secret &lt;code>oc create -f mysealedsecret.json&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_verify_secret">Verify Secret&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The object SealedSecret is created:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get SealedSecret
NAME AGE
mypasswords 3s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The SealedSecretController will decrypt the and store the secret in the namespace. This can take a few seconds:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get secret mypasswords
NAME TYPE DATA AGE
mypasswords Opaque 1 25s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Extract the secret and verify that your string has been stored as &amp;#34;normal&amp;#34; secret&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/mypasswords --to=-
# password
my_super_secret_string&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_updating_or_appending_new_values">Updating or appending new values&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The process for updateing or appending a secret is similar. The only difference is that a new value for the key string is new.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># Updaing string
echo -n &amp;#34;my_NEW_super_secret_string&amp;#34; \
| kubectl create secret generic mypasswords --dry-run=client --from-file=password=/dev/stdin -o json \
| kubeseal --controller-namespace=sealed-secrets --controller-name=controller-sealed-secrets --format json --merge-into mysealedsecret.json
# Appending
echo -n &amp;#34;my_appended_string&amp;#34; \
| kubectl create secret generic mypasswords --dry-run=client --from-file=appendedstring=/dev/stdin -o json \
| kubeseal --controller-namespace=sealed-secrets --controller-name=controller-sealed-secrets --format json --merge-into mysealedsecret.json&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Be sure that you are in the namespace you want to install the secret
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Upload the sealed secret &lt;code>oc apply -f mysealedsecret.json&lt;/code> and extract it again to validate:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc extract secret/mypasswords --to=-
# appendedstring
my_appended_string
# password
my_NEW_super_secret_string&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_sources">Sources&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a id="source_1">&lt;/a>[1]: &lt;a href="https://github.com/bitnami-labs/sealed-secrets" target="_blank" rel="noopener">Bitname Readme on Github&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Understanding RWO block device handling in OpenShift</title><link>https://blog.stderr.at/openshift/2021/02/understanding-rwo-block-device-handling-in-openshift/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021/02/understanding-rwo-block-device-handling-in-openshift/</guid><description>&lt;div class="paragraph">
&lt;p>In this blog post we would like to explore OpenShift / Kubernetes
block device handling. We try to answer the following questions:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>What happens if multiple pods try to access the same block device?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What happens if we scale a deployment using block devices to more than one replica?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>And finally we want to give a short, high level overview about how the
container storage interface (CSI) actually works.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
A block device provides Read-Write-Once (RWO) storage. This
basically means a local file system mounted by a single node. Do not
confuse this with a cluster (CephFS, GlusterFS) or network file system
(NFS). These file systems provide Read-Write-Many (RWX) storage
mountable on more than one node.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_test_setup">Test setup&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>For running our tests we need the following resources&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>A new namespace/project for running our tests&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A persistent volume claim (PVC) to be mounted in our test pods&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Two pods definitions for mounting the PVC&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_step_1_creating_a_new_namespaceproject">Step 1: Creating a new namespace/project&lt;/h3>
&lt;div class="paragraph">
&lt;p>To run our test cases we created a new project with OpenShift&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc new-project blockdevices&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect2">
&lt;h3 id="_step_2_defining_a_block_pvc">Step 2: Defining a block PVC&lt;/h3>
&lt;div class="paragraph">
&lt;p>Our cluster is running the rook operator (&lt;a href="https://rook.io" class="bare">https://rook.io&lt;/a>) and provides a ceph-block
storage class for creating block devices:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get sc
NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE
ceph-block rook-ceph.rbd.csi.ceph.com Delete Immediate false 4d14h&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s take a look a the details of the storage class:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">$ oc get sc -o yaml ceph-block
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
name: ceph-block
parameters:
clusterID: rook-ceph
csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
csi.storage.k8s.io/fstype: ext4 &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
imageFeatures: layering
imageFormat: &amp;#34;2&amp;#34;
pool: blockpool
provisioner: rook-ceph.rbd.csi.ceph.com
reclaimPolicy: Delete
volumeBindingMode: Immediate&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>So whenever we create a PVC using this storage class the Ceph
provisioner will also create an EXT4 file system on the block device.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To test block device handling we create the following persistent volume claim (PVC):&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
name: block-claim
spec:
accessModes:
- ReadWriteOnce &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
resources:
requests:
storage: 1Gi
storageClassName: ceph-block&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>The access mode is set to ReadWriteOnce (RWO), as block devices&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc create -f pvc.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get pvc
NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE
block-claim Bound pvc-bd68be5d-c312-4c31-86a8-63a0c22de844 1Gi RWO ceph-block 91s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>To test our shiny new block device we are going to use the following three pod definitions:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="title">block-pod-a&lt;/div>
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
labels:
run: block-pod-a
name: block-pod-a
spec:
containers:
- image: registry.redhat.io/ubi8/ubi:8.3
name: block-pod-a
command:
- sh
- -c
- &amp;#39;df -h /block &amp;amp;&amp;amp; findmnt /block &amp;amp;&amp;amp; sleep infinity&amp;#39;
volumeMounts:
- name: blockdevice
mountPath: /block
volumes:
- name: blockdevice
persistentVolumeClaim:
claimName: block-claim&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="title">block-pod-b&lt;/div>
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
labels:
run: block-pod-b
name: block-pod-b
spec:
affinity:
podAntiAffinity: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
requiredDuringSchedulingIgnoredDuringExecution:
- labelSelector:
matchExpressions:
- key: run
operator: In
values:
- block-pod-a
topologyKey: kubernetes.io/hostname
containers:
- image: registry.redhat.io/ubi8/ubi:8.3
name: block-pod-b
command:
- sh
- -c
- &amp;#39;df -h /block &amp;amp;&amp;amp; findmnt /block &amp;amp;&amp;amp; sleep infinity&amp;#39;
volumeMounts:
- name: blockdevice
mountPath: /block
volumes:
- name: blockdevice
persistentVolumeClaim:
claimName: block-claim&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We use an &lt;em>AntiAffinity&lt;/em> rule for making sure that &lt;em>block-pod-b&lt;/em> runs
on a &lt;strong>different&lt;/strong> node than &lt;em>block-pod-a&lt;/em>.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="title">block-pod-c&lt;/div>
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
labels:
run: block-pod-c
name: block-pod-c
spec:
affinity:
podAffinity: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
preferredDuringSchedulingIgnoredDuringExecution:
- weight: 100
podAffinityTerm:
labelSelector:
matchExpressions:
- key: run
operator: In
values:
- block-pod-a
topologyKey: kubernetes.io/hostname
containers:
- image: registry.redhat.io/ubi8/ubi:8.3
name: block-pod-c
command:
- sh
- -c
- &amp;#39;df -h /block &amp;amp;&amp;amp; findmnt /block &amp;amp;&amp;amp; sleep infinity&amp;#39;
volumeMounts:
- name: blockdevice
mountPath: /block
volumes:
- name: blockdevice
persistentVolumeClaim:
claimName: block-claim&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>We use an &lt;em>Affinity&lt;/em> rule for making sure that &lt;em>block-pod-c&lt;/em> runs
on the &lt;strong>same&lt;/strong> node as &lt;em>block-pod-a&lt;/em>.&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our first test we want to make sure that both pods are running on
separate cluster nodes. So we create &lt;em>block-pod-a&lt;/em> and &lt;em>block-pod-b&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc create -f block-pod-a.yml
$ oc create -f block-pod-b.yml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After a few seconds we can check the state of our pods:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get pods -o wide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
block-pod-a 1/1 Running 0 46s 10.130.6.4 infra02.lan.stderr.at &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
block-pod-b 0/1 ContainerCreating 0 16s &amp;lt;none&amp;gt; infra01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Hm, block-pod-b is in the state &lt;em>ContainerCreating&lt;/em>, let’s check the
events. Also note that it is running on another node (infra01) then
&lt;em>block-pod-a&lt;/em> (infra02).&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">10s Warning FailedAttachVolume pod/block-pod-b Multi-Attach error for volume &amp;#34;pvc-bd68be5d-c312-4c31-86a8-63a0c22de844&amp;#34; Volume is already used by pod(s) block-pod-a&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Ah, so because of our block device with RWO access mode and
&lt;em>block-pod-b&lt;/em> running on separate cluster node, OpenShift or K8s can’t
attach the volume to our &lt;em>block-pod-b&lt;/em>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>But let’s try another test and let’s create a third pod &lt;em>block-pod-c&lt;/em>
that should run on the same node as &lt;em>block-pod-a&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc create -f block-pod-c.yml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now let’s check the status of &lt;em>block-pod-c&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">$ oc get pods -o wide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
block-pod-a 1/1 Running 0 6m49s 10.130.6.4 infra02.lan.stderr.at &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
block-pod-b 0/1 ContainerCreating 0 6m19s &amp;lt;none&amp;gt; infra01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
block-pod-c 1/1 Running 0 14s 10.130.6.5 infra02.lan.stderr.at &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Oh, &lt;em>block-pod-c&lt;/em> is running on node &lt;em>infra02&lt;/em> and mounted the RWO volume. Let’s check the events for &lt;em>block-pod-c&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">3m6s Normal Scheduled pod/block-pod-c Successfully assigned blockdevices/block-pod-c to infra02.lan.stderr.at
2m54s Normal AddedInterface pod/block-pod-c Add eth0 [10.130.6.5/23]
2m54s Normal Pulled pod/block-pod-c Container image &amp;#34;registry.redhat.io/ubi8/ubi:8.3&amp;#34; already present on machine
2m54s Normal Created pod/block-pod-c Created container block-pod-c
2m54s Normal Started pod/block-pod-c Started container block-pod-c&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we compare this with the events for &lt;em>block-pod-a&lt;/em>:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">9m41s Normal Scheduled pod/block-pod-a Successfully assigned blockdevices/block-pod-a to infra02.lan.stderr.at
9m41s Normal SuccessfulAttachVolume pod/block-pod-a AttachVolume.Attach succeeded for volume &amp;#34;pvc-bd68be5d-c312-4c31-86a8-63a0c22de844&amp;#34;
9m34s Normal AddedInterface pod/block-pod-a Add eth0 [10.130.6.4/23]
9m34s Normal Pulled pod/block-pod-a Container image &amp;#34;registry.access.redhat.com/ubi8/ubi:8.3&amp;#34; already present on machine
9m34s Normal Created pod/block-pod-a Created container block-pod-a
9m34s Normal Started pod/block-pod-a Started container block-pod-a&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So the &lt;em>AttachVolume.Attach&lt;/em> message is missing in the events for
&lt;em>block-pod-c&lt;/em>. Because the volume is already attached to the node,
interesting.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
Even with RWO block device volumes it is possible to use the
same volume in multiple pods &lt;strong>if&lt;/strong> the pods a running on the &lt;strong>same&lt;/strong> node.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>I was not aware of this possibility and always had the believe with an
RWO block device only one pod can access the volume. That’s the
problem with believing :-)&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Thanks or reading this far.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Writing Operator using Ansible</title><link>https://blog.stderr.at/openshift/2021/01/writing-operator-using-ansible/</link><pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2021/01/writing-operator-using-ansible/</guid><description>&lt;div class="paragraph">
&lt;p>This quick post shall explain, without any fancy details, how to write an Operator based on Ansible. It is assumed that you know what purpose an Operator has.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As a short summary: Operators are a way to create custom controllers in OpenShift or Kubernetes. It watches for custom resource objects and creates the application based on the parameters in such custom resource object.
Often written in &lt;strong>Go&lt;/strong>, the SDK supports &lt;strong>Ansible&lt;/strong>, &lt;strong>Helm&lt;/strong> and (new) &lt;strong>Java&lt;/strong> as well.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this example we will install Gogs, a painless self-hosted Git services.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As general prerequisites we have:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Installed OpenShift 4.6+ cluster (could be Minicube)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Possibility to execute Ansible scripts and oc/kubectl commands&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Commands: make, docker (or podman)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;hr/>
&lt;div class="sect1">
&lt;h2 id="_install_operator_sdk">Install Operator SDK&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As explained at &lt;a href="https://sdk.operatorframework.io/docs/installation/" class="bare">https://sdk.operatorframework.io/docs/installation/&lt;/a> the following prerequisites must be met prior installing the SDK at least:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Docker v17.03+ or podman v1.9.3+ or buildah v1.7+&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OpenShift CLU v4.6+&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kubernetes/OpenShift cluster&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Access to container registry, for example quay.io&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Optional: Go v1.13+ (for Operators based on Golang)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Ansible v2.9.0+&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Following the instructions of the SDK documentation, the &lt;strong>operator-sdk&lt;/strong> command will be installed.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_creating_the_operator">Creating the Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>To begin we create a new folder for the Operator and initialize the Operator project.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">mkdir gogs-operator
cd gogs-operator
operator-sdk init --plugins=ansible --domain=example.com.at
operator-sdk create api --group gogs --version=v1alpha1 --kind Gogs --generate-playbook&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will create a new project structure with the following parameters:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>--plugin&lt;/strong>: Type of Operator (Ansible or Helm)&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>--domain&lt;/strong>: Defines the api endpoint together with group and version.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>--group&lt;/strong>: Usually short product name&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>&lt;strong>--version&lt;/strong>: Defines version of API endpoint&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The folder structure which will be created automatically looks as follows:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">.
|-- Dockerfile
|-- Makefile
|-- PROJECT
|-- config
| |-- crd
| | |-- bases
| | | |-- gogs.example.com.at_gogs.yaml
| | |-- kustomization.yaml
| |-- default
| | |-- kustomization.yaml
| | |-- manager_auth_proxy_patch.yaml
| |-- manager
| | |-- kustomization.yaml
| | |-- manager.yaml
| |-- prometheus
| | |-- kustomization.yaml
| | |-- monitor.yaml
| |-- rbac
| | |-- auth_proxy_client_clusterrole.yaml
| | |-- auth_proxy_role.yaml
| | |-- auth_proxy_role_binding.yaml
| | |-- auth_proxy_service.yaml
| | |-- gogs_editor_role.yaml
| | |-- gogs_viewer_role.yaml
| | |-- kustomization.yaml
| | |-- leader_election_role.yaml
| | |-- leader_election_role_binding.yaml
| | |-- role.yaml
| | |-- role_binding.yaml
| |-- samples
| | |-- gogs_v1alpha1_gogs.yaml
| | |-- kustomization.yaml
| |-- scorecard
| | |-- bases
| | | |-- config.yaml
| | |-- kustomization.yaml
| | |-- patches
| | |-- basic.config.yaml
| | |-- olm.config.yaml
| |-- testing
| |-- debug_logs_patch.yaml
| |-- kustomization.yaml
| |-- manager_image.yaml
| |-- pull_policy
| |-- Always.yaml
| |-- IfNotPresent.yaml
| |-- Never.yaml
|-- molecule
| |-- default
| | |-- converge.yml
| | |-- create.yml
| | |-- destroy.yml
| | |-- kustomize.yml
| | |-- molecule.yml
| | |-- prepare.yml
| | |-- tasks
| | | |-- gogs_test.yml
| | |-- verify.yml
| |-- kind
| |-- converge.yml
| |-- create.yml
| |-- destroy.yml
| |-- molecule.yml
|-- playbooks
| |-- gogs.yml
|-- requirements.yml
|-- roles
|-- watches.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The &lt;strong>watches.yaml&lt;/strong> file maps Custom Resources (identified by Group, Version, and Kind [GVK]) to Ansible Roles and Playbooks. It tells the Operator where to find the actual Ansible playbook.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
# Use the &amp;#39;create api&amp;#39; subcommand to add watches to this file.
- version: v1alpha1
group: gogs.example.com.at
kind: Gogs
playbook: playbooks/gogs.yml
# +kubebuilder:scaffold:watch&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Other files, especially inside &lt;strong>playbooks&lt;/strong> and &lt;strong>roles&lt;/strong> are created as placeholders. These files (or folders) are waiting for you to add the Ansible logic.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_defining_roles_and_playbook">Defining Roles and Playbook&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>With the folder structure above, a playbook and different roles can be created in order to tell the Operator what it needs to do.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
Since the Operator will constantly watch for changes, all tasks must be &lt;strong>idempotent&lt;/strong>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In our example we will try to install Gogs, a Git service. It contains a Postgres database system and a webservice.
To use some example roles and not fully start from scratch let’s clone the following repository and copy the folders to our Operator.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">cd ..
https://github.com/tjungbauer/ansible-operator-roles
cd gogs-operator
# Remove placeholder
rm -Rf roles/
# Copy Postgres deployment role
cp -R ../ansible-operator-roles/roles/postgresql-ocp ./roles
# Copy Gogs Deplyoment role
cp -R ../ansible-operator-roles/roles/gogs-ocp ./roles&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we examine the folder, we see 2 typical Ansible roles. The simple purpose is, to create all required OpenShift objects, like Deployment, Route, Service and so on, fully automated by the Operator.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">|-- playbooks
| |-- gogs.yaml
|-- roles
|-- gogs-ocp
| |-- README.adoc
| |-- defaults
| | |-- main.yml
| |-- meta
| | |-- main.yml
| |-- tasks
| | |-- main.yml
| |-- templates
| |-- config_map.j2
| |-- deployment.j2
| |-- persistent_volume_claim.j2
| |-- route.j2
| |-- service.j2
| |-- service_account.j2
|-- postgresql-ocp
|-- README.adoc
|-- defaults
| |-- main.yml
|-- meta
| |-- main.yml
|-- tasks
| |-- main.yml
|-- templates
|-- deployment.j2
|-- persistent_volume_claim.j2
|-- secret.j2
|-- service.j2&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Copy (or create) the following playbook under &lt;strong>playbooks/gogs.yaml&lt;/strong>. As you can see there are 2 tasks: the first one will create the postgres application, the seconds one the Gogs service.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
# Persistent Gogs deployment playbook.
#
# The Playbook expects the following variables to be set in the CR:
# (Note that Camel case gets converted by the ansible-operator to Snake case)
# - PostgresqlVolumeSize
# - GogsVolumeSize
# - GogsSSL
# The following variables come from the ansible-operator
# - ansible_operator_meta.namespace
# - ansible_operator_meta.name (from the name of the CR)
- hosts: localhost
gather_facts: no
tasks:
- name: Set up PostgreSQL
include_role:
name: ../roles/postgresql-ocp &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
vars: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
_postgresql_namespace: &amp;#34;{{ ansible_operator_meta.namespace }}&amp;#34;
_postgresql_name: &amp;#34;postgresql-gogs-{{ ansible_operator_meta.name }}&amp;#34;
_postgresql_database_name: &amp;#34;gogsdb&amp;#34;
_postgresql_user: &amp;#34;gogsuser&amp;#34;
_postgresql_password: &amp;#34;gogspassword&amp;#34;
_postgresql_volume_size: &amp;#34;{{ postgresql_volume_size|d(&amp;#39;4Gi&amp;#39;) }}&amp;#34;
_postgresql_image: &amp;#34;{{ postgresql_image|d(&amp;#39;registry.redhat.io/rhscl/postgresql-10-rhel7&amp;#39;) }}&amp;#34;
_postgresql_image_tag: &amp;#34;{{ postgresql_image_tag|d(&amp;#39;latest&amp;#39;) }}&amp;#34;
_postgresql_size: 1
- name: Set Gogs Service name to default value
set_fact:
gogs_service_name: &amp;#34;gogs-{{ ansible_operator_meta.name }}&amp;#34;
when:
gogs_service_name is not defined
- name: Set up Gogs
include_role:
name: ../roles/gogs-ocp &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
vars: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
_gogs_namespace: &amp;#34;{{ ansible_operator_meta.namespace }}&amp;#34;
_gogs_name: &amp;#34;{{ gogs_service_name }}&amp;#34;
_gogs_ssl: &amp;#34;{{ gogs_ssl|d(False)|bool }}&amp;#34;
_gogs_route: &amp;#34;{{ gogs_route | d(&amp;#39;&amp;#39;) }}&amp;#34;
_gogs_image_tag: &amp;#34;{{ gogs_image_tag | d(&amp;#39;latest&amp;#39;) }}&amp;#34;
_gogs_volume_size: &amp;#34;{{ gogs_volume_size|d(&amp;#39;4Gi&amp;#39;) }}&amp;#34;
_gogs_postgresql_service_name: &amp;#34;postgresql-gogs-{{ ansible_operator_meta.name }}&amp;#34;
_gogs_postgresql_database_name: gogsdb
_gogs_postgresql_user: gogsuser
_gogs_postgresql_password: gogspassword
_gogs_size: 1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Path to Postgres Role&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Parameters for Postgres service&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>Path to Gogs Role&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Parameters for Gogs service&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_operator_permissions">Operator Permissions&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The Operator will require correct permissions in order to create objects like Routes or Services in OpenShift. The SDK automatically created a default role.yaml which can be modified.
Open the file &lt;strong>config/rbac/role.yaml&lt;/strong> and add permissions for:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>for apiGroups &amp;#34;&amp;#34;&lt;/p>
&lt;div class="olist loweralpha">
&lt;ol class="loweralpha" type="a">
&lt;li>
&lt;p>services&lt;/p>
&lt;/li>
&lt;li>
&lt;p>routes&lt;/p>
&lt;/li>
&lt;li>
&lt;p>peristentvlumeclaims&lt;/p>
&lt;/li>
&lt;li>
&lt;p>serviceaccounts&lt;/p>
&lt;/li>
&lt;li>
&lt;p>configmaps&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>for apiGroups: route.operanshift.io the resource &lt;strong>routes&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>At the end, the role.yaml should look like this:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
name: manager-role
rules:
##
## Base operator rules
##
- apiGroups:
- &amp;#34;&amp;#34;
resources:
- secrets
- pods
- pods/exec
- pods/log
- services
- routes
- configmaps
- persistentvolumeclaims
- serviceaccounts
verbs:
- create
- delete
- get
- list
- patch
- update
- watch
- apiGroups:
- apps
resources:
- deployments
- daemonsets
- replicasets
- statefulsets
verbs:
- create
- delete
- get
- list
- patch
- update
- watch
##
## Rules for gogs.example.com.at/v1alpha1, Kind: Gogs
##
- apiGroups:
- gogs.example.com.at
resources:
- gogs
- gogs/status
- gogs/finalizers
verbs:
- create
- delete
- get
- list
- patch
- update
- watch
- apiGroups:
- route.openshift.io
resources:
- routes
verbs:
- create
- update
- delete
- get
- list
- watch
- patch
- apiGroups:
- route.openshift.io
resources:
- routes
verbs:
- create
- update
- delete
- get
- list
- watch
- patch&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_building_and_deploy_the_operator">Building and Deploy the Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now it is time to build the Operator and push it to a repository. In this example a repository was created at quay.io and is called &lt;strong>gogs-operator&lt;/strong>.
The SDK will automatically create a Makefile during the initialization, which we will use now.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock caution">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-caution" title="Caution">&lt;/i>
&lt;/td>
&lt;td class="content">
The Makefile is prepared for &lt;em>docker&lt;/em>. If you use &lt;strong>podman&lt;/strong> some modifications must be done first. Run the command &lt;strong>sed -i &amp;#39;s/docker/podman/g&amp;#39; Makefile&lt;/strong> to replace all docker commands inside the Makefile.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The next commands will &lt;em>build, push, install and deploy&lt;/em> the Operator. Before we start we must be logged in to you Registry of choice (i.e. docker login …​) as well as into our OpenShift cluster.
Moreover, it is required that the &lt;strong>IMG&lt;/strong> environment variable is exported with the correct value.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Build the Operator and push into the registry&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># export IMG, be sure that the correct tag is used
export IMG=quay.io/tjungbau/gogs-operator:v1.0.0
# Build and push into registry
make podman-build podman-push
podman build . -t quay.io/tjungbau/gogs-operator:v1.0.0
STEP 1: FROM quay.io/operator-framework/ansible-operator:v1.3.0
STEP 2: COPY requirements.yml ${HOME}/requirements.yml
--&amp;gt; Using cache 4f84e7064b066c2cac5179b56490a0ef85591170c501ec8a480b617d6e91cff3
STEP 3: RUN ansible-galaxy collection install -r ${HOME}/requirements.yml &amp;amp;&amp;amp; chmod -R ug+rwx ${HOME}/.ansible
--&amp;gt; Using cache 2a3a5d44451a45a4c38e1c314e8887c6c45f2551cbef87ef0d1ce518c1969c0d
STEP 4: COPY watches.yaml ${HOME}/watches.yaml
--&amp;gt; Using cache 642f8361a7b358b89d2e4e5211c1c7a1e22488c53bba0bf1ba2ba275fd56ee69
STEP 5: COPY roles/ ${HOME}/roles/
--&amp;gt; Using cache 93c1af8782bad84d8b81d2d2294c405caab70e2d01c232440f7eb8e5001746c1
STEP 6: COPY playbooks/ ${HOME}/playbooks/
--&amp;gt; Using cache 1cdeee1456ac67d70d4233b0f9ed8052465aaa2cded6bd8ae962dfcc848e5b92
STEP 7: COMMIT quay.io/tjungbau/gogs-operator:v1.0.0
--&amp;gt; 1cdeee1456a
1cdeee1456ac67d70d4233b0f9ed8052465aaa2cded6bd8ae962dfcc848e5b92
podman push quay.io/tjungbau/gogs-operator:v1.0.0
Getting image source signatures
Copying blob d5ca8c3b3d34 skipped: already exists
Copying blob 4b036ae478b7 skipped: already exists
Copying blob 5cfcd0621ffc skipped: already exists
Copying blob c6f3d1432bd0 skipped: already exists
Copying blob 92538e92de29 skipped: already exists
Copying blob eb7bf34352ca skipped: already exists
Copying blob 80c43a11288f done
Copying blob 803eb2035c9a done
Copying blob 40d943ae1834 done
Copying blob f4d9024614ee done
Copying blob 5143a36c6002 done
Copying blob 5050e1080446 skipped: already exists
Copying config 1cdeee1456 done
Writing manifest to image destination
Copying config 1cdeee1456 [--------------------------------------] 0.0b / 6.2KiB
Writing manifest to image destination
Writing manifest to image destination
Storing signatures&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Install the CRD into OpenShift&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># Install the custom resource definition
make install
/root/projects/gogs-operator/bin/kustomize build config/crd | kubectl apply -f -
customresourcedefinition.apiextensions.k8s.io/gogs.gogs.example.com.at created&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Deploy the Operator and all required objects into OpenShift&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># Deploy the Operator into OpenShift
make deploy
cd config/manager &amp;amp;&amp;amp; /root/projects/gogs-operator/bin/kustomize edit set image controller=quay.io/tjungbau/gogs-operator:v1.0.0
/root/projects/gogs-operator/bin/kustomize build config/default | kubectl apply -f -
namespace/gogs-operator-system created
customresourcedefinition.apiextensions.k8s.io/gogs.gogs.example.com.at unchanged
role.rbac.authorization.k8s.io/gogs-operator-leader-election-role created
clusterrole.rbac.authorization.k8s.io/gogs-operator-manager-role created
clusterrole.rbac.authorization.k8s.io/gogs-operator-metrics-reader created
clusterrole.rbac.authorization.k8s.io/gogs-operator-proxy-role created
rolebinding.rbac.authorization.k8s.io/gogs-operator-leader-election-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/gogs-operator-manager-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/gogs-operator-proxy-rolebinding created
service/gogs-operator-controller-manager-metrics-service created
deployment.apps/gogs-operator-controller-manager created&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will create a new project in OpenShift called &lt;strong>gogs-operator-system&lt;/strong>. Here, the Operator is running and waiting that somebody creates a CRD of the kind &lt;strong>Gogs&lt;/strong>. Once this happens the Operator will execute the playbooks and therefore create a Postgres and a Gogs pod.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash"># Operator Namespace
oc get pods -n gogs-operator-system
NAME READY STATUS RESTARTS AGE
gogs-operator-controller-manager-6747bb6c6-s8794 2/2 Running 0 6m8s&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_using_the_operator">Using the Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Now we need to create a CRD of the kind &lt;em>Gogs&lt;/em>. This will happen in a new project, where the Gogs service shall be hosted.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Create a new OpenShift project&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc new-project gogs&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Verify the sample resource&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">cat config/samples/gogs_v1alpha1_gogs.yaml
apiVersion: gogs.example.com.at/v1alpha1
kind: Gogs
metadata:
name: gogs-sample
spec:
foo: bar&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Apply the sample resource&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc apply -f config/samples/gogs_v1alpha1_gogs.yaml -n gogs&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This will create two services:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>postgresql&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Gogs&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Operator will be responsible to roll out all required objects. This includes the Deployments for the container, the Openshift service and the route.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get all -n gogs
NAME READY STATUS RESTARTS AGE
pod/gogs-gogs-sample-57778fd76-ghg8j 1/1 Running 0 74s
pod/postgresql-gogs-gogs-sample-bbc49b794-mnltb 1/1 Running 0 115s
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/gogs-gogs-sample ClusterIP 172.30.47.31 &amp;lt;none&amp;gt; 3000/TCP 80s
service/postgresql-gogs-gogs-sample ClusterIP 172.30.47.158 &amp;lt;none&amp;gt; 5432/TCP 117s
NAME READY UP-TO-DATE AVAILABLE AGE
deployment.apps/gogs-gogs-sample 1/1 1 1 74s
deployment.apps/postgresql-gogs-gogs-sample 1/1 1 1 115s
NAME DESIRED CURRENT READY AGE
replicaset.apps/gogs-gogs-sample-57778fd76 1 1 1 74s
replicaset.apps/postgresql-gogs-gogs-sample-bbc49b794 1 1 1 115s
NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD
route.route.openshift.io/gogs-gogs-sample gogs-gogs-sample-gogs.apps.ocp.ispworld.at gogs-gogs-sample &amp;lt;all&amp;gt; None&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>At the end, all Pods are alive, ready and are fully controlled by the Operator. We can access the Gogs web interface via the route and start using our own Git service.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_updating_operator">Updating Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>While the Operator is running fine now, at some point you might want to do some changes. For example, let’s run the Gog service with a replica of 3.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Perform the following actions:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Set the variable &lt;strong>_gogs_size&lt;/strong> to 3 in playbooks/gogs.yml&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Build and push the new version&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">export IMG=quay.io/tjungbau/gogs-operator:v1.0.8
make podman-build podman-push
podman build . -t quay.io/tjungbau/gogs-operator:v1.0.8
STEP 1: FROM quay.io/operator-framework/ansible-operator:v1.3.0
STEP 2: COPY requirements.yml ${HOME}/requirements.yml
--&amp;gt; Using cache 4f84e7064b066c2cac5179b56490a0ef85591170c501ec8a480b617d6e91cff3
STEP 3: RUN ansible-galaxy collection install -r ${HOME}/requirements.yml &amp;amp;&amp;amp; chmod -R ug+rwx ${HOME}/.ansible
--&amp;gt; Using cache 2a3a5d44451a45a4c38e1c314e8887c6c45f2551cbef87ef0d1ce518c1969c0d
STEP 4: COPY watches.yaml ${HOME}/watches.yaml
--&amp;gt; Using cache 642f8361a7b358b89d2e4e5211c1c7a1e22488c53bba0bf1ba2ba275fd56ee69
STEP 5: COPY roles/ ${HOME}/roles/
--&amp;gt; Using cache 55785493e215d933ef7a93fe000afa6fbb088d87eeffcdddeea4e7fd1896f5b5
STEP 6: COPY playbooks/ ${HOME}/playbooks/
STEP 7: COMMIT quay.io/tjungbau/gogs-operator:v1.0.8
--&amp;gt; bb9d6a995d0
bb9d6a995d059eab7758f9ac17d3ce12f8759518e231f77d32a4b820e4b14396
podman push quay.io/tjungbau/gogs-operator:v1.0.8
Getting image source signatures
Copying blob 5cfcd0621ffc skipped: already exists
Copying blob d5ca8c3b3d34 skipped: already exists
Copying blob eb7bf34352ca skipped: already exists
Copying blob 4b036ae478b7 skipped: already exists
Copying blob c6f3d1432bd0 skipped: already exists
Copying blob 92538e92de29 skipped: already exists
Copying blob 41e53e538a36 done
Copying blob 5050e1080446 skipped: already exists
Copying blob 40d943ae1834 skipped: already exists
Copying blob 803eb2035c9a skipped: already exists
Copying blob 80c43a11288f skipped: already exists
Copying blob ee0361a14e3b skipped: already exists
Copying config bb9d6a995d done
Writing manifest to image destination
Copying config bb9d6a995d [--------------------------------------] 0.0b / 6.2KiB
Writing manifest to image destination
Writing manifest to image destination
Storing signatures&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Deploy the new version&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">make deploy
cd config/manager &amp;amp;&amp;amp; /root/projects/gogs-operator/bin/kustomize edit set image controller=quay.io/tjungbau/gogs-operator:v1.0.8
/root/projects/gogs-operator/bin/kustomize build config/default | kubectl apply -f -
namespace/gogs-operator-system unchanged
customresourcedefinition.apiextensions.k8s.io/gogs.gogs.example.com.at unchanged
role.rbac.authorization.k8s.io/gogs-operator-leader-election-role unchanged
clusterrole.rbac.authorization.k8s.io/gogs-operator-manager-role unchanged
clusterrole.rbac.authorization.k8s.io/gogs-operator-metrics-reader unchanged
clusterrole.rbac.authorization.k8s.io/gogs-operator-proxy-role unchanged
rolebinding.rbac.authorization.k8s.io/gogs-operator-leader-election-rolebinding unchanged
clusterrolebinding.rbac.authorization.k8s.io/gogs-operator-manager-rolebinding unchanged
clusterrolebinding.rbac.authorization.k8s.io/gogs-operator-proxy-rolebinding unchanged
service/gogs-operator-controller-manager-metrics-service unchanged
deployment.apps/gogs-operator-controller-manager configured&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The Operator will restart with a new version. After a while the changes will take affect and 3 Gogs pods will run.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc get pods -n gogs
NAME READY STATUS RESTARTS AGE
gogs-gogs-sample-57778fd76-4m98m 1/1 Running 0 12m
gogs-gogs-sample-57778fd76-5hrdn 1/1 Running 0 6m23s
gogs-gogs-sample-57778fd76-xgh2f 1/1 Running 0 6m24s
postgresql-gogs-gogs-sample-bbc49b794-z84wt 1/1 Running 0 13m&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_what_else_references">What Else? - References&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Above example is a very quick overview about what can be done. There are many other options. You can create Operators using Go or Helm.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The best starting points are the following websites:&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://redhat-connect.gitbook.io/certified-operator-guide/">Certified Operator Build Guide&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://sdk.operatorframework.io/docs/">Operator SDK Documentation&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Thanos Querier vs Thanos Querier</title><link>https://blog.stderr.at/openshift/2020/12/thanos-querier-vs-thanos-querier/</link><pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate><guid>https://blog.stderr.at/openshift/2020/12/thanos-querier-vs-thanos-querier/</guid><description>&lt;div class="paragraph">
&lt;p>OpenShift comes per default with a static Grafana dashboard, which will present cluster metrics to cluster administrators. It is not possible to customize this Grafana instance.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>However, many customers would like to create their own dashboards, their own monitoring and their own alerting while leveraging the possibilities of OpenShift at the same time and without installing a completely separated monitoring stack.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>So how can you create your own queries? How can you visualize them on custom dashboards, without the need to install Prometheus or Alertmanager a second time?&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The solution is simple: Since OpenShift 4.5 (as TechPreview) and since OpenShift 4.6 (as GA) the default monitoring stack of OpenShift has been extended to support monitoring of &lt;strong>user-defined projects&lt;/strong>. This additional configuration will help to observe your own projects.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In this article we will see how to deploy the Grafana operator and what the possible issues can occur, when simply connecting Grafana to the OpenShift monitoring.&lt;/p>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_overview">Overview&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As a developer in OpenShift, you can create an application which provides your custom statistics of your application at the endpoint &lt;em>/metrics&lt;/em>. Here the example from the official OpenShift documentation:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-ini" data-lang="ini"># HELP http_requests_total Count of all HTTP requests
# TYPE http_requests_total counter
http_requests_total{code=&amp;#34;200&amp;#34;,method=&amp;#34;get&amp;#34;} 4
http_requests_total{code=&amp;#34;404&amp;#34;,method=&amp;#34;get&amp;#34;} 2
# HELP version Version information about this binary
# TYPE version gauge
version{version=&amp;#34;v0.1.0&amp;#34;} 1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This metric can then be viewed inside OpenShift in the developer view under the menu &lt;strong>Monitoring&lt;/strong>. If you go to &amp;#34;Monitoring &amp;gt; Metrics&amp;#34; and select &amp;#34;Custom Query&amp;#34; from the drop down, you can enter, for example, the following PromQL query:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-sql" data-lang="sql">sum(rate(http_requests_total[2m]))&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The following graph will be the result:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/custom-query.png?width=940px" alt="Custom Query"/>
&lt;/div>
&lt;div class="title">Figure 1. Custom Query&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is great! But …​ what happens if a customer would like to see his very own super fancy Grafana dashboard? You cannot change the cluster dashboard. However, you can install your own Grafana instance and one way to do so is using the &lt;strong>Custom Grafana Operator&lt;/strong>.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_before_we_begin">Before we begin&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before we start the following should be prepared already:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>OpenShift 4.5+&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Enabled user-define workload monitoring&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A project with user-defined workload monitoring. This is explained in the official documentation at &lt;a href="https://docs.openshift.com/container-platform/4.6/monitoring/enabling-monitoring-for-user-defined-projects.html" class="bare">https://docs.openshift.com/container-platform/4.6/monitoring/enabling-monitoring-for-user-defined-projects.html&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>During this blog, we will use the namespace &lt;strong>ns1&lt;/strong> with a custom metric&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_deploy_custom_grafana_operator">Deploy Custom Grafana Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>As for any community operator the following must be considered:&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
Community Operators are operators which have not been vetted or verified by Red Hat. Community Operators should be used with caution because their stability is unknown. Red Hat provides no support for Community Operators.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The community Grafana operator must be deployed to its own namespace, for example &lt;strong>grafana&lt;/strong>. Create this namespace first (oc new-project grafana) and search and intall the &lt;em>Grafana Operator&lt;/em> from the OperatorHub. You can use the default values, just be sure to select the wanted namespace.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After a few minutes, the operator should be available:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/grafana-operator.png?width=940px" alt="Grafana Operator"/>
&lt;/div>
&lt;div class="title">Figure 2. Installed Community Grafana Operator&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_setup_grafana_operator">Setup Grafana Operator&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Before we can use Grafana to draw beautiful images it must be configured. We need to create an instance of Grafana. Ideally, OpenShift OAuth is already leveraged, to avoid the need to creating user account manually, inside Grafana.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>OAuth requires some objects, which must be created before the actual Grafana instance. The following YAMLs are taken from the operator documentation. Create the following inside the Grafana namespace:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Session secret for the proxy …​ change the password!!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a cluster role &lt;em>grafana-proxy&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a cluster role binding for the role&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a config map injecting trusted CA bundles&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: v1
data:
session_secret: Y2hhbmdlIG1lCg==
kind: Secret
metadata:
name: grafana-k8s-proxy
type: Opaque
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
name: grafana-proxy
rules:
- apiGroups:
- authentication.k8s.io
resources:
- tokenreviews
verbs:
- create
- apiGroups:
- authorization.k8s.io
resources:
- subjectaccessreviews
verbs:
- create
---
apiVersion: authorization.openshift.io/v1
kind: ClusterRoleBinding
metadata:
name: grafana-proxy
roleRef:
name: grafana-proxy
subjects:
- kind: ServiceAccount
name: grafana-serviceaccount
namespace: grafana
userNames:
- system:serviceaccount:grafana:grafana-serviceaccount
---
apiVersion: v1
kind: ConfigMap
metadata:
labels:
config.openshift.io/inject-trusted-cabundle: &amp;#34;true&amp;#34;
name: ocp-injected-certs&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Now you can create the following instance under: &amp;#34;Installed Operators &amp;gt; Grafana Operator &amp;gt; Grafana &amp;gt; Create Grafana &amp;gt; YAML View&amp;#34; (or, as an alternative, via the CLI)&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">apiVersion: integreatly.org/v1alpha1
kind: Grafana
metadata:
name: grafana-oauth
namespace: grafana
spec:
config: &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
auth:
disable_login_form: false
disable_signout_menu: true
auth.anonymous:
enabled: false
auth.basic:
enabled: true
log:
level: warn
mode: console
security: &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
admin_password: secret
admin_user: root
secrets:
- grafana-k8s-tls
- grafana-k8s-proxy
client:
preferService: true
dataStorage: &lt;i class="conum" data-value="3">&lt;/i>&lt;b>(3)&lt;/b>
accessModes:
- ReadWriteOnce
class: managed-nfs-storage
size: 10Gi
containers: &lt;i class="conum" data-value="4">&lt;/i>&lt;b>(4)&lt;/b>
- args:
- &amp;#39;-provider=openshift&amp;#39;
- &amp;#39;-pass-basic-auth=false&amp;#39;
- &amp;#39;-https-address=:9091&amp;#39;
- &amp;#39;-http-address=&amp;#39;
- &amp;#39;-email-domain=*&amp;#39;
- &amp;#39;-upstream=http://localhost:3000&amp;#39;
- &amp;#39;-tls-cert=/etc/tls/private/tls.crt&amp;#39;
- &amp;#39;-tls-key=/etc/tls/private/tls.key&amp;#39;
- &amp;gt;-
-client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
- &amp;#39;-cookie-secret-file=/etc/proxy/secrets/session_secret&amp;#39;
- &amp;#39;-openshift-service-account=grafana-serviceaccount&amp;#39;
- &amp;#39;-openshift-ca=/etc/pki/tls/cert.pem&amp;#39;
- &amp;#39;-openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt&amp;#39;
- &amp;#39;-openshift-ca=/etc/grafana-configmaps/ocp-injected-certs/ca-bundle.crt&amp;#39;
- &amp;#39;-skip-auth-regex=^/metrics&amp;#39;
- &amp;gt;-
-openshift-sar={&amp;#34;namespace&amp;#34;: &amp;#34;grafana&amp;#34;, &amp;#34;resource&amp;#34;: &amp;#34;services&amp;#34;,
&amp;#34;verb&amp;#34;: &amp;#34;get&amp;#34;}
image: &amp;#39;quay.io/openshift/origin-oauth-proxy:4.8&amp;#39;
name: grafana-proxy
ports:
- containerPort: 9091
name: grafana-proxy
resources: {}
volumeMounts:
- mountPath: /etc/tls/private
name: secret-grafana-k8s-tls
readOnly: false
- mountPath: /etc/proxy/secrets
name: secret-grafana-k8s-proxy
readOnly: false
ingress:
enabled: true
targetPort: grafana-proxy
termination: reencrypt
service:
annotations:
service.alpha.openshift.io/serving-cert-secret-name: grafana-k8s-tls
ports:
- name: grafana-proxy
port: 9091
protocol: TCP
targetPort: grafana-proxy
serviceAccount:
annotations:
serviceaccounts.openshift.io/oauth-redirectreference.primary: &amp;gt;-
{&amp;#34;kind&amp;#34;:&amp;#34;OAuthRedirectReference&amp;#34;,&amp;#34;apiVersion&amp;#34;:&amp;#34;v1&amp;#34;,&amp;#34;reference&amp;#34;:{&amp;#34;kind&amp;#34;:&amp;#34;Route&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;grafana-route&amp;#34;}}
configMaps:
- ocp-injected-certs
dashboardLabelSelector:
- matchExpressions:
- key: app
operator: In
values:
- grafana&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>Some default settings, which can be modified if required&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>A default administrative user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="3">&lt;/i>&lt;b>3&lt;/b>&lt;/td>
&lt;td>A datastore to use a persistent volume. Other options would be to use ephemeral storage, or another database. This might be especially important, if you would like HA for your Grafana.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="4">&lt;/i>&lt;b>4&lt;/b>&lt;/td>
&lt;td>Container arguments, most important the openshift-sar line which is important for the OAuth&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>After a few moments, the operator will pick up the change and creates a Grafana pod.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_adding_a_data_source">Adding a Data Source&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>The next step is to connect your custom Grafana to Prometheus, or actually to the Thanos Querier. To do so, you will need to add a role to the Grafana service account and to create a CRD &lt;em>GrafanaDataSource&lt;/em>.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>At this moment, we will work with the cluster role &lt;em>cluster-monitoring-view&lt;/em>. The problem this might bring is discussed later.&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Add the role to the Grafana serviceaccount&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc adm policy add-cluster-role-to-user cluster-monitoring-view -z grafana-serviceaccount&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Retrieve the token of the service account&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc serviceaccounts get-token grafana-serviceaccount -n grafana&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Create the following Grafana Data Source, either via UI or via CLI. Be sure to change &amp;lt;TOKEN&amp;gt; with the token from step #2.&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">apiVersion: integreatly.org/v1alpha1
kind: GrafanaDataSource
metadata:
name: prometheus-grafanadatasource
namespace: grafana
spec:
datasources:
- access: proxy
editable: true
isDefault: true
jsonData:
httpHeaderName1: Authorization
timeInterval: 5s
tlsSkipVerify: true
name: Prometheus
secureJsonData:
httpHeaderValue1: &amp;gt;-
Bearer &amp;lt;TOKEN&amp;gt; &lt;i class="conum" data-value="1">&lt;/i>&lt;b>(1)&lt;/b>
type: prometheus
url: &amp;#39;https://thanos-querier.openshift-monitoring.svc.cluster.local:9091&amp;#39; &lt;i class="conum" data-value="2">&lt;/i>&lt;b>(2)&lt;/b>
name: prometheus-grafanadatasource.yaml&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="colist arabic">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td>&lt;i class="conum" data-value="1">&lt;/i>&lt;b>1&lt;/b>&lt;/td>
&lt;td>enter token from step #2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;i class="conum" data-value="2">&lt;/i>&lt;b>2&lt;/b>&lt;/td>
&lt;td>Thanos default querier URL…​. this might cause problems (see below)&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The operator will now restart the Grafana pod to add the newest changes, which should not take more than a few seconds.
Grafana can be used now. Dashboards can be created …​ but lets run some tests with PromQL queries instead.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_lets_test">Let’s Test&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>Log in to your Grafana using OAuth and a cluster administrator.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
You could also use a non cluster administrator, if the user is able to GET the services of the Grafana namespace. The reason is the following line in the Grafana CRD: &lt;strong>-openshift-sar={&amp;#34;namespace&amp;#34;: &amp;#34;grafana&amp;#34;, &amp;#34;resource&amp;#34;: &amp;#34;services&amp;#34;,&amp;#34;verb&amp;#34;: &amp;#34;get&amp;#34;}&lt;/strong> which defines, that OAuth will work for everybody who can get the service. This might be changed according to personal needs, but for this test it is good enough.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Then use the credentials for the admin account, which have been defined while creating the Grafana instance.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>You will be logged in now and since there are no Dashboards, lets go to &lt;em>Explore&lt;/em> to enter some custom PromQL queries, for instance our example from above:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-sql" data-lang="sql">sum(rate(http_requests_total[2m]))&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/query1.png?width=940px" alt="Query"/>
&lt;/div>
&lt;div class="title">Figure 3. First Query&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is looking good.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s give it another try and sort by namespaces.&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-sql" data-lang="sql">sum(rate(http_requests_total[2m])) by (namespace)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/query2.png?width=940px" alt="Query"/>
&lt;/div>
&lt;div class="title">Figure 4. Second Query - showing internal namespace&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>What is this? I see a namespace which is actually meant for the cluster (openshift-monitoring).&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Let’s try another query using a different metric:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-sql" data-lang="sql">sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate) by (namespace)&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/query3.png?width=940px" alt="Query"/>
&lt;/div>
&lt;div class="title">Figure 5. Third Query - shows even more namespaces&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Ok, so we have access to all namespaces on the cluster.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_why_do_i_see_all_namespaces">Why do I see all namespaces?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>What does this mean? Well, it means that we have access to all namespaces of the cluster. We see everything. This makes sense, since we assign the cluster role &amp;#34;cluster-monitoring-view&amp;#34; to the serviceaccount of Grafana.
But what if we want to show only objects from a specific namespace? If we want, for example, give the developers the possibility to create their own dashboards, without having view access to the whole cluster.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The first test might be to remove the cluster-monitoring-view privileges from the Grafana serviceaccount. This will lead to an error on Grafana itself, since it cannot access the Thanos Querier, which we configured with: &lt;a href="https://thanos-querier.openshift-monitoring.svc.cluster.local:9091" class="bare">https://thanos-querier.openshift-monitoring.svc.cluster.local:9091&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>How does the Openshift WebUI actually work, when you are a developer and would like to search one of the above queries. Let’s try that:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/query4.png?width=940px" alt="Query"/>
&lt;/div>
&lt;div class="title">Figure 6. Query using the OpenShift UI&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>It works! It shows the namespace of the developer and only this namespace.
When you inspect the actual network traffic, you will see that OpenShift automatically adds the URL parameter &lt;strong>namespace=ns1&lt;/strong> to the request URL:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-sql" data-lang="sql">https://your-cluster/api/prometheus-tenancy/api/v1/query?namespace=ns1&amp;amp;query=sum%28node_namespace_pod_container%3Acontainer_cpu_usage_seconds_total%3Asum_rate%29+by+%28namespace%29&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>This is good information, let’s try this using the Grafana Data Source.&lt;/p>
&lt;/div>
&lt;div class="admonitionblock warning">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-warning" title="Warning">&lt;/i>
&lt;/td>
&lt;td class="content">
It is currently not possible to perform this configuration using the GrafanaDataSource CRD. Instead, it must be done directly at the Grafana Dashboard configuration. There is an open ticket at: &lt;a href="https://github.com/integr8ly/grafana-operator/issues/309" class="bare">https://github.com/integr8ly/grafana-operator/issues/309&lt;/a>
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Login to Grafana as administrator and switch to &amp;#34;Configuration &amp;gt; Data Source &amp;gt; Prometheus &amp;gt;&amp;#34;. At the very bottom add &lt;strong>namespace=ns1&lt;/strong> to the &lt;strong>Custom query parameters&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/config-datasource.png?width=940px" alt="Configure Data Source"/>
&lt;/div>
&lt;div class="title">Figure 7. Configure Grafana Data Source&lt;/div>
&lt;/div>
&lt;div class="admonitionblock note">
&lt;table>
&lt;tbody>&lt;tr>
&lt;td class="icon">
&lt;i class="fa icon-note" title="Note">&lt;/i>
&lt;/td>
&lt;td class="content">
At this point the Grafana serviceaccount has &lt;em>cluster_monitoring_view&lt;/em> privileges.
&lt;/td>
&lt;/tr>
&lt;/tbody>&lt;/table>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As you can see in the following image, this configuration did not help.&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/query5.png?width=940px" alt="Query"/>
&lt;/div>
&lt;div class="title">Figure 8. Query after Data Source has manually been modified&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_thanos_querier_vs_thanos_querier">Thanos Querier vs. Thanos Querier&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>To summarize, in the OpenShift UI everything works, but when using the Grafana dashboard, we see all namespaces from the cluster. Let’s try to find out how OpenShift does this.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we check the Thanos services we will see 3 ports:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> ports:
- name: web
protocol: TCP
port: 9091
targetPort: web
- name: tenancy
protocol: TCP
port: 9092
targetPort: tenancy
- name: tenancy-rules
protocol: TCP
port: 9093
targetPort: tenancy-rules&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Currently we configured port 9091, but there is another one, which is called &lt;strong>tenancy&lt;/strong>, maybe this is what we need? Let’s try it:&lt;/p>
&lt;/div>
&lt;div class="olist arabic">
&lt;ol class="arabic">
&lt;li>
&lt;p>Change the CRD GrafanaDataSource to use port 9092 (instead of 9091). This will restart the pod and remove the custom query parameter we configured earlier.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Remove the cluster-role&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc adm policy remove-cluster-role-from-user cluster-monitoring-view -z grafana-serviceaccount&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>The serviceaccount of Grafana, must be able to view the project we want to show in the dashboards. Therefore, allow the Grafana serviceaccount to view the project &lt;em>ns1&lt;/em>:&lt;/p>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-bash" data-lang="bash">oc adm policy add-role-to-user view system:serviceaccount:grafana:grafana-serviceaccount -n ns1&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>Log into Grafana as administrator and manually change the Data Source and add &lt;strong>namespace=ns1&lt;/strong> to the setting &lt;strong>Custom query parameters&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Rerun the Query …​ as you see you will now see one namespace only.&lt;/p>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/working-query.png?width=940px" alt="Query"/>
&lt;/div>
&lt;div class="title">Figure 9. Query with Thanos Querier on port 9092&lt;/div>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_what_happened">What happened?&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>So what actually happened here? We have two ports for our Thanos Querier which are important: 9091 and 9092.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When we check the Deployment of the Thanos Querier for these ports we will see:&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>For the port &lt;strong>9091&lt;/strong> it looks like the following:&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml">spec:
[...]
containers:
[...]
- resources:
[...]
ports:
- name: web
containerPort: 9091
protocol: TCP
[...]
args:
[...]
- &amp;#39;-openshift-sar={&amp;#34;resource&amp;#34;: &amp;#34;namespaces&amp;#34;, &amp;#34;verb&amp;#34;: &amp;#34;get&amp;#34;}&amp;#39;&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>There is an OAuth setting which says: you have to have the privilege to GET the objects &amp;#34;namespace&amp;#34;.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>The only cluster role which has exactly this privilege and which is also mentioned by the official OpenShift documentation is &lt;strong>cluster-monitoring-view&lt;/strong>&lt;/p>
&lt;/div>
&lt;div class="listingblock">
&lt;div class="content">
&lt;pre class="highlight">&lt;code class="language-yaml" data-lang="yaml"> - apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
name: cluster-monitoring-view
rules:
- apiGroups:
- &amp;#34;&amp;#34;
resources:
- namespaces
verbs:
- get&lt;/code>&lt;/pre>
&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>As we have seen above, this will show you all namespaces available on the cluster.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>When you check port &lt;strong>9092&lt;/strong> there is no such OAuth configuration. This service is actually in front of the container &lt;strong>kube-rbac-proxy&lt;/strong>. It does not require OAuth, but instead the namespace URL parameter.&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Details can be found at: &lt;a href="https://github.com/openshift/enhancements/blob/master/enhancements/monitoring/user-workload-monitoring.md" class="bare">https://github.com/openshift/enhancements/blob/master/enhancements/monitoring/user-workload-monitoring.md&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="paragraph">
&lt;p>In short the whole setup looks like this:&lt;/p>
&lt;/div>
&lt;div class="imageblock">
&lt;div class="content">
&lt;img src="https://blog.stderr.at/openshift/images/grafana/thanos.png?width=640px" alt="Thanos"/>
&lt;/div>
&lt;div class="title">Figure 10. Thanos interconnecting containers&lt;/div>
&lt;/div>
&lt;div class="paragraph">
&lt;p>While port 9091 goes directly to Thanos it will require that you have the cluster-monitoring-view role. Port 9092 does not require this, but instead you &lt;strong>MUST&lt;/strong> send the URL parameter namespace=.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="sect1">
&lt;h2 id="_summary">Summary&lt;/h2>
&lt;div class="sectionbody">
&lt;div class="paragraph">
&lt;p>While both options are valid, some considerations must be done when using the Grafana Operator.&lt;/p>
&lt;/div>
&lt;div class="ulist">
&lt;ul>
&lt;li>
&lt;p>Currently the URL parameter can be set in Grafana directly only. The operator will ignore it. The ticket in the project shall address this, but is not yet implemented: &lt;a href="https://github.com/integr8ly/grafana-operator/issues/309" class="bare">https://github.com/integr8ly/grafana-operator/issues/309&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The URL parameter setting will be gone, when the Grafana pods is restarted, which might lead to a problem.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>While the Grafana serviceaccount does not require cluster permissions, it will require permission to view the appropriate namespace&lt;/p>
&lt;/li>
&lt;li>
&lt;p>All above also means, that you actually would need to create a new DataSource for every project you want to monitor. I was not able to find a way, to send multiple namespaces in the URL parameter.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div class="paragraph">
&lt;p>Is it useful to leverage the Grafana operator then at all? Probably yes, since Operators are the future and it is actively developed. Nevertheless, it is always possible to deploy Grafana manually.&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div></description></item></channel></rss>